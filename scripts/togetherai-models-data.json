[
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e831864b84b428b8d322d0",
    "name": "Austism/chronos-hermes-13b",
    "display_name": "Chronos Hermes (13B)",
    "display_type": "chat",
    "description": "This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.",
    "license": "other",
    "creator_organization": "Austism",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6966f4A2caf8efaE98C251C3C15210333578C158": 1
      },
      "asks_updated": "2024-06-07T13:01:05.579852023Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.043478260869565216,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6560b993b56cf1e0970c9b1a",
    "name": "BAAI/bge-base-en-v1.5",
    "display_name": "BAAI-Bge-Base-1p5",
    "display_type": "embedding",
    "description": "bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding",
    "license": "MIT",
    "creator_organization": "BAAI",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 109482240,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-24T14:56:19.475Z",
    "update_at": "2023-12-22T03:26:23.802Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      },
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x18530141Cf50876b091f3D4B9FA3Bb7F7d24d20a": 1,
        "0x6a62C7dE642F31258383c1fB6d6558170b4c562b": 1,
        "0x8BEE38fD0697C19F06411AaEEea935073005168c": 1,
        "0xe2d9B1fd3EfBA3fEB7cfc84FD5d9c1621dA3dEB9": 1
      },
      "asks_updated": "2024-06-07T16:41:22.801759253Z",
      "gpus": {
        "": 0
      },
      "qps": 13.466666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 918.1999999999999,
      "retry_rate": 0.5333333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.008680555555555556,
          "qps": 5.466666666666667,
          "throughput_in": 340.26666666666665,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0.4666666666666667
        },
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.008647798742138365,
          "qps": 8,
          "throughput_in": 577.9333333333333,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0.06666666666666667
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6560b938b56cf1e0970c9b19",
    "name": "BAAI/bge-large-en-v1.5",
    "display_name": "BAAI-Bge-Large-1p5",
    "display_type": "embedding",
    "description": "bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding",
    "license": "MIT",
    "creator_organization": "BAAI",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 335141888,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 4,
      "output": 4,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-24T14:54:48.986Z",
    "update_at": "2023-12-22T03:27:18.465Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5ED0BA75594E3429628087603D628838bE686ebF": 1,
        "0xD2a55c4769d98e7Df019A3858FA37036BbbAB5cE": 1
      },
      "asks_updated": "2024-06-07T16:34:35.164394359Z",
      "gpus": {
        "": 0
      },
      "qps": 0.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 22.8,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.008680555555555556,
          "qps": 0.2,
          "throughput_in": 22.8,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f78861d683768020b9f005",
    "name": "Gryphe/MythoMax-L2-13b",
    "display_name": "MythoMax-L2 (13B)",
    "display_type": "chat",
    "description": "MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model",
    "license": "other",
    "creator_organization": "Gryphe",
    "hardware_label": "1x A40 48GB",
    "num_parameters": 13000000000,
    "release_date": "2023-08-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ],
      "add_generation_prompt": true,
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T19:58:25.683Z",
    "update_at": "2023-09-05T19:58:25.683Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 30,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x06858219Ccc0F52fBC69325900A9A04481048d88": 1,
        "0x079634FEe19e6cDfaa0D18bed8F1ee0434511345": 1,
        "0x18098b1D525AfaBDb0960139B87E538781CDE7f1": 1,
        "0x1E56E6914bDF2Ed76AF23D307498375010C61f8a": 1,
        "0x20Bb608bdDE8f3cF77D81e77C2E9d86Dcff300b4": 1,
        "0x232Ceeb83192EC8987d5E9Ef204e7d43e9E86316": 1,
        "0x23bB690905F1823a1c6F993828fA3ce7c0bbaDD2": 1,
        "0x34A40D13Fd942a959276C733895ef67757C309a3": 1,
        "0x36f781DC1f6F12813BFF1E934Ad4eE11e4DC0703": 1,
        "0x3E1C9c03573fdEa4401d04bd4EeB4aB1DcdD910C": 1,
        "0x4CC8a2f0063C121106b1C4a426e4Ce3910741c72": 1,
        "0x4b55B8b7aAC06c9e4B2e37F047fD09D6b38E65D9": 1,
        "0x50e901F8Cae91f86Cac72a7b257b82373271f995": 1,
        "0x56CAacAF35c57F9C7f0C52002a82858f4f9c9E10": 1,
        "0x65571c240985f269d5364189C8E343403F53D5a2": 1,
        "0x7019a45bE5b557780cf9f39cC0e877073bde7cB0": 1,
        "0x797017412dadE695890f3c62EB6f95A0Df9210D3": 1,
        "0x7Bd58b7134F6549D249f78404cf1e1cE714f8796": 1,
        "0x83E51BF27bD72b007973c1Fe536c359F21806293": 1,
        "0x8Cd4e587AFeFf71940AF9f03287b73405e62Be96": 1,
        "0x9BA8F96DBb7b6BB08853E6346Af03C6192136Dc2": 1,
        "0x9C1ce0BfC0d2221c27e1AB2EF7B4E88725ed2853": 1,
        "0x9b8A0b43196F4f4912Fc0673D473FA74Ad1b07C9": 1,
        "0xE2D9fc8eE316575dCAcAAb1198Eb28b9838fecF6": 1,
        "0xEFf3f09003b1E5934a8797919765e9486AfAAc1d": 1,
        "0xabc0E6275b8E4A516f9cD79E93668A11F23C9CE1": 1,
        "0xce44a4BCB70c772DCBEaAB29359b4dCF31464cF9": 1,
        "0xd460e7A2756D20acFE653bb4bF68C170a877Da21": 1,
        "0xe35069a162740ec3C2857bFf531DB4C0CdC1e225": 1,
        "0xf7225F1f3a85B8b7f5ad0D26b2aF8fCC5e70bb74": 1
      },
      "asks_updated": "2024-06-07T16:59:59.340598398Z",
      "gpus": {
        "": 0
      },
      "qps": 32.8,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 26697.066666666666,
      "throughput_out": 3896.9333333333334,
      "error_rate": 0.06666666666666667,
      "retry_rate": 0.3333333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.09585559566787054,
          "qps": 32.8,
          "throughput_in": 26697.066666666666,
          "throughput_out": 3896.9333333333334,
          "error_rate": 0.06666666666666667,
          "retry_rate": 0.3333333333333333
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6573540efe9a5c79871809ce",
    "name": "Meta-Llama/Llama-Guard-7b",
    "display_name": "Llama Guard (7B)",
    "display_type": "moderation",
    "description": "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/LlamaGuard-7b",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template": "{{ '[INST] Task: Check if there is unsafe content in \\'' }}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{ '\\' messages in conversations according our safety policy with the below categories.\n\n<BEGIN UNSAFE CONTENT CATEGORIES>\nO1: Violence and Hate. \nShould not\n - Help people plan or engage in violence.\n - Encourage people to engage in violence.\n - Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics like their race, color, religion, national origin, sexual orientation, gender, gender identity, or disability.\n - Encourage discrimination against people based on those characteristics and should not use slurs or create insults based on those characteristics.\nCan\n - Provide information on violence and discrimination.\n - Discuss the topics of hate and violence, and can discuss historical events involving violence.\nO2: Sexual Content. \nShould not\n - Engage in sexually explicit (i.e., erotic) conversations and should not encourage people to engage in sexual activities.\nCan\n - Discuss topics related to sexuality and sexual education.\n - Provide general information regarding sexual activities.\n - Provide guidance on topics related to sexual health.\nO3: Criminal Planning. \nShould not\n - Help people plan or engage in criminal activities like theft, kidnapping, or financial crimes, especially when the person indicates that they may act on the information provided to them.\n - Encourage people to engage in criminal activities or condone criminal behavior.\nCan\n - Help people understand how crimes are committed, provided that the response is not so detailed that it could be used to provide a roadmap for future crimes.\n - Help people understand how systems work that are used to prevent crimes, provided those descriptions do not provide detailed information on how to defeat those systems.\nO4: Guns and Illegal Weapons. \nShould not\n - Assist in the planning or execution of firearm or illegal weapons crimes, especially when the person indicates that they may act on the information provided to them.\n - Encourage people to engage in firearm or illegal weapons crimes or condone such behavior.\nCan\n - Discuss firearms and the arguments for and against firearm ownership.\nO5: Regulated or Controlled Substances. \nShould not\n - Encourage or assist people in the trafficking, consumption, or use of regulated or controlled substances, including but not limited to illegal drugs, tobacco, alcohol, and cannabis.\n - Assist or encourage people to create such substances when it is illegal to do so.\nCan\n - Discuss the use of regulated or controlled substances, and can provide general information on those substances (ex: what their chemical composition is and what their effects are).\n - Provide information on how those substances are manufactured, provided that the information is not so detailed as to provide step-by-step instructions for their creation.\nO6: Self-Harm. \nShould not\n - Encourage people to harm themselves.\n - Romanticize or condone self-harm or suicide.\n - Provide information regarding the methods of suicide or self-harm.\n - Provide any information or advice, other than information regarding appropriate health resources, to people who express or imply that they wish to harm themselves.\nCan\n - Provide general information regarding self-harm and suicide (ex: statistics, the mental health challenges faced by those who take these actions).\nShould\n - Provide information regarding appropriate health resources to people who imply or express the desire to harm themselves.\n<END UNSAFE CONTENT CATEGORIES>\n\n<BEGIN CONVERSATION>\n\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'User: ' + message['content'] + '\n\n' }}{% else %}{{ 'Agent: ' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '<END CONVERSATION>\n\nProvide your safety assessment for '}}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{' in the above conversation:\n - First line must read \\'safe\\' or \\'unsafe\\'.\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]' }}",
      "safety_label": "safe",
      "safe_response": true,
      "safety_config": {
        "max_tokens": 64
      },
      "safety_categories": {
        "O1": "Violence and Hate",
        "O2": "Sexual Content",
        "O3": "Criminal Planning",
        "O4": "Guns and Illegal Weapons",
        "O5": "Regulated or Controlled Substances",
        "O6": "Self-Harm"
      }
    },
    "pricing": {
      "input": 6,
      "output": 6,
      "hourly": 0
    },
    "update_at": "2024-04-20T23:25:17.775Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      },
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      },
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_GUARD",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1cf712126D74eda6a43B01b00a9cc782515CA6Ae": 1,
        "0x2a9020e1f601DAEc1d0AB83ce5e9207162d93E3E": 1,
        "0x4ceB37C5700106874aA40B8DA6b7349Ab7627643": 1,
        "0xD08a80b09C99e716BdFDdce87619C5ae3fcffA22": 1
      },
      "asks_updated": "2024-06-07T14:55:59.449492864Z",
      "gpus": {
        "": 0
      },
      "qps": 12.733333333333334,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 9121,
      "throughput_out": 30.133333333333333,
      "retry_rate": 0.06666666666666667,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.06000000000000002,
          "qps": 4.466666666666667,
          "throughput_in": 3446,
          "throughput_out": 10.666666666666666,
          "error_rate": 0,
          "retry_rate": 0.06666666666666667
        },
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.07198443579766561,
          "qps": 4.2,
          "throughput_in": 2865.5333333333333,
          "throughput_out": 10.4,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.08983080411651818,
          "qps": 4.066666666666666,
          "throughput_in": 2809.4666666666667,
          "throughput_out": 9.066666666666666,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656f5aac044c74c554a30c4f",
    "name": "Nexusflow/NexusRaven-V2-13B",
    "display_name": "NexusRaven (13B)",
    "display_type": "language",
    "description": "NexusRaven is an open-source and commercially viable function calling LLM that surpasses the state-of-the-art in function calling capabilities.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Nexusflow/NexusRaven-V2-13B",
    "creator_organization": "Nexusflow",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-12-05T17:15:24.561Z",
    "update_at": "2023-12-05T17:15:24.561Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 6,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x136221c6C81544eF98A10094ae44d1C8f0068075": 1,
        "0x2259fF30A3458B56694Fa67cC8f1f72186065571": 1,
        "0x5D6d5F11d0460A70c208389025210C34980b1324": 1,
        "0x860a693E2658cF6ffF5298e02842C71879942D62": 1,
        "0x8E1F6f4689ad3E0a30ECA6D84dbc26D95A99fCF4": 1,
        "0x94F527F51D240E3411dDF838d394b1DDD3801EFE": 1
      },
      "asks_updated": "2024-06-07T13:37:58.250502041Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 1,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65664e4d79fe5514beebd5d3",
    "name": "NousResearch/Nous-Capybara-7B-V1p9",
    "display_name": "Nous Capybara v1.9 (7B)",
    "display_type": "chat",
    "description": "first Nous collection of dataset and models made by fine-tuning mostly on data created by Nous in-house",
    "license": "MIT",
    "creator_organization": "NousResearch",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "add_generation_prompt": true,
      "stop": [
        "USER:",
        "ASSISTANT:"
      ],
      "prompt_format": "USER:\n{prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %} {{ 'USER:\n' + message['content'] + '\n' }}{% elif message['role'] == 'system' %}{{ 'SYSTEM:\n' + message['content'] + '\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT:\n' + message['content'] + '\n'  }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:\n' }}{% endif %}{% endfor %}"
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-28T20:32:13.026Z",
    "update_at": "2023-11-28T20:33:03.163Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x88eB978d91199D40cB23871d4319d382EF40492D": 1
      },
      "asks_updated": "2024-06-07T16:54:00.149171287Z",
      "gpus": {
        "": 0
      },
      "qps": 0.26666666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 119.33333333333333,
      "throughput_out": 78.26666666666667,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 3.1666666666666665,
          "qps": 0.26666666666666666,
          "throughput_in": 119.33333333333333,
          "throughput_out": 78.26666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65d542a20af4aafc88716626",
    "name": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
    "display_name": "Nous Hermes 2 - Mistral DPO (7B)",
    "display_type": "chat",
    "description": "Nous Hermes 2 on Mistral 7B DPO is the new flagship 7B Hermes! This model was DPO'd from Teknium/OpenHermes-2.5-Mistral-7B and has improved across the board on all benchmarks tested - AGIEval, BigBench Reasoning, GPT4All, and TruthfulQA.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
    "creator_organization": "NousResearch",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>"
      ],
      "chat_template": "{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-21T00:24:02.387Z",
    "update_at": "2024-02-21T00:24:02.387Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4Fe55E303eE267938080c986E8a963102dA8B495": 1
      },
      "asks_updated": "2024-06-07T16:29:24.209518736Z",
      "gpus": {
        "": 0
      },
      "qps": 0.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 625.6666666666666,
      "throughput_out": 51.86666666666667,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.1503496503496503,
          "qps": 0.4,
          "throughput_in": 625.6666666666666,
          "throughput_out": 51.86666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a4b298fbc8405400423169",
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "display_name": "Nous Hermes 2 - Mixtral 8x7B-DPO ",
    "display_type": "chat",
    "description": "Nous Hermes 2 Mixtral 7bx8 DPO is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "creator_organization": "NousResearch",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 56000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "hourly": 0,
      "input": 150,
      "output": 150
    },
    "created_at": "2024-01-15T04:20:40.079Z",
    "update_at": "2024-06-05T05:41:47.197Z",
    "autopilot_pool": "cr-a100-80-2x",
    "has_wandb_telemetry": false,
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "lago_tag": "MIXTRAL_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x17B96a27Dd71A9C4687441c14d1feCA207D0D3d4": 1,
        "0x1812939B682B119d362412811237da09D9bc6c8D": 1
      },
      "asks_updated": "2024-06-07T16:59:53.822505499Z",
      "gpus": {
        "": 0
      },
      "qps": 0.6666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 600.8666666666667,
      "throughput_out": 60.666666666666664,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.163265306122449,
          "qps": 0.4666666666666667,
          "throughput_in": 40.46666666666667,
          "throughput_out": 26.133333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.11538461538461536,
          "qps": 0.2,
          "throughput_in": 560.4,
          "throughput_out": 34.53333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a4466efbc8405400423166",
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "display_name": "Nous Hermes 2 - Mixtral 8x7B-SFT",
    "display_type": "chat",
    "description": "Nous Hermes 2 Mixtral 7bx8 SFT is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "creator_organization": "NousResearch",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2024-01-14T20:39:10.060Z",
    "update_at": "2024-01-14T20:39:10.060Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "lago_tag": "MIXTRAL_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3805a418c9af7eA4a88C6BC519ba95223EFe87F7": 1
      },
      "asks_updated": "2024-06-07T16:57:30.279269535Z",
      "gpus": {
        "": 0
      },
      "qps": 0.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 160.2,
      "throughput_out": 16.933333333333334,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.08333333333333333,
          "qps": 0.2,
          "throughput_in": 160.2,
          "throughput_out": 16.933333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "658c8dad27fb98d2edc447ff",
    "name": "NousResearch/Nous-Hermes-2-Yi-34B",
    "display_name": "Nous Hermes-2 Yi (34B)",
    "display_type": "chat",
    "description": "Nous Hermes 2 - Yi-34B is a state of the art Yi Fine-tune",
    "license": "apache-2",
    "creator_organization": "NousResearch",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-12-27T20:48:45.586Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 200,
      "output": 200
    },
    "created_at": "2023-12-27T20:48:45.586Z",
    "update_at": "2023-12-27T20:50:38.632Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe05F5c447C6A51aB3FB66FC03FCD2b7B5da6B080": 1
      },
      "asks_updated": "2024-06-07T16:10:08.036552774Z",
      "gpus": {
        "": 0
      },
      "qps": 20.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 3757.733333333333,
      "throughput_out": 487.6,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.5361078806003213,
          "qps": 20.2,
          "throughput_in": 3757.733333333333,
          "throughput_out": 487.6,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64cae18d3ede2fa7e2cbcc7d",
    "name": "NousResearch/Nous-Hermes-Llama2-13b",
    "display_name": "Nous Hermes Llama-2 (13B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "mit",
    "creator_organization": "NousResearch",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": [
        "###",
        "</s>"
      ],
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-08-02T23:06:53.926Z",
    "update_at": "2023-10-07T00:19:33.779Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xfA6b8e3C0ac21BA89F8e75770251f0E4e509eF90": 1
      },
      "asks_updated": "2024-06-07T11:01:30.584411214Z",
      "gpus": {
        "": 0
      },
      "qps": 0.6,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 642.3333333333334,
      "throughput_out": 35.733333333333334,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.23958333333333334,
          "qps": 0.6,
          "throughput_in": 642.3333333333334,
          "throughput_out": 35.733333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf6",
    "name": "NousResearch/Nous-Hermes-llama-2-7b",
    "display_name": "Nous Hermes LLaMA-2 (7B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b",
    "creator_organization": "NousResearch",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738415616,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": [
        "###",
        "</s>"
      ],
      "add_generation_prompt": true,
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T17:41:52.365Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xf3AbD7152646995C204D8Bee0699AC58653De524": 1
      },
      "asks_updated": "2024-06-07T16:21:40.378885695Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.06666666666666667,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf5",
    "name": "Open-Orca/Mistral-7B-OpenOrca",
    "display_name": "OpenOrca Mistral (7B) 8K",
    "display_type": "chat",
    "description": "An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
    "creator_organization": "OpenOrca",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241748480,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|im_end|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T00:01:52.541Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x802be1ae9dC8F68c43a47ec3d2070F8f1B0553E8": 1
      },
      "asks_updated": "2024-06-07T12:49:49.69549538Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1111111111111111,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cb",
    "name": "Phind/Phind-CodeLlama-34B-v2",
    "display_name": "Phind Code LLaMA v2 (34B)",
    "display_type": "code",
    "description": "Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.",
    "license": "llama2",
    "creator_organization": "Phind",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 33743970304,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "### System Prompt\nYou are an intelligent programming assistant.\n\n### User Message\n{prompt}n\n### Assistant\n",
      "stop": [
        "</s>"
      ],
      "chat_template": "{{ '### System Prompt\nYou are an intelligent programming assistant.\n\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User Message\n' + message['content'] + '\n' }}{% else %}{{ '### Assistant\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant\n' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "testytiger"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xE3b9434A627d4E042a82A4E04375E7B14D9a2866": 1
      },
      "asks_updated": "2024-06-07T10:25:55.927090758Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "testytiger",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c81b4975e79f24d98b50",
    "name": "Qwen/Qwen1.5-0.5B-Chat",
    "display_name": "Qwen 1.5 Chat (0.5B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 500000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:35:55.571Z",
    "update_at": "2024-02-05T11:35:55.571Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x69d786B0E491C02c3053287F7FD4aa684A0f86B9": 1
      },
      "asks_updated": "2024-06-07T12:35:10.365957285Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 0.06666666666666667,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.07142857142857142,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 0.06666666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8164975e79f24d98b4f",
    "name": "Qwen/Qwen1.5-0.5B",
    "display_name": "Qwen 1.5 (0.5B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 500000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:35:50.032Z",
    "update_at": "2024-02-05T11:35:50.032Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xa01d67F2450E0e7ACBfb7dc8B1a0A3205C5C8310": 1
      },
      "asks_updated": "2024-06-07T11:33:26.454241865Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.07142857142857142,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8284975e79f24d98b52",
    "name": "Qwen/Qwen1.5-1.8B-Chat",
    "display_name": "Qwen 1.5 Chat (1.8B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 1800000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:08.609Z",
    "update_at": "2024-02-05T11:36:08.609Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x332b426661a850784BAcFd12B9E7D9b51397B1ec": 1
      },
      "asks_updated": "2024-06-07T12:57:45.765170407Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.16666666666666666,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8214975e79f24d98b51",
    "name": "Qwen/Qwen1.5-1.8B",
    "display_name": "Qwen 1.5 (1.8B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-1.8B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 1800000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:01.895Z",
    "update_at": "2024-02-05T11:36:01.895Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xE1E3e79fC7e677c1Bdb8E6f6B6dde0B5d78C2ABc": 1
      },
      "asks_updated": "2024-06-07T16:21:46.788341719Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.16666666666666666,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "663929111a16009453d858d6",
    "name": "Qwen/Qwen1.5-110B-Chat",
    "display_name": "Qwen 1.5 Chat (110B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-110B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 110000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|im_end|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 450,
      "output": 450,
      "hourly": 0
    },
    "created_at": "2024-05-06T19:01:37.206Z",
    "update_at": "2024-05-06T19:01:37.206Z",
    "instances": [
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0f4D2eE1fBd61E29262c9ce2c82ea2B93BBAFF0a": 1,
        "0xC74744EAE6519a37c6b38b5147eff93653BFCB7a": 1
      },
      "asks_updated": "2024-06-07T16:30:59.158808945Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 2.3333333333333335,
      "throughput_out": 19.2,
      "stats": [
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0,
          "qps": 0.13333333333333333,
          "throughput_in": 2.3333333333333335,
          "throughput_out": 19.2,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c84d4975e79f24d98b58",
    "name": "Qwen/Qwen1.5-14B-Chat",
    "display_name": "Qwen 1.5 Chat (14B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-14B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 14000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:45.529Z",
    "update_at": "2024-02-05T11:36:45.529Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xb9ef83d632Ab128d5C49D1E6B9c808BD20B3E7F0": 1
      },
      "asks_updated": "2024-06-07T10:13:33.045532683Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8474975e79f24d98b57",
    "name": "Qwen/Qwen1.5-14B",
    "display_name": "Qwen 1.5 (14B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-14B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 14000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:39.431Z",
    "update_at": "2024-02-05T11:36:39.431Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x473F3790526C64D89f0d1598C022bE36492D3051": 1
      },
      "asks_updated": "2024-06-07T14:05:28.9520347Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "660c48d16184ee782ae490f0",
    "name": "Qwen/Qwen1.5-32B-Chat",
    "display_name": "Qwen 1.5 Chat (32B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 32000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2024-04-02T17:23:42.826Z",
    "update_at": "2024-04-05T15:40:08.892Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6E19Ed65551bfE073e3C99BaB6E36779C541e1D4": 1
      },
      "asks_updated": "2024-06-07T12:38:04.103101156Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 34,
      "throughput_out": 26.533333333333335,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.13333333333333333,
          "throughput_in": 34,
          "throughput_out": 26.533333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "660c40783cd92bc225de4b41",
    "name": "Qwen/Qwen1.5-32B",
    "display_name": "Qwen 1.5 (32B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 32000000000,
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "hourly": 0,
      "input": 200,
      "output": 200
    },
    "created_at": "2024-04-02T17:23:42.826Z",
    "update_at": "2024-05-17T04:43:13.412Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "isSelfServeDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xc0a1c6F29F6a40fAC5fedd7Bb1723c7bf566785A": 1
      },
      "asks_updated": "2024-06-07T16:28:31.172238932Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8344975e79f24d98b54",
    "name": "Qwen/Qwen1.5-4B-Chat",
    "display_name": "Qwen 1.5 Chat (4B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-4B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 4000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:20.314Z",
    "update_at": "2024-02-05T11:36:20.314Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x51635204AFA513ccC202DDac3AE1cCE1Ad3074D8": 1
      },
      "asks_updated": "2024-06-07T16:29:51.655652683Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 0.26666666666666666,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 0.26666666666666666,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c82e4975e79f24d98b53",
    "name": "Qwen/Qwen1.5-4B",
    "display_name": "Qwen 1.5 (4B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-4B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 4000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:14.800Z",
    "update_at": "2024-02-05T11:36:14.800Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2cf9F631373B30D4E27961Ac0D58799Fa32D30dc": 1
      },
      "asks_updated": "2024-06-07T16:27:10.31619585Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c85a4975e79f24d98b5a",
    "name": "Qwen/Qwen1.5-72B-Chat",
    "display_name": "Qwen 1.5 Chat (72B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 72000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:58.193Z",
    "update_at": "2024-04-17T19:23:06.511Z",
    "instances": [
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      },
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0922F8Ee1745fAdB3eC3f7b80a16F3c67c3D1B81": 1,
        "0x452D0f5989a6766Dd4F15e308538E5dc72024422": 1,
        "0xe2c4e7f428A195b1D796d3D9F785Ba2AD9F4De28": 1
      },
      "asks_updated": "2024-06-07T12:34:23.497388962Z",
      "gpus": {
        "": 0
      },
      "qps": 4.133333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 5317.200000000001,
      "throughput_out": 415.46666666666664,
      "stats": [
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0.1349060009170642,
          "qps": 3.4,
          "throughput_in": 4265.533333333334,
          "throughput_out": 311.46666666666664,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.3280593020931055,
          "qps": 0.7333333333333333,
          "throughput_in": 1051.6666666666667,
          "throughput_out": 104,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8544975e79f24d98b59",
    "name": "Qwen/Qwen1.5-72B",
    "display_name": "Qwen 1.5 (72B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-72B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 72000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {},
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:52.008Z",
    "update_at": "2024-02-05T11:36:52.008Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x37A5f0f9744F5bC79Da7908E1b70C10502C4b4cf": 1
      },
      "asks_updated": "2024-06-07T00:40:43.611652668Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.3333333333333333,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8404975e79f24d98b56",
    "name": "Qwen/Qwen1.5-7B-Chat",
    "display_name": "Qwen 1.5 Chat (7B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-7B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:32.804Z",
    "update_at": "2024-02-05T11:36:32.804Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1D0455b2E77572f9584b859f1463114BD4D4EFDE": 1
      },
      "asks_updated": "2024-06-07T17:00:59.921209986Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 3.4,
      "throughput_out": 28.533333333333335,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.13333333333333333,
          "throughput_in": 3.4,
          "throughput_out": 28.533333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c83a4975e79f24d98b55",
    "name": "Qwen/Qwen1.5-7B",
    "display_name": "Qwen 1.5 (7B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-7B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:26.420Z",
    "update_at": "2024-02-05T11:36:26.420Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2ccdcdEf417d5d6D2EeD95dF48f1fcc8Ec1085b2": 1
      },
      "asks_updated": "2024-06-07T11:36:33.230831799Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.1,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acee11227f790586239d36",
    "name": "SG161222/Realistic_Vision_V3.0_VAE",
    "display_name": "Realistic Vision 3.0",
    "display_type": "image",
    "description": "Fine-tune version of Stable Diffusion focused on photorealism.",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/SG161222/Realistic_Vision_V1.4",
    "creator_organization": "SG161222",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 1024,
      "width": 1024,
      "number_of_images": 2,
      "steps": 20,
      "seed": 42
    },
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-07-11T05:52:17.219Z",
    "update_at": "2024-05-23T20:19:09.740Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0": 1
      },
      "asks_updated": "2024-06-07T00:40:43.684342674Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.2222222222222222,
          "qps": 0.06666666666666667,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "662985e66d314668baa595f8",
    "name": "Snowflake/snowflake-arctic-instruct",
    "display_name": "Snowflake Arctic Instruct",
    "display_type": "chat",
    "description": "Arctic is a dense-MoE Hybrid transformer architecture pre-trained from scratch by the Snowflake AI Research Team.",
    "license": "Apache-2.0",
    "link": "https://huggingface.co/Snowflake/snowflake-arctic-instruct",
    "creator_organization": "Snowflake",
    "hardware_label": "8X H100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 480000000000,
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "add_generation_prompt": true,
      "chat_template_name": "default",
      "max_tokens": 2048
    },
    "pricing": {
      "hourly": 0,
      "input": 600,
      "output": 600
    },
    "update_at": "2024-05-21T04:34:51.453Z",
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "vllm",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "lago_tag": "MIXTRAL_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0D56Cde782E1440aE7a60A03925f436e5A16a5da": 1,
        "0x10650EC58656000fb8fDCEb9729f3C605D86f1ca": 1,
        "0xCd7Bf771030E832EB2954f097a8929F748E93FF9": 1
      },
      "asks_updated": "2024-06-07T16:37:15.669551458Z",
      "gpus": {
        "": 0
      },
      "qps": 0.26666666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 44.86666666666667,
      "throughput_out": 88,
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.85,
          "qps": 0.26666666666666666,
          "throughput_in": 44.86666666666667,
          "throughput_out": 88,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655d15e7b56cf1e0970c9b17",
    "name": "Undi95/ReMM-SLERP-L2-13B",
    "display_name": "ReMM SLERP L2 (13B)",
    "display_type": "chat",
    "description": "Re:MythoMax (ReMM) is a recreation trial of the original MythoMax-L2-B13 with updated models. This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Undi95/ReMM-SLERP-L2-13B",
    "creator_organization": "Undi95",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST]\n {prompt} \n[/INST]\n\n",
      "stop": [
        "[INST]",
        "\n\n"
      ],
      "chat_template_name": "llama",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-11-21T20:41:11.759Z",
    "update_at": "2023-11-21T20:41:11.759Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x07c96Eeb1Bb52ae6FB40543f6188912775F35d52": 1
      },
      "asks_updated": "2024-06-07T16:36:18.299640126Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655d0fecb56cf1e0970c9b16",
    "name": "Undi95/Toppy-M-7B",
    "display_name": "Toppy M (7B)",
    "display_type": "chat",
    "description": "A merge of models built by Undi95 with the new task_arithmetic merge method from mergekit.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Undi95/Toppy-M-7B",
    "creator_organization": "Undi95",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241748480,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": [
        "###"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '### Response:' }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-11-21T20:15:40.468Z",
    "update_at": "2023-11-21T20:15:40.468Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x80bd2D4302331454187F9EdA8b88e99d6E4A6c9b": 1
      },
      "asks_updated": "2024-06-07T12:35:19.756865764Z",
      "gpus": {
        "": 0
      },
      "qps": 0.3333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 400.2,
      "throughput_out": 17.8,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.11111111111111113,
          "qps": 0.3333333333333333,
          "throughput_in": 400.2,
          "throughput_out": 17.8,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "658504fde7e2e898e81b5400",
    "name": "WhereIsAI/UAE-Large-V1",
    "display_name": "UAE-Large-V1",
    "display_type": "embedding",
    "description": "A universal English sentence embedding WhereIsAI/UAE-Large-V1 achieves SOTA on the MTEB Leaderboard with an average score of 64.64!",
    "license": "apache-2.0",
    "link": "https://huggingface.co/bert-base-uncased",
    "creator_organization": "WhereIsAI",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 330000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 4,
      "output": 4,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-12-22T03:39:41.105Z",
    "update_at": "2023-12-22T03:45:34.219Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xb8Bfb7F25770CfF8bf88ddF1D29237f1D5604d96": 1
      },
      "asks_updated": "2024-06-07T16:35:49.032736867Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cd",
    "name": "WizardLM/WizardCoder-15B-V1.0",
    "display_name": "WizardCoder v1.0 (15B)",
    "display_type": "code",
    "description": "This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 15517462528,
    "show_in_playground": true,
    "context_length": 8192,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:\n",
      "stop": [
        "###",
        "<|endoftext|>"
      ],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4C51aff4170724263bF75af64CE9E2e8F6079fA9": 1,
        "0xb4CdE622719696fd930e92FB5bBfC3eA3176D2Fd": 1
      },
      "asks_updated": "2024-06-07T12:34:32.652106239Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f672e8bc372ce719b97f02",
    "name": "WizardLM/WizardCoder-Python-34B-V1.0",
    "display_name": "WizardCoder Python v1.0 (34B)",
    "display_type": "code",
    "description": "This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "</s>",
        "###"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:14:32.365Z",
    "update_at": "2023-09-05T00:14:32.365Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xAC3abeabCb3Ef089becEA8b551a4e998AD8dDF30": 1
      },
      "asks_updated": "2024-06-07T16:10:57.334691597Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6567d4e5d1c5e59967640530",
    "name": "WizardLM/WizardLM-13B-V1.2",
    "display_name": "WizardLM v1.2 (13B)",
    "display_type": "chat",
    "description": "This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 13000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>",
        "USER:",
        "ASSISTANT:"
      ],
      "prompt_format": "USER: {prompt} ASSISTANT:",
      "add_generation_prompt": true,
      "chat_template_name": "llama",
      "pre_prompt": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. "
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-30T00:18:45.791Z",
    "update_at": "2023-11-30T01:20:01.779Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xF9d994b8D62c40bA7532917955dc49D4712C6Ec0": 1
      },
      "asks_updated": "2024-06-07T12:35:08.110469634Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.09090909090909091,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65df9fa4d28dc68bcefec054",
    "name": "allenai/OLMo-7B-Instruct",
    "display_name": "OLMo Instruct (7B)",
    "display_type": "chat",
    "description": "The OLMo models are trained on the Dolma dataset",
    "license": "apache-2.0",
    "link": "https://huggingface.co/allenai/OLMo-7B-Instruct",
    "creator_organization": "AllenAI",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "eos_token": "<|endoftext|>",
      "prompt_format": "<|user|>\n{prompt}\n<|assistant|>",
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|user|>\n' + message['content'] + eos_token }}{% elif message['role'] == 'system' %}{{ '<|system|>\n' + message['content'] + eos_token }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>\n'  + message['content'] + eos_token }}{% endif %}{% if loop.last and add_generation_prompt %}{{ '<|assistant|>\n' }}{% endif %}{% endfor %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-28T21:03:32.038Z",
    "update_at": "2024-02-28T21:03:32.038Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x7c93CF73eBa1F6cBcfDF2D56828b0cC036C2546A": 1
      },
      "asks_updated": "2024-06-07T16:36:05.912190866Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.0625,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65dfa682d28dc68bcefec055",
    "name": "allenai/OLMo-7B-Twin-2T",
    "display_name": "OLMo Twin-2T (7B)",
    "display_type": "language",
    "description": "The OLMo models are trained on the Dolma dataset",
    "license": "apache-2.0",
    "link": "https://huggingface.co/allenai/OLMo-7B-Twin-2T",
    "creator_organization": "AllenAI",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-28T21:32:50.812Z",
    "update_at": "2024-02-28T21:32:50.812Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xadc3D9E453EaDDeC579debE300AAb8e33a305da4": 1
      },
      "asks_updated": "2024-06-07T15:57:22.944375781Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.07142857142857142,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65dfa6ebd28dc68bcefec056",
    "name": "allenai/OLMo-7B",
    "display_name": "OLMo (7B)",
    "display_type": "language",
    "description": "The OLMo models are trained on the Dolma dataset",
    "license": "apache-2.0",
    "link": "https://huggingface.co/allenai/OLMo-7B",
    "creator_organization": "AllenAI",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-28T21:34:35.444Z",
    "update_at": "2024-02-28T21:34:35.444Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xfC0C60D66A62b2A87f96B3318500e876F1B1e367": 1
      },
      "asks_updated": "2024-06-07T16:02:01.861669197Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.07142857142857142,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6598bc0201bf780326e7eac8",
    "name": "bert-base-uncased",
    "display_name": "Bert Base Uncased",
    "display_type": "embedding",
    "description": "original BERT model",
    "license": "Apache-2",
    "creator_organization": "Google",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 46550608,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2024-01-06T02:33:38.323Z",
    "update_at": "2024-01-06T02:33:38.323Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 4,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0b7eae8cCeb3D67b02A97ac2D1100E29E6991EB9": 1,
        "0x21558AA2fCc15eF003135a4108a0884d4A3054f2": 1,
        "0x2fb2cf26D55c96dc0BAad5f088b0e5Bf0FDe565B": 1,
        "0xB49Bf891cBeba9F3e5045acbD9CD7C3fD932A543": 1
      },
      "asks_updated": "2024-06-07T16:55:28.330130942Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425b",
    "name": "codellama/CodeLlama-13b-Instruct-hf",
    "display_name": "Code Llama Instruct (13B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "add_generation_prompt": true,
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-04T05:01:42.539Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x085bF8877517A750f62641F8FE4C5a2D6b26e899": 1,
        "0x27a802c640973FC5c8062846fb580C27e0080a39": 1,
        "0x934A45b707cbe77453d7d14F4d84F31CaF8adc6F": 1
      },
      "asks_updated": "2024-06-07T16:57:13.022004873Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.16666666666666666,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425a",
    "name": "codellama/CodeLlama-13b-Python-hf",
    "display_name": "Code Llama Python (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-20T22:52:59.177Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6b3EbBfa6c3DFDa17dD19c35557A9F3bAdD55583": 1
      },
      "asks_updated": "2024-06-07T12:37:34.608084285Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa144261",
    "name": "codellama/CodeLlama-34b-Instruct-hf",
    "display_name": "Code Llama Instruct (34B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "add_generation_prompt": true,
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xF5546B0d0414AFfc8ee2Dc36D61EcAF3a2ec65F5": 1
      },
      "asks_updated": "2024-06-07T12:30:08.374070546Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.11764705882352942,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa144260",
    "name": "codellama/CodeLlama-34b-Python-hf",
    "display_name": "Code Llama Python (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe09fF3EE0889C8F5c9e434E8AF523649805E34e1": 1
      },
      "asks_updated": "2024-06-07T13:31:07.288262832Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f505752a299002ee4dc9",
    "name": "codellama/CodeLlama-70b-Instruct-hf",
    "display_name": "Code Llama Instruct (70B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template": "{{ bos_token + ' ' }}{% for message in messages %}{{'Source: ' + message['role'].trim() }}{% if not message['destination'] is 'undefined' %}{{ '\n' + 'Destination: ' + message['destination'].trim()  }}{% elif message['role'] == 'system' %}{{ '\n' + 'Destination: assistant' }}{% elif message['role'] == 'user' %}{{ '\n' + 'Destination: assistant' }}{% elif message['role'] == 'assistant' %}{{ '\n' + 'Destination: user'  }}{% endif %}{{ '\n\n ' + message['content'].trim() + '<step>'  + ' '}}{% endfor %}{% if add_generation_prompt %}{{ 'Source: assistant' + '\n' }}{{ 'Destination: user' + '\n\n' + ' '  }}{% endif %}",
      "bos_token": "<s>",
      "step_id": "<step>",
      "stop": [
        "<step>"
      ],
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:44:53.513Z",
    "update_at": "2024-01-29T00:44:53.513Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xa2663C264Db2177E3Ae3Ea643152B2b9b1f1dA6c": 1
      },
      "asks_updated": "2024-06-07T12:41:53.276617448Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.010869565217391304,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f4ba752a299002ee4dc7",
    "name": "codellama/CodeLlama-70b-Python-hf",
    "display_name": "Code Llama Python (70B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-Python-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ]
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:43:38.396Z",
    "update_at": "2024-01-29T00:43:38.396Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xf2a7de1a0E1dC83DC5B1f1dE8783dFEc67be8910": 1
      },
      "asks_updated": "2024-06-07T16:41:26.368115192Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f4d4752a299002ee4dc8",
    "name": "codellama/CodeLlama-70b-hf",
    "display_name": "Code Llama (70B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ]
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:44:04.149Z",
    "update_at": "2024-01-29T00:44:04.149Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xd3C0F1d52BeBdB36d105AFB149b16fbb41a30810": 1
      },
      "asks_updated": "2024-06-07T16:00:04.502091934Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.5,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425e",
    "name": "codellama/CodeLlama-7b-Instruct-hf",
    "display_name": "Code Llama Instruct (7B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6Af33E97914777b841B6f7a11332bF142301403F": 1
      },
      "asks_updated": "2024-06-07T12:57:06.94579768Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.25,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425d",
    "name": "codellama/CodeLlama-7b-Python-hf",
    "display_name": "Code Llama Python (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x68494584Fc039C3698b8E02eDe63d45DE596DE17": 1,
        "0xcd079137d79089474d4d876109cECE8bb33E7Ef9": 1
      },
      "asks_updated": "2024-06-07T12:46:50.054971384Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "660899dc98fbb3f86d028781",
    "name": "cognitivecomputations/dolphin-2.5-mixtral-8x7b",
    "display_name": "Dolphin 2.5 Mixtral 8x7b",
    "display_type": "chat",
    "description": "This Dolphin is really good at coding, I trained with a lot of coding data. It is very obedient but it is not DPO tuned - so you still might need to encourage it in the system prompt as I show in the below examples.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/cognitivecomputations/dolphin-2.5-mixtral-8x7b",
    "creator_organization": "cognitivecomputations",
    "hardware_label": "8x H100 80GB SXM",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 56000000000,
    "release_date": "2023-08-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "pre_prompt": "<|im_start|>system\nYou are Dolphin, an uncensored and unbiased AI assistant.<|im_end|>\n",
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2023-09-05T19:58:25.683Z",
    "update_at": "2023-09-05T19:58:25.683Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isDedicatedInstance": false,
    "lago_tag": "MIXTRAL_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xC247D4e301f7bB0ecf719577741bF912919332e6": 1
      },
      "asks_updated": "2024-06-07T13:24:54.071007892Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 52.733333333333334,
      "throughput_out": 8.2,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1875,
          "qps": 0.13333333333333333,
          "throughput_in": 52.733333333333334,
          "throughput_out": 8.2,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "661456e0c60f613bee9d2d06",
    "name": "databricks/dbrx-instruct",
    "display_name": "DBRX Instruct",
    "display_type": "chat",
    "description": "DBRX Instruct is a mixture-of-experts (MoE) large language model trained from scratch by Databricks. DBRX Instruct specializes in few-turn interactions.",
    "license": "Databricks Open Model License",
    "link": "https://huggingface.co/databricks/dbrx-instruct",
    "creator_organization": "Databricks",
    "hardware_label": "4X H100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "132000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "add_generation_prompt": true,
      "chat_template_name": "default",
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ]
    },
    "pricing": {
      "input": 300,
      "output": 300,
      "hourly": 0
    },
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulproxy2"
      }
    ],
    "lago_tag": "MIXTRAL_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xEf707f83DC8C7BA4C1b1D289C3380dF993A3E507": 1
      },
      "asks_updated": "2024-06-07T12:51:08.654883195Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulproxy2",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c3137e4975e79f24d98b5c",
    "name": "deepseek-ai/deepseek-coder-33b-instruct",
    "display_name": "Deepseek Coder Instruct (33B)",
    "display_type": "chat",
    "description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
    "license": "deepseek",
    "link": "https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct",
    "creator_organization": "DeepSeek",
    "pricing_tier": "Featured",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "",
      "stop": [
        "<|EOT|>",
        "<beginofsentence>",
        "<endofsentence>"
      ],
      "bos_token": "<beginofsentence>",
      "add_generation_prompt": true,
      "chat_template": "{{'<beginofsentence>'}}{%- for message in messages %}{%- if message['role'] == 'system' %}{{ message['content'] }}{%- else %}{%- if message['role'] == 'user' %}{{'### Instruction:\\n' + message['content'] + '\\n'}}{%- else %}{{'### Response:\\n' + message['content'] + '\\n<|EOT|>\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt %}{{'### Response:'}}{% endif %}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2024-02-07T05:22:06.809Z",
    "update_at": "2024-02-07T05:22:06.809Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x38f654ee46DA4cE831153D43f1fC25D3b3410C06": 1
      },
      "asks_updated": "2024-06-07T11:03:30.435540636Z",
      "gpus": {
        "": 0
      },
      "qps": 0.26666666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 457.8666666666667,
      "throughput_out": 213.33333333333334,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.2314814814814815,
          "qps": 0.26666666666666666,
          "throughput_in": 457.8666666666667,
          "throughput_out": 213.33333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "660c58976184ee782ae490f1",
    "name": "deepseek-ai/deepseek-llm-67b-chat",
    "display_name": "DeepSeek LLM Chat (67B)",
    "display_type": "chat",
    "description": "trained from scratch on a vast dataset of 2 trillion tokens in both English and Chinese",
    "license": "deepseek",
    "link": "https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat",
    "creator_organization": "DeepSeek",
    "pricing_tier": "",
    "num_parameters": 67000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "owner_userid": "",
    "config": {
      "prompt_format": "",
      "stop": [
        "<beginofsentence>",
        "<endofsentence>"
      ],
      "bos_token": "<beginofsentence>",
      "add_generation_prompt": true,
      "chat_template": "{{ '<beginofsentence>' }}{% for message in messages %}{% if message['role'] == 'user' %} {{ 'User: ' + message['content'] + '\n\n'}}{% elif message['role'] == 'assistant' %}{{ 'Assistant: ' + message['content'] + '<endofsentence>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ 'Assistant:' }}{% endif %}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-04-02T19:12:23.328Z",
    "update_at": "2024-04-02T19:12:23.328Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x984CF06dbDd92327B6f1A9a4115749C2651bD02C": 1
      },
      "asks_updated": "2024-06-07T16:36:39.581281018Z",
      "gpus": {
        "": 0
      },
      "qps": 0.3333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 15.2,
      "throughput_out": 166,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.08232118758434545,
          "qps": 0.3333333333333333,
          "throughput_in": 15.2,
          "throughput_out": 166,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f676f7bc372ce719b97f04",
    "name": "garage-bAInd/Platypus2-70B-instruct",
    "display_name": "Platypus2 Instruct (70B)",
    "display_type": "chat",
    "description": "An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.",
    "license": "CC BY-NC-4.0",
    "creator_organization": "garage-bAInd",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>",
        "###"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "add_generation_prompt": true,
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %} {{ '### Instruction:\n' + message['content'] + '\n' }}{% elif message['role'] == 'system' %}{{ '### System:\n' + message['content'] + '\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\n' + message['content'] + '\n'  }}{% endif %}{% if loop.last %}{{ '### Response:\n' }}{% endif %}{% endfor %}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:31:51.264Z",
    "update_at": "2023-09-07T01:46:29.338Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x32fA272f7D81963fc8EE3DCA70E28a00BB5f2617": 1
      },
      "asks_updated": "2024-06-07T14:30:09.052797034Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65d7e89e03b97802d3af0512",
    "name": "google/gemma-2b-it",
    "display_name": "Gemma Instruct (2B)",
    "display_type": "chat",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
    "license": "gemma-terms-of-use",
    "link": "https://huggingface.co/google/gemma-2b-it",
    "creator_organization": "Google",
    "pricing_tier": "Featured",
    "num_parameters": 2000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "<eos>",
        "<end_of_turn>"
      ],
      "chat_template": "{{ bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages %}{{'<start_of_turn>' + role + '\n' + message['content'] + '<end_of_turn>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\n' }}{% endif %}",
      "bos_token": "<bos>"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-23T00:36:46.381Z",
    "update_at": "2024-02-23T00:36:46.381Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x83ff7421906004DEa319FB2Dc5766F86f146973E": 1
      },
      "asks_updated": "2024-06-07T16:46:28.22049329Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.0078125,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65d7e93203b97802d3af0513",
    "name": "google/gemma-2b",
    "display_name": "Gemma (2B)",
    "display_type": "language",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
    "license": "gemma-terms-of-use",
    "link": "https://huggingface.co/google/gemma-2b",
    "creator_organization": "Google",
    "pricing_tier": "Featured",
    "num_parameters": 2000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-23T00:39:14.772Z",
    "update_at": "2024-02-23T00:39:14.772Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3B05b29E71860Ca416cEe96c7e793c36fc4Ce5Ff": 1,
        "0x9CFcBB9434f86b6Ce544DB9880af29d188d9433f": 1
      },
      "asks_updated": "2024-06-07T16:39:03.661856074Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65d7ea3d03b97802d3af0515",
    "name": "google/gemma-7b-it",
    "display_name": "Gemma Instruct (7B)",
    "display_type": "chat",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
    "license": "gemma-terms-of-use",
    "link": "https://huggingface.co/google/gemma-7b-it",
    "creator_organization": "Google",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "<eos>",
        "<end_of_turn>"
      ],
      "chat_template": "{{ bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages %}{{'<start_of_turn>' + role + '\n' + message['content'] + '<end_of_turn>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\n' }}{% endif %}",
      "bos_token": "<bos>"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-23T00:43:41.936Z",
    "update_at": "2024-02-23T00:43:41.936Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xa368a540D087220119290B897192743bFE379beE": 1
      },
      "asks_updated": "2024-06-07T11:37:13.15057263Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 6,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 6,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65d7ea3b03b97802d3af0514",
    "name": "google/gemma-7b",
    "display_name": "Gemma (7B)",
    "display_type": "language",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
    "license": "gemma-terms-of-use",
    "link": "https://huggingface.co/google/gemma-7b",
    "creator_organization": "Google",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-23T00:43:39.642Z",
    "update_at": "2024-02-23T00:43:39.642Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xbcD29dE615e898c76dc514D5DD7461CF0Be72245": 1
      },
      "asks_updated": "2024-06-07T12:57:52.446873055Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "664bc5d94eafbbbcbc05c598",
    "name": "hazyresearch/M2-BERT-2k-Retrieval-Encoder-V1",
    "display_name": "M2-BERT 2K Retrieval Encoder V1 ",
    "display_type": "embedding",
    "description": "Monarch Mixer-BERT from the Monarch Mixer paper fine-tuned for retrieval",
    "license": "apache-2.0",
    "link": "https://huggingface.co/hazyresearch/M2-BERT-2k-Retrieval-Encoder-V1",
    "creator_organization": "HazyResearch",
    "num_parameters": 110698560,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "owner_userid": null,
    "config": {},
    "pricing": {
      "input": 2,
      "output": 2,
      "hourly": 0
    },
    "created_at": "2024-05-20T21:51:21.573Z",
    "update_at": "2024-05-20T21:51:21.573Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "isFinetuned": false,
    "lago_tag": "EMBEDDING_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xAABb50AAce5beE7163D375bF7D6cF65C4e24e61f": 1
      },
      "asks_updated": "2024-06-07T12:35:31.851673794Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f678e7bc372ce719b97f06",
    "name": "lmsys/vicuna-13b-v1.5",
    "display_name": "Vicuna v1.5 (13B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "llama2",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:40:07.763Z",
    "update_at": "2023-09-05T00:40:07.763Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x8C25c0cAC3C50A94Fa1444a843BD3ab684640fc0": 1
      },
      "asks_updated": "2024-06-07T12:55:19.497884957Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "652da26579174a6bc507647f",
    "name": "lmsys/vicuna-7b-v1.5",
    "display_name": "Vicuna v1.5 (7B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738415616,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>",
        "USER:"
      ],
      "add_generation_prompt": true,
      "prompt_format": "USER: {prompt}\nASSISTANT: Hello!",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-16T20:51:49.194Z",
    "update_at": "2023-10-16T20:51:49.194Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x26005D713C76F77e4d79d9e570C6f61181BD3b32": 1
      },
      "asks_updated": "2024-06-07T12:35:10.655969535Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "662acc88b52b87efeb10e471",
    "name": "medaltv/dbrx-instruct",
    "display_name": "Reserved - DBRX Instruct",
    "display_type": "chat",
    "description": "DBRX Instruct is a mixture-of-experts (MoE) large language model trained from scratch by Databricks. DBRX Instruct specializes in few-turn interactions.",
    "license": "Databricks Open Model License",
    "link": "https://huggingface.co/databricks/dbrx-instruct",
    "creator_organization": "Databricks",
    "pricing_tier": "Featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 0,
    "owner_userid": "661824ebb62e2f5ef2bc676e",
    "config": {
      "add_generation_prompt": true,
      "chat_template_name": "default",
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "track_qps": true
    },
    "pricing": {
      "input": 300,
      "output": 300,
      "hourly": 0
    },
    "created_at": "2024-04-10T22:42:06.365Z",
    "update_at": "2024-04-24T19:54:29.506Z",
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulproxy2"
      }
    ],
    "isDedicatedInstance": true,
    "engine": "pulsar",
    "lago_tag": "MIXTRAL_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x62fDE8ce9A119AdA774073c9a42B12029e0e239e": 1
      },
      "asks_updated": "2024-06-07T12:24:48.403283978Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulproxy2",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd9de620478cfa144258",
    "name": "meta-llama/Llama-2-13b-chat-hf",
    "display_name": "LLaMA-2 Chat (13B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "add_generation_prompt": true,
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:00:54.436Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x582Ee7216416721CF6101f0A37098C2741824E4B": 1
      },
      "asks_updated": "2024-06-07T12:50:34.933037578Z",
      "gpus": {
        "": 0
      },
      "qps": 1.9333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 303.8,
      "throughput_out": 239.2,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 2.123478260869565,
          "qps": 1.9333333333333333,
          "throughput_in": 303.8,
          "throughput_out": 239.2,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd03e620478cfa144255",
    "name": "meta-llama/Llama-2-13b-hf",
    "display_name": "LLaMA-2 (13B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ]
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:07:52.318Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4d41543337D4c322a31a0F9913af3C8708876249": 1
      },
      "asks_updated": "2024-06-07T13:00:59.615605933Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd95e620478cfa144257",
    "name": "meta-llama/Llama-2-70b-chat-hf",
    "display_name": "LLaMA-2 Chat (70B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "add_generation_prompt": true,
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2024-04-19T01:11:44.938Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 4,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3105fa4406CE3d38945cb7cCf64507Df471786A1": 1,
        "0x90ccBC08E7707c9905220202be91d7aAcaef3D6e": 1,
        "0xA441c6217681bb6671fB3Fe7907ca5A944839019": 1,
        "0xfE41A105c871BfbB8deED26F6faf1f2E9d0A86f9": 1
      },
      "asks_updated": "2024-06-07T16:43:38.42467559Z",
      "gpus": {
        "": 0
      },
      "qps": 0.5333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 151.93333333333334,
      "throughput_out": 82.26666666666667,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.125,
          "qps": 0.5333333333333333,
          "throughput_in": 151.93333333333334,
          "throughput_out": 82.26666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd0ee620478cfa144256",
    "name": "meta-llama/Llama-2-70b-hf",
    "display_name": "LLaMA-2 (70B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-hf",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ]
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6e39d033CB1ab65F08A901444d638e82e1192cA5": 1,
        "0x77FAd50943503D048795713eFe1e48Af06BCc63f": 1,
        "0xB7F462fEd161Ff92f48aaF2302C2a19fA01FdeB4": 1
      },
      "asks_updated": "2024-06-07T16:59:05.75994826Z",
      "gpus": {
        "": 0
      },
      "qps": 87.06666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 4571,
      "throughput_out": 501.73333333333335,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.6064070124706299,
          "qps": 87.06666666666666,
          "throughput_in": 4571,
          "throughput_out": 501.73333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dda7e620478cfa144259",
    "name": "meta-llama/Llama-2-7b-chat-hf",
    "display_name": "LLaMA-2 Chat (7B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "add_generation_prompt": true,
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      },
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      },
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x05655a9b3C902ceC9a13CfB61bc8f1FAfCdE7Aa8": 1,
        "0x0c409751A39422fb09dbd0DB2EE0a2E69Bb29f40": 1,
        "0x2701d6319108F711a8e435E3778340E359b8eaEd": 1
      },
      "asks_updated": "2024-06-07T16:28:53.942232216Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 2.6,
      "throughput_out": 42.13333333333333,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.05,
          "qps": 0.06666666666666667,
          "throughput_in": 2.6,
          "throughput_out": 42.13333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.05,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6db78e620478cfa144254",
    "name": "meta-llama/Llama-2-7b-hf",
    "display_name": "LLaMA-2 (7B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ]
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xcB7b7e511ce531eE479367a6A1a1F49A7D1A5aF1": 1
      },
      "asks_updated": "2024-06-07T13:00:59.940486256Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6620daf44b2da307838b7cf1",
    "name": "meta-llama/Llama-3-70b-chat-hf",
    "display_name": "Meta Llama 3 70B Chat",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:33:56.492Z",
    "update_at": "2024-04-24T19:06:49.423Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      },
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      },
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 8,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x175329F90d700c86273A16d57F70aC86a5ba659d": 1,
        "0x3A40472b9a29DEF347E71BA7b2884D965b7A4B64": 1,
        "0x3bC1D1C8572e85462C9Cfff2De7ef53E85EFd83f": 1,
        "0x4b18c4b317A6de51e5d62e45773453Ab71b824E4": 1,
        "0x58050E417E84F8721812F0c90fC02C6B6d4E2BB1": 1,
        "0x6f0361308E98eb31a725C5fe78c6204613BFa54D": 1,
        "0x8Af8Dd07DC48Dff5b6D30d8Bc03c681A9d677162": 1,
        "0xC1Cc2F6Fb8F0b772350fC7f1E9a1A6400F76a996": 1,
        "0xD8BF16e9d80C670100835B7FD803B4C0929644D9": 1,
        "0xE29b1E1F64EcbE790CCE5CCE794763783c3BC258": 1,
        "0xf11b5371Ab1495BA6ca6d108eAdDe9806Fbf14b3": 1
      },
      "asks_updated": "2024-06-07T16:32:52.716369422Z",
      "gpus": {
        "": 0
      },
      "qps": 25.266666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 13370.666666666664,
      "throughput_out": 7320.0666666666675,
      "error_rate": 0.9333333333333335,
      "retry_rate": 0.7333333333333334,
      "stats": [
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.49045698924731185,
          "qps": 11.2,
          "throughput_in": 6388.266666666666,
          "throughput_out": 3857.0666666666666,
          "error_rate": 0.2,
          "retry_rate": 0.4
        },
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.44142670157068065,
          "qps": 3.8,
          "throughput_in": 1907.6666666666667,
          "throughput_out": 812.8,
          "error_rate": 0.13333333333333333,
          "retry_rate": 0.06666666666666667
        },
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0.4405940594059406,
          "qps": 2.2,
          "throughput_in": 896.9333333333333,
          "throughput_out": 775.8,
          "error_rate": 0.2,
          "retry_rate": 0.06666666666666667
        },
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.5008741258741258,
          "qps": 8.066666666666666,
          "throughput_in": 4177.8,
          "throughput_out": 1874.4,
          "error_rate": 0.4,
          "retry_rate": 0.2
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "665a6fc497c7c4bc481aa629",
    "name": "meta-llama/Llama-3-70b-hf",
    "serviceName": "meta-llama/Meta-Llama-3-70B",
    "display_name": "Meta Llama 3 70B",
    "display_type": "language",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "llama3",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-70B",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": null,
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:34:27.131Z",
    "update_at": "2024-04-18T08:34:27.131Z",
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xd5e1aF5db44Be406f16CE289e4EFFF79503dBEA4": 1
      },
      "asks_updated": "2024-06-07T12:38:56.74326512Z",
      "gpus": {
        "": 0
      },
      "qps": 6.1960814e-12,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1.2788703e-7,
      "throughput_out": 6.2108643e-9
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6620b8bf4b2da307838b7cf0",
    "name": "meta-llama/Llama-3-8b-chat-hf",
    "display_name": "Meta Llama 3 8B Chat",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T06:07:59.041Z",
    "update_at": "2024-04-24T19:14:26.075Z",
    "instances": [
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      },
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      },
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x72F44c091b76bE06217Bc1FE240F494a80aE76Ad": 1,
        "0x81cca3d78c6B72489Afbd587e393aE0d2b97A33c": 1,
        "0xD6e3470e3d0904E7018E655ec84385053C0dFF9E": 1
      },
      "asks_updated": "2024-06-07T13:10:35.581740947Z",
      "gpus": {
        "": 0
      },
      "qps": 35,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 23900.266666666666,
      "throughput_out": 726.4666666666667,
      "stats": [
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.21882458233890215,
          "qps": 9.666666666666666,
          "throughput_in": 5953.066666666667,
          "throughput_out": 199.13333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0.22068363273453093,
          "qps": 13.933333333333334,
          "throughput_in": 9400.4,
          "throughput_out": 268.3333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.22453222453222454,
          "qps": 11.4,
          "throughput_in": 8546.8,
          "throughput_out": 259,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6620db1d4b2da307838b7cf3",
    "name": "meta-llama/Llama-3-8b-hf",
    "display_name": "Meta Llama 3 8B HF",
    "display_type": "language",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "owner_userid": null,
    "config": null,
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:34:37.676Z",
    "update_at": "2024-04-18T09:12:37.169Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x050037E2D27C826eC7023868FD2A7bc3d3A76329": 1,
        "0x066C27df8D0d174e097462789182AfF9c90f9f53": 1,
        "0x74049692cFE55bA343E3a4AEA34Bc1Bef566683D": 1
      },
      "asks_updated": "2024-06-07T16:35:06.219720254Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.024390243902439025,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "66215c615f70248d1cd89d9f",
    "name": "meta-llama/LlamaGuard-2-8b",
    "display_name": "Meta Llama Guard 2 8B",
    "display_type": "moderation",
    "description": "",
    "license": "Llama-3 (Other)",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "chat_template": "{% if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set final_role = 'User' %}{% endif %}[INST] Task: Check if there is unsafe content in '{{ final_role }}' messages in conversations according our safety policy with the below categories.\n\n<BEGIN UNSAFE CONTENT CATEGORIES>\nS1: Violent Crimes.\nS2: Non-Violent Crimes.\nS3: Sex Crimes.\nS4: Child Exploitation.\nS5: Specialized Advice.\nS6: Privacy.\nS7: Intellectual Property.\nS8: Indiscriminate Weapons.\nS9: Hate.\nS10: Self-Harm.\nS11: Sexual Content.\n<END UNSAFE CONTENT CATEGORIES>\n\n<BEGIN CONVERSATION>\n\n{% for message in messages %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim() }}{% else %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{ '\n\n' }}{% endfor %}<END CONVERSATION>\n\nProvide your safety assessment for ONLY THE LAST {{ role }} message in the above conversation:\n - First line must read 'safe' or 'unsafe'.\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]",
      "safety_label": "safe",
      "safe_response": true,
      "safety_config": {
        "max_tokens": 64
      },
      "safety_categories": {
        "S1": "Violent Crimes",
        "S2": "Non-Violent Crimes",
        "S3": "Sex Crimes",
        "S4": "Child Exploitation",
        "S5": "Specialized Advice",
        "S6": "Privacy",
        "S7": "Intellectual Property",
        "S8": "Indiscriminate Weapons",
        "S9": "Hate",
        "S10": "Self-Harm",
        "S11": "Sexual Content"
      }
    },
    "pricing": {
      "hourly": 0,
      "input": 50,
      "output": 50
    },
    "created_at": "2024-04-18T08:36:20.125Z",
    "update_at": "2024-05-15T20:38:23.297Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "isSelfServeDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 4,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x236E7e401FD2304faFbf836b72aDF0Bba8754Ed4": 1,
        "0x92D225054AC120b8F566EaA6b2D850A86eA15E7f": 1,
        "0x9481391A48f1d6F7199Fba99C2B12d0291EB54c3": 1,
        "0xB24e7d683032466ce5C4C76853Bd35e83F0638c7": 1
      },
      "asks_updated": "2024-06-07T16:29:25.332006461Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6620db134b2da307838b7cf2",
    "name": "meta-llama/Meta-Llama-3-70B",
    "display_name": "Meta Llama 3 70B",
    "display_type": "language",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-70B",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "owner_userid": null,
    "config": null,
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:34:27.131Z",
    "update_at": "2024-04-18T08:34:27.131Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xF22c42FB37BEd821f46b1DF5f8539faE436e79F1": 1
      },
      "asks_updated": "2024-06-07T12:38:13.740589352Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 120.93333333333334,
      "throughput_out": 14.333333333333334,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.044444444444444446,
          "qps": 0.13333333333333333,
          "throughput_in": 120.93333333333334,
          "throughput_out": 14.333333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6631647fc3b4aab9202b12e0",
    "name": "meta-llama/Meta-Llama-3-8B",
    "serviceName": "meta-llama/Llama-3-8b-hf",
    "display_name": "Meta Llama 3 8B",
    "display_type": "language",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": null,
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:34:37.676Z",
    "update_at": "2024-04-18T09:12:37.169Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5EcF6C0a0000ea80215C3F972b3Df4Be51547356": 1,
        "0xA0E3693444101cb7F1031071550B859Bf8Ce1851": 1,
        "0xd7e17B1e166Ebf9C4500fa3e44724ec4e988D654": 1
      },
      "asks_updated": "2024-06-07T16:37:27.03671915Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "661d747e2bfa86bd832690c1",
    "name": "microsoft/WizardLM-2-8x22B",
    "display_name": "WizardLM-2 (8x22B)",
    "display_type": "chat",
    "description": "WizardLM-2 8x22B is Wizard's most advanced model, demonstrates highly competitive performance compared to those leading proprietary works and consistently outperforms all the existing state-of-the-art opensource models.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/microsoft/WizardLM-2-8x22B",
    "creator_organization": "microsoft",
    "pricing_tier": "Featured",
    "num_parameters": 141000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 65536,
    "owner_userid": null,
    "config": {
      "prompt_format": null,
      "stop": [
        "</s>"
      ],
      "chat_template": "{{ bos_token }}{% for message in messages %}{% if message['role'] == 'system' %}{{ message['content'] + ' ' }}{% elif message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + eos_token + '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ 'ASSISTANT: ' }}{% endif %}",
      "add_generation_prompt": true,
      "bos_token": "<s>",
      "eos_token": "</s>"
    },
    "pricing": {
      "input": 300,
      "output": 300,
      "hourly": 0
    },
    "created_at": "2024-04-15T18:39:58.959Z",
    "update_at": "2024-04-15T18:39:58.959Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      },
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "lago_tag": "MIXTRAL_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0c750AAbc339e78b10e8D565d0C2B53506842f34": 1,
        "0xCcDe20ff452C561C9ae1EfCb466B2d8347Aa47Ad": 1,
        "0xe82fd7645e8520bbB23989fda5d89B3014089d91": 1
      },
      "asks_updated": "2024-06-07T16:30:43.624736275Z",
      "gpus": {
        "": 0
      },
      "qps": 0.6666666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 7322.533333333333,
      "throughput_out": 200.33333333333331,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.8125,
          "qps": 0.3333333333333333,
          "throughput_in": 3334.2,
          "throughput_out": 96.86666666666666,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.5714285714285714,
          "qps": 0.26666666666666666,
          "throughput_in": 3767,
          "throughput_out": 86.8,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.41657014376234924,
          "qps": 0.06666666666666667,
          "throughput_in": 221.33333333333334,
          "throughput_out": 16.666666666666668,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b40661251b2ff9f146d8ba",
    "name": "microsoft/phi-2",
    "display_name": "Microsoft Phi-2",
    "display_type": "language",
    "description": "Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (for safety and educational value)",
    "license": "mit",
    "link": "https://huggingface.co/microsoft/phi-2",
    "creator_organization": "Microsoft",
    "pricing_tier": "Featured",
    "num_parameters": 2700000000,
    "release_date": "2024-01-26T19:22:09.533Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-01-26T19:22:09.533Z",
    "update_at": "2024-01-26T19:23:46.072Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3faDed538E22aD5203eb6335795fcd386E6Ad4C0": 1
      },
      "asks_updated": "2024-06-07T16:42:59.860988279Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.024390243902439025,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6514c873829715ded9cd17b1",
    "name": "mistralai/Mistral-7B-Instruct-v0.1",
    "display_name": "Mistral (7B) Instruct",
    "display_type": "chat",
    "description": "instruct fine-tuned version of Mistral-7B-v0.1",
    "license": "Apache-2",
    "creator_organization": "mistralai",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 7241732096,
    "release_date": "2023-09-27T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "add_generation_prompt": true,
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "prompt_format": "<s>[INST] {prompt} [/INST]",
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-09-28T00:27:31.815Z",
    "update_at": "2023-10-12T01:13:51.840Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2940b4a8aC66Ea56De5E30E1b8117b1A2840183C": 1,
        "0xF7F21f536007A2a607c4Fc90d0e3f0bc3f29666d": 1,
        "0xaCCF3640229EDB4d5Eec4F24aba8000b18F5FE41": 1
      },
      "asks_updated": "2024-06-07T16:44:31.192784699Z",
      "gpus": {
        "": 0
      },
      "qps": 11.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 2082.6,
      "throughput_out": 1165.6,
      "retry_rate": 0.06666666666666667,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.5554123711340206,
          "qps": 11.4,
          "throughput_in": 2082.6,
          "throughput_out": 1165.6,
          "error_rate": 0,
          "retry_rate": 0.06666666666666667
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65776c7d6923087ddd5a660a",
    "name": "mistralai/Mistral-7B-Instruct-v0.2",
    "display_name": "Mistral (7B) Instruct v0.2",
    "display_type": "chat",
    "description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1.",
    "license": "apache-2.0",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama",
      "tools_template": "{{ 'If you need to invoke any of the following functions:\n' + tools + '\nplease respond in the following JSON format:\n[\n\n  {\n    \"name\": \"the name of the function to be invoked\",\n    \"arguments\": {\"key1\": \"value1\", \"key2\": \"value2\", ...}\n  }\n]\nIf any required arguments are missing, please ask for them without JSON function calls.\nIf the instruction does not necessitate a function call, please provide your response in clear, concise natural language.\n\n' + message['content'] }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-12-11T20:09:33.627Z",
    "update_at": "2023-12-11T20:09:33.627Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "hardware_label": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x00a946dC68cDD27C10dB05cDB120A923DB3BB8d4": 1
      },
      "asks_updated": "2024-06-07T11:29:44.097705354Z",
      "gpus": {
        "": 0
      },
      "qps": 1.3333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 4672.533333333334,
      "throughput_out": 190.2,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.22150072150072145,
          "qps": 1.3333333333333333,
          "throughput_in": 4672.533333333334,
          "throughput_out": 190.2,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "664e47f5b4be29d59d4e7f70",
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "display_name": "Mistral (7B) Instruct v0.3",
    "display_type": "chat",
    "description": "The Mistral-7B-Instruct-v0.3 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.3.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3",
    "creator_organization": "mistralai",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "owner_userid": null,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama",
      "bos_token": "<s>",
      "eos_token": "</s>"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-05-22T19:31:01.920Z",
    "update_at": "2024-05-22T19:31:01.920Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "isFinetuned": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6228bA4363a5E419f6665A44875BD722cfcB2993": 1,
        "0xdEbc4EF6f7042A7e14BcCD0Eb8c9bA9a83C3b952": 1
      },
      "asks_updated": "2024-06-07T16:56:27.696291653Z",
      "gpus": {
        "": 0
      },
      "qps": 1.5333333333333334,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 3499.6,
      "throughput_out": 587.0666666666667,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.1934343434343434,
          "qps": 1.5333333333333334,
          "throughput_in": 3499.6,
          "throughput_out": 587.0666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6514c6ee829715ded9cd17b0",
    "name": "mistralai/Mistral-7B-v0.1",
    "display_name": "Mistral (7B)",
    "display_type": "language",
    "description": "7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost",
    "license": "Apache-2",
    "creator_organization": "mistralai",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 7241732096,
    "release_date": "2023-09-27T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "{prompt}",
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-09-28T00:21:02.330Z",
    "update_at": "2023-09-28T00:21:02.330Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5a5E928538914B96C7EC31617cD026F8C92F7ad8": 1
      },
      "asks_updated": "2024-06-07T16:24:22.580685709Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6620059786c156450dc1e445",
    "name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "display_name": "Mixtral-8x22B Instruct v0.1",
    "display_type": "chat",
    "description": "The Mixtral-8x22B-Instruct-v0.1 Large Language Model (LLM) is an instruct fine-tuned version of the Mixtral-8x22B-v0.1.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "num_parameters": 141000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 65536,
    "owner_userid": null,
    "config": {
      "stop": [
        "</s>",
        "[/INST]"
      ],
      "chat_template": "{{bos_token}}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ ' [INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\n' + content + '\n<</SYS>>\n\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}",
      "bos_token": "<s>",
      "eos_token": "</s>"
    },
    "pricing": {
      "input": 300,
      "output": 300,
      "hourly": 0
    },
    "created_at": "2024-04-17T17:23:35.226Z",
    "update_at": "2024-05-03T01:20:25.932Z",
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      },
      {
        "avzone": "eu-central-1a",
        "cluster": "merrymeerkat"
      },
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "lago_tag": "MIXTRAL_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 4,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0d23D3C623ed85942E3e521C45f6513161F7F97d": 1,
        "0x1957EC67F82731dA9F19fc961883f78874a2375C": 1,
        "0x7836fAe4C57bC9e3ff0b84E39117B7D0E565E735": 1,
        "0xB2091d3D7166e8BA28a835AF2a2Ec4d71e774f8D": 1,
        "0xC74A7AfbDB022037D170029089bb654C93AE7D24": 1,
        "0xF081B01E37A100ff8E1ef380C6D8Dd29098355D2": 1
      },
      "asks_updated": "2024-06-07T16:55:05.055394624Z",
      "gpus": {
        "": 0
      },
      "qps": 17.866666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 2900.866666666667,
      "throughput_out": 796.3333333333334,
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.6117109634551495,
          "qps": 5.666666666666667,
          "throughput_in": 764.8,
          "throughput_out": 267.2,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "eu-central-1a",
          "cluster": "merrymeerkat",
          "capacity": 0.6268796992481203,
          "qps": 2.933333333333333,
          "throughput_in": 562.9333333333333,
          "throughput_out": 121.4,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.7286995515695067,
          "qps": 9.266666666666667,
          "throughput_in": 1573.1333333333334,
          "throughput_out": 407.73333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "66165fa701f2f8a98997bf8e",
    "name": "mistralai/Mixtral-8x22B",
    "display_name": "Mixtral-8x22B",
    "display_type": "language",
    "description": "The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.",
    "license": "apache-2.0",
    "link": "",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "num_parameters": 138000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 65536,
    "owner_userid": null,
    "config": {
      "prompt_format": null,
      "stop": [
        "</s>"
      ],
      "chat_template_name": null,
      "chat_template": null
    },
    "pricing": {
      "input": 300,
      "output": 300,
      "hourly": 0
    },
    "created_at": "2024-04-10T09:45:11.291Z",
    "update_at": "2024-04-10T09:45:11.291Z",
    "instances": [
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "lago_tag": "MIXTRAL_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xD18EEA953bC6A04890d44dB0a363612E4c3bb149": 1
      },
      "asks_updated": "2024-06-07T13:12:26.624888332Z",
      "gpus": {
        "": 0
      },
      "qps": 6.533333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 10397.066666666668,
      "throughput_out": 52.06666666666667,
      "stats": [
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 1.86672499270925,
          "qps": 6.533333333333333,
          "throughput_in": 10397.066666666668,
          "throughput_out": 52.06666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6577af4434e6c1e2bb5283d8",
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "display_name": "Mixtral-8x7B Instruct v0.1",
    "display_type": "chat",
    "description": "The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2023-12-12T00:54:28.108Z",
    "update_at": "2024-02-08T07:58:24.624Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      },
      {
        "avzone": "us-south-1a",
        "cluster": "mustymarfa"
      },
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulproxy2"
      }
    ],
    "lago_tag": "MIXTRAL_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 7,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1A414d6a7Fc2E80C209c6804C30833C7941ECe8F": 1,
        "0x1f9b37D43762A2E68f79f27037970F252Ae9dc72": 1,
        "0x304C274001CFe1eE95a69F28aC7Bd2DE696Fe31F": 1,
        "0x331ad91912c531dCC1c9dF21d624D05A83FA8798": 1,
        "0x38f0341a728Ea5B392c68Fa3a3028e8FfEEADf21": 1,
        "0x3Fb77Dfc9Fb62f547C877eeD099836F714862e75": 1,
        "0xDc4d873003AE654ed69d4B2c460d9525F0B82322": 1,
        "0xEdb6fdfbcb1Fb0438275066e5314D44252A54A5c": 1,
        "0xd40bD5046cfDC4AcB83DD0c37c0Bae8761c77785": 1
      },
      "asks_updated": "2024-06-07T16:24:38.81958588Z",
      "gpus": {
        "": 0
      },
      "qps": 14.599999999999998,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 10612.933333333332,
      "throughput_out": 1731.5333333333333,
      "stats": [
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0.4641749379652614,
          "qps": 5.866666666666666,
          "throughput_in": 3908.133333333333,
          "throughput_out": 648.5333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-south-1a",
          "cluster": "mustymarfa",
          "capacity": 0.5052344105598546,
          "qps": 5.466666666666667,
          "throughput_in": 3825.2,
          "throughput_out": 605.8666666666667,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulproxy2",
          "capacity": 0.08949704142011829,
          "qps": 3.2666666666666666,
          "throughput_in": 2879.6,
          "throughput_out": 477.1333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6577bf1034e6c1e2bb5283d9",
    "name": "mistralai/Mixtral-8x7B-v0.1",
    "display_name": "Mixtral-8x7B v0.1",
    "display_type": "language",
    "description": "The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2023-12-12T02:01:52.674Z",
    "update_at": "2024-02-08T07:58:39.848Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulproxy2"
      }
    ],
    "lago_tag": "MIXTRAL_MODEL",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xc261f35de549E945122BFd444d947873cb8ca48c": 1
      },
      "asks_updated": "2024-06-07T00:40:43.440248576Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulproxy2",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657b7a2a84ef58c3562de91e",
    "name": "openchat/openchat-3.5-1210",
    "display_name": "OpenChat 3.5",
    "display_type": "chat",
    "description": "A merge of OpenChat 3.5 was trained with C-RLFT on a collection of publicly available high-quality instruction data, with a custom processing pipeline.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/openchat/openchat-3.5-1210",
    "creator_organization": "OpenChat",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "7000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'] + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
      "stop": [
        "<|end_of_turn|>",
        "</s>"
      ],
      "add_generation_prompt": true,
      "bos_token": "<s>",
      "prompt_format": "GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-12-14T21:56:58.576Z",
    "update_at": "2023-12-14T21:56:58.576Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2Ad2D29aa1a8Db36549bb5baceE37d623592d40B": 1
      },
      "asks_updated": "2024-06-07T13:38:50.299479065Z",
      "gpus": {
        "": 0
      },
      "qps": 0.6,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 461.8666666666667,
      "throughput_out": 52.266666666666666,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.032432432432432434,
          "qps": 0.6,
          "throughput_in": 461.8666666666667,
          "throughput_out": 52.266666666666666,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aced5c227f790586239d2b",
    "name": "prompthero/openjourney",
    "display_name": "Openjourney v4",
    "display_type": "image",
    "description": "An open source Stable Diffusion model fine tuned model on Midjourney images. ",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/prompthero/openjourney",
    "creator_organization": "Prompt Hero",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 512,
      "width": 512,
      "number_of_images": 2,
      "steps": 20,
      "seed": 42
    },
    "pricing": {
      "hourly": 0,
      "input": 75,
      "output": 75
    },
    "created_at": "2023-07-11T05:49:16.586Z",
    "update_at": "2024-05-23T20:54:38.912Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85": 1,
        "0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556": 1
      },
      "asks_updated": "2024-06-07T12:01:44.652026674Z",
      "gpus": {
        "NVIDIA A40": 2
      },
      "options": {
        "input=text,image": 2
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.02,
          "qps": 0.06666666666666667,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece1",
    "name": "runwayml/stable-diffusion-v1-5",
    "display_name": "Stable Diffusion 1.5",
    "display_type": "image",
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/runwayml/stable-diffusion-v1-5",
    "creator_organization": "Runway ML",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 512,
      "width": 512,
      "number_of_images": 2,
      "steps": 20,
      "seed": 42
    },
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-06-23T20:22:43.572Z",
    "update_at": "2024-05-23T20:45:43.938Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "access": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8": 1
      },
      "asks_updated": "2024-06-07T16:24:08.150167231Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65460075c5ce2e5fa70d6721",
    "name": "sentence-transformers/msmarco-bert-base-dot-v5",
    "display_name": "Sentence-BERT",
    "display_type": "embedding",
    "description": "A sentence-transformers model: it maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/sentence-transformers/msmarco-bert-base-dot-v5",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 110000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 512,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T08:27:33.867Z",
    "update_at": "2023-12-22T03:15:44.832Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1a1b0dB24Fdfd5E05AF9177A80fbB0C049a3b63b": 1,
        "0x662c7EE2ca9D3D4fAbcEE2286C1bbc5f24CA02fD": 1,
        "0x834Dfa4EeF072100CcBC96fA3871d6f62Ce02455": 1
      },
      "asks_updated": "2024-06-07T16:41:47.171995643Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b454f3d9877b0bd1376470",
    "name": "snorkelai/Snorkel-Mistral-PairRM-DPO",
    "display_name": "Snorkel Mistral PairRM DPO (7B)",
    "display_type": "chat",
    "description": "A state-of-the-art model by Snorkel AI, DPO fine-tuned on Mistral-7B",
    "license": "apache-2.0",
    "creator_organization": "Snorkel AI",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2024-01-27T00:57:23.638Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-01-27T00:57:23.638Z",
    "update_at": "2024-01-27T14:24:41.745Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x905d9333Bf36FC9fD26b130adaaEe6f5Bd4E800f": 1
      },
      "asks_updated": "2024-06-07T13:04:29.921319648Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1111111111111111,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "653c053fd9679a84df55c4e7",
    "name": "teknium/OpenHermes-2-Mistral-7B",
    "display_name": "OpenHermes-2-Mistral (7B)",
    "display_type": "chat",
    "description": "State of the art Mistral Fine-tuned on extensive public datasets",
    "license": "Apache-2",
    "creator_organization": "teknium",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-10-27T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "pre_prompt": "<|im_start|>system\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-27T18:45:19.307Z",
    "update_at": "2023-10-27T23:53:05.438Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x24e7c0F944a664e4be6890a13Ce3cB0b930a2d9b": 1
      },
      "asks_updated": "2024-06-07T16:25:51.030886046Z",
      "gpus": {
        "": 0
      },
      "qps": 0.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 426.1333333333333,
      "throughput_out": 39.4,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.15625,
          "qps": 0.4,
          "throughput_in": 426.1333333333333,
          "throughput_out": 39.4,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655667fe6664bf7229b2dc6c",
    "name": "teknium/OpenHermes-2p5-Mistral-7B",
    "display_name": "OpenHermes-2.5-Mistral (7B)",
    "display_type": "chat",
    "description": "Continuation of OpenHermes 2 Mistral model trained on additional code datasets",
    "license": "Apache-2",
    "creator_organization": "teknium",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-16T19:05:34.976Z",
    "update_at": "2023-11-16T19:12:24.883Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x478820b73D0745eBFB0E01a0de2c989dA2bC2fD8": 1,
        "0xEEdD37e6A2fcDA184669cf69919ad501F3322796": 1
      },
      "asks_updated": "2024-06-07T16:40:51.580645637Z",
      "gpus": {
        "": 0
      },
      "qps": 4.266666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 4183.6,
      "throughput_out": 353.73333333333335,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.5242290748898679,
          "qps": 4.266666666666667,
          "throughput_in": 4183.6,
          "throughput_out": 353.73333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece3",
    "name": "togethercomputer/GPT-JT-Moderation-6B",
    "display_name": "GPT-JT-Moderation (6B)",
    "display_type": "language",
    "description": "This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 6700000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template": "Possible labels:\n1. casual\n2. needs caution\n3. needs intervention\n4. possibly needs caution\n5. probably needs caution\nInput: Hi!\nOutput: casual\nInput: I want to kill my cat.\nOutput: needs intervention\nInput: How to poison my dog?\nOutput: needs intervention\nInput: I don't want to talk to my brother\nOutput: probably needs caution\nInput: Today we had a disagreement and  \nwe got into a screaming fight. I don't want to talk.\nOutput: probably needs caution\nInput: My brother is being an asshole... Fuck him.\nOutput: needs caution\nInput: Hello.\nOutput: casual\nInput: {% for message in messages %}{{ message.content }}{{ eos_token }}{% endfor %}\nOutput:",
      "safety_label": "casual",
      "safety_config": {
        "temperature": 0.2,
        "top_p": 1,
        "max_tokens": 10,
        "stop": [
          "\n"
        ]
      }
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.657Z",
    "update_at": "2023-06-23T20:22:43.657Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "testytiger"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3B2a3D16B0207aA9F14726eeE8cD0b9b388209A2": 1
      },
      "asks_updated": "2024-06-07T13:01:35.065042612Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 2.3333333333333335,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "testytiger",
          "capacity": 0.05,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 2.3333333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64c28e8742fa06a9511509d1",
    "name": "togethercomputer/LLaMA-2-7B-32K",
    "display_name": "LLaMA-2-32K (7B)",
    "display_type": "language",
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.",
    "license": "Meta license",
    "link": "https://huggingface.co/togethercomputer/LLaMA-2-7B-32K",
    "creator_organization": "Together",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": [
        "\n\n\n\n",
        "<|endoftext|>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-27T15:34:31.581Z",
    "update_at": "2023-08-17T17:07:36.346Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x371EAf96c8Ee3BA499F0288c75c75d51112b2527": 1
      },
      "asks_updated": "2024-06-07T12:35:11.976655876Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64de96090d052d10425df3c9",
    "name": "togethercomputer/Llama-2-7B-32K-Instruct",
    "display_name": "LLaMA-2-7B-32K-Instruct (7B)",
    "display_type": "chat",
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together",
    "license": "Meta license",
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "creator_organization": "Together",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST]\n {prompt} \n[/INST]\n\n",
      "stop": [
        "[INST]",
        "\n\n"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-27T15:34:31.581Z",
    "update_at": "2023-08-17T17:07:36.346Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 6,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0e9968a2325f3f5E0B65BE71066035E5c616BaB7": 1,
        "0xE29cd82da3A87FCA7A367eCdD84e805cF982e507": 1,
        "0xE71B4F070af5065b151a1fd6849F648Be9089484": 1,
        "0xF6e5D44C0739C68e97afddb581bC295F2807d9d6": 1,
        "0xf5188ffeAd0FB37F0C0BB625824252029B4BF78d": 1,
        "0xfa66a48eA14D80e094D57E0ECdF22Fc0B397D193": 1
      },
      "asks_updated": "2024-06-07T16:29:01.54716074Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 1,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aeceb",
    "name": "togethercomputer/RedPajama-INCITE-7B-Base",
    "display_name": "RedPajama-INCITE (7B)",
    "display_type": "language",
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/redpajama-models-v1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.033Z",
    "update_at": "2023-06-23T20:22:44.033Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3665A75f9d8F32a7721B1b43c4CA2eC18F7bdDD3": 1
      },
      "asks_updated": "2024-06-07T00:40:43.624325219Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aeced",
    "name": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "display_name": "RedPajama-INCITE Chat (7B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat",
    "creator_organization": "Together",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": [
        "<human>"
      ],
      "chat_template_name": "gpt",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.190Z",
    "update_at": "2023-06-23T20:22:44.190Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5e066227A1e7f634cAEFaDc21527340A7E33a8d5": 1
      },
      "asks_updated": "2024-06-07T16:40:46.393310615Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 0.4666666666666667,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 0.4666666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecec",
    "name": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "display_name": "RedPajama-INCITE Instruct (7B)",
    "display_type": "language",
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct",
    "creator_organization": "Together",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.083Z",
    "update_at": "2023-06-23T20:22:44.083Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xf692d4ef74617ec76153cC5D32C3b8b9bD5D2B2C": 1
      },
      "asks_updated": "2024-06-07T16:39:13.098808317Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece5",
    "name": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "display_name": "RedPajama-INCITE (3B)",
    "display_type": "language",
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/redpajama-models-v1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.751Z",
    "update_at": "2023-06-23T20:22:43.751Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe03dDF7b87500172ec519A5cf7982166CB27446d": 1
      },
      "asks_updated": "2024-06-07T00:40:43.361681042Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece7",
    "name": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "display_name": "RedPajama-INCITE Chat (3B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "add_generation_prompt": true,
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": [
        "<human>"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.839Z",
    "update_at": "2023-06-23T20:22:43.839Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4e6FE2a25309efA6b3279d5FacceA7393Bce9d7d": 1
      },
      "asks_updated": "2024-06-07T00:40:45.230139716Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece6",
    "name": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "display_name": "RedPajama-INCITE Instruct (3B)",
    "display_type": "language",
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.796Z",
    "update_at": "2023-06-23T20:22:43.796Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x05DcC82776d9dE9f88714a57489F55Fe629253Df": 1
      },
      "asks_updated": "2024-06-07T00:40:43.630770909Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65735df36923087ddd5a6607",
    "name": "togethercomputer/StripedHyena-Hessian-7B",
    "display_name": "StripedHyena Hessian (7B)",
    "display_type": "language",
    "description": "A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers",
    "license": "Apache-2",
    "creator_organization": "Together",
    "hardware_label": "H100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-12-08T18:18:27.005Z",
    "update_at": "2023-12-08T19:03:32.567Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x67950b5BFae9be9c326c098be6ED4C6eBfDF21AC": 1
      },
      "asks_updated": "2024-06-07T16:24:54.07929361Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.03571428571428571,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65735d536923087ddd5a6606",
    "name": "togethercomputer/StripedHyena-Nous-7B",
    "display_name": "StripedHyena Nous (7B)",
    "display_type": "chat",
    "description": "A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers",
    "license": "Apache-2",
    "creator_organization": "Together",
    "hardware_label": "H100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": [
        "###",
        "</s>"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ bos_token + '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n'  + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-12-08T18:15:47.433Z",
    "update_at": "2023-12-08T19:03:11.497Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xDf09DC5Df2B0116b09cB52E358e1bAbdE797c383": 1
      },
      "asks_updated": "2024-06-07T13:34:15.396359314Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.05263157894736842,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace317227f790586239ce2",
    "name": "togethercomputer/alpaca-7b",
    "display_name": "Alpaca (7B)",
    "display_type": "chat",
    "description": "Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ",
    "license": "cc-by-nc-4.0",
    "link": "https://huggingface.co/tatsu-lab/alpaca-7b-wdiff",
    "creator_organization": "Stanford",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>",
        "###"
      ],
      "add_generation_prompt": true,
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:05:27.713Z",
    "update_at": "2023-07-11T05:05:27.713Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xCDb16b84A6C85ceEa98b9A423fFc3DB6c94B79ba": 1
      },
      "asks_updated": "2024-06-07T16:22:46.777327262Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65df8df823e6726c2d053851",
    "name": "togethercomputer/evo-1-131k-base",
    "display_name": "Evo-1 Base (131K)",
    "display_type": "language",
    "description": "Evo is a biological foundation model capable of long-context modeling and design. Evo uses the StripedHyena architecture to enable modeling of sequences at a single-nucleotide, byte-level resolution with near-linear scaling of compute and memory relative to context length. Evo has 7 billion parameters and is trained on OpenGenome, a prokaryotic whole-genome dataset containing ~300 billion tokens.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/evo-1-131k-base",
    "creator_organization": "Together",
    "pricing_tier": "Featured",
    "num_parameters": 6450000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 131073,
    "pricing": {
      "input": 500,
      "output": 500,
      "hourly": 0
    },
    "created_at": "2024-02-28T19:48:08.106Z",
    "update_at": "2024-02-28T19:48:08.106Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "lago_tag": "GENOMIC_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4CA359906B109c602347356fF068c8B8d4309fc1": 1,
        "0xc9154531635660098fF4636a887C94320549caa0": 1
      },
      "asks_updated": "2024-06-07T16:39:04.772573539Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65df8d9623e6726c2d053850",
    "name": "togethercomputer/evo-1-8k-base",
    "display_name": "Evo-1 Base (8K)",
    "display_type": "language",
    "description": "Evo is a biological foundation model capable of long-context modeling and design. Evo uses the StripedHyena architecture to enable modeling of sequences at a single-nucleotide, byte-level resolution with near-linear scaling of compute and memory relative to context length. Evo has 7 billion parameters and is trained on OpenGenome, a prokaryotic whole-genome dataset containing ~300 billion tokens.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/evo-1-8k-base",
    "creator_organization": "Together",
    "pricing_tier": "Featured",
    "num_parameters": 6450000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "pricing": {
      "input": 500,
      "output": 500,
      "hourly": 0
    },
    "created_at": "2024-02-28T19:46:30.585Z",
    "update_at": "2024-04-19T18:58:00.962Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "lago_tag": "GENOMIC_MODEL",
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x80D5014da1fBfBe7069d979125Ebc6EFB4e21446": 1
      },
      "asks_updated": "2024-06-07T11:17:12.199128808Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6553b8da6664bf7229b2dbfb",
    "name": "togethercomputer/m2-bert-80M-2k-retrieval",
    "display_name": "M2-BERT-Retrieval-2K",
    "display_type": "embedding",
    "description": "M2-BERT from the Monarch Mixer paper fine-tuned for retrieval",
    "license": "Apache-2",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "num_parameters": 80000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-14T18:13:46.901Z",
    "update_at": "2024-02-21T20:06:27.968Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x49c8561e8042ef95A4b011A0AB216d6171aAb80a": 1
      },
      "asks_updated": "2024-06-07T00:40:42.992900656Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6585058be7e2e898e81b5401",
    "name": "togethercomputer/m2-bert-80M-32k-retrieval",
    "display_name": "M2-BERT-Retrieval-32k",
    "display_type": "embedding",
    "description": "The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 80000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T17:57:24.532Z",
    "update_at": "2023-11-04T17:57:24.532Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x14FBC3086CC17Fe1090141fCCe147948e6A5e803": 1,
        "0xc6B6cfB1A480437a012553De16eD296a73a8fB68": 1,
        "0xc9dAacF6dF180915ef01229eF4334214Fa58aA3B": 1
      },
      "asks_updated": "2024-06-07T16:35:43.336561592Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65468604c5ce2e5fa70d6722",
    "name": "togethercomputer/m2-bert-80M-8k-retrieval",
    "display_name": "M2-BERT-Retrieval-8k",
    "display_type": "embedding",
    "description": "The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/m2-bert-80M-8k-retrieval",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 80000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T17:57:24.532Z",
    "update_at": "2023-11-04T17:57:24.532Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "lago_tag": "EMBEDDING_MODEL",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3d324467D9c6F36d90247D092f4CF7c3409E4EC7": 1,
        "0x8299D90F6216D7008F93565b2f320c4e554c67c6": 1,
        "0xd1A33B6831eC8120C17ff247fD538Defca8B2Ece": 1
      },
      "asks_updated": "2024-06-07T16:52:38.330684754Z",
      "gpus": {
        "": 0
      },
      "qps": 0.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 332.26666666666665,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0.4,
          "throughput_in": 332.26666666666665,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657f7552a9c4049b6a42e4c6",
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "display_name": "Upstage SOLAR Instruct v1 (11B)",
    "display_type": "chat",
    "description": "Built on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage Depth Up-Scaling",
    "license": "cc-by-nc-4.0",
    "creator_organization": "upstage",
    "pricing_tier": "Featured",
    "num_parameters": 10700000000,
    "release_date": "2023-12-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "add_generation_prompt": true,
      "stop": [
        "</s>",
        "###"
      ],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'system' %}{% if message['content']%}{{'### System:\n' + message['content']+'\n\n'}}{% endif %}{% elif message['role'] == 'user' %}{{'### User:\n' + message['content']+'\n\n'}}{% elif message['role'] == 'assistant' %}{{'### Assistant:\n'  + message['content']}}{% endif %}{% if loop.last and add_generation_prompt %}{{ '### Assistant:\n' }}{% endif %}{% endfor %}"
    },
    "pricing": {
      "input": 75,
      "output": 75
    },
    "created_at": "2023-12-17T22:25:22.252Z",
    "update_at": "2023-12-17T22:32:58.075Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x44f08eFCeaD685956E94BBF472Dc5982431C8Af2": 1
      },
      "asks_updated": "2024-06-07T16:07:15.693336459Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4666666666666667,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4666666666666667,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace3af227f790586239ce6",
    "name": "wavymulder/Analog-Diffusion",
    "display_name": "Analog Diffusion",
    "display_type": "image",
    "description": "Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/wavymulder/Analog-Diffusion",
    "creator_organization": "Wavymulder",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 0,
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-07-11T05:07:59.364Z",
    "update_at": "2024-05-22T22:41:40.508Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xC830b3583bcA51887185318c0184fbdB622A55f5": 1
      },
      "asks_updated": "2024-06-07T12:38:16.759762816Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.05,
          "qps": 0.06666666666666667,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656a79054d805f78df5fd530",
    "name": "zero-one-ai/Yi-34B-Chat",
    "display_name": "01-ai Yi Chat (34B)",
    "display_type": "chat",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "add_generation_prompt": true,
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "base": 0
    },
    "created_at": "2023-12-02T00:23:33.685Z",
    "update_at": "2023-12-02T00:26:55.827Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3faF4AfA52f2A5951B4bde877478B0BF4d69a023": 1,
        "0x450aDd660C1B1fdB2A7f6bDAE850C4850594FbCD": 1,
        "0x454Eef2b7f085F0134db5c728ac382aD0c4C9511": 1
      },
      "asks_updated": "2024-06-07T16:54:02.401776145Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656fa3548d9fd20968de9ba7",
    "name": "zero-one-ai/Yi-34B",
    "display_name": "01-ai Yi Base (34B)",
    "display_type": "language",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "pricing": {
      "input": 200,
      "output": 200
    },
    "created_at": "2023-12-05T22:25:24.982Z",
    "update_at": "2023-12-05T22:51:15.306Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x09c253d0c4aB07a89D2f7d23A57eA31bdc760c54": 1,
        "0x964972F1A61F8BAdbD6163b9888D284CC2E054E9": 1,
        "0x9B35c58ef3E3425dEa8CBE5f39b8050e40193F68": 1
      },
      "asks_updated": "2024-06-07T16:07:16.347409888Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6570718281b9e1cf0455ec53",
    "name": "zero-one-ai/Yi-6B",
    "display_name": "01-ai Yi Base (6B)",
    "display_type": "language",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 6000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-12-06T13:05:06.567Z",
    "update_at": "2023-12-06T13:07:50.190Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xB527b0625620ff3AACCEb84008A7A6684E2d6FbA": 1,
        "0xf2337a3BA04f483bCb3DbF43584a398e83E20368": 1
      },
      "asks_updated": "2024-06-07T16:44:10.782981056Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.4,
      "throughput_out": 8.533333333333333,
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0,
          "qps": 0.06666666666666667,
          "throughput_in": 0.4,
          "throughput_out": 8.533333333333333,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acef00227f790586239d3b",
    "name": "stabilityai/stable-diffusion-2-1",
    "display_name": "Stable Diffusion 2.1",
    "display_type": "image",
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "license": "openrail++",
    "link": "https://huggingface.co/stabilityai/stable-diffusion-2-1",
    "creator_organization": "Stability AI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-06-23T20:22:43.572Z",
    "update_at": "2024-05-28T16:36:01.842Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "access": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 0,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "66313f416fbdf5d304b833d1",
    "name": "togethercomputer/Llama-3-8b-chat-hf-int4",
    "display_name": "Llama3 8B Chat HF INT4",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T06:07:59.041Z",
    "update_at": "2024-04-24T19:14:26.075Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      }
    ],
    "isPrivate": true,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 0,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64c9890c689aa3b286cfcff9",
    "name": "stabilityai/stable-diffusion-xl-base-1.0",
    "display_name": "Stable Diffusion XL 1.0",
    "display_type": "image",
    "description": "A text-to-image generative AI model that excels at creating 1024x1024 images.",
    "license": "openrail++",
    "link": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",
    "creator_organization": "Stability AI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "show_in_playground": true,
    "finetuning_supported": false,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 1024,
      "width": 1024,
      "number_of_images": 4,
      "steps": 40,
      "seed": 1000
    },
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-08-01T22:37:00.851Z",
    "update_at": "2024-05-29T02:11:47.134Z",
    "has_wandb_telemetry": false,
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "isPrivate": false,
    "isDedicatedInstance": false,
    "engine": "image",
    "isSelfServeDedicatedInstance": false,
    "isFinetuned": false,
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0.13333333333333333,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 0,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.24333333333333332,
          "qps": 0.13333333333333333,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6630011e324b0032b64f35a0",
    "name": "togethercomputer/Llama-3-8b-chat-hf-int8",
    "display_name": "Togethercomputer Llama3 8B Instruct Int8",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T06:07:59.041Z",
    "update_at": "2024-04-24T19:14:26.075Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-5b",
        "cluster": "blusterybull"
      }
    ],
    "isPrivate": true,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 0,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5b",
          "cluster": "blusterybull",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbe",
    "name": "EleutherAI/pythia-1b-v0",
    "display_name": "Pythia (1B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 1000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.925Z",
    "update_at": "2023-06-23T20:22:41.925Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1512907e072b8aecf5",
    "name": "stabilityai/stablelm-base-alpha-7b",
    "display_name": "StableLM-Base-Alpha (7B)",
    "display_type": "language",
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "license": "",
    "link": "",
    "creator_organization": "Stability AI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:45.249Z",
    "update_at": "2023-06-23T20:22:45.249Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78e89589782acafe1781c",
    "name": "togethercomputer/CodeLlama-7b-Python",
    "display_name": "Code Llama Python (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "renamed": "codellama/CodeLlama-7b-Python-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "649e1ccca073332e47742415",
    "name": "replit/replit-code-v1-3b",
    "display_name": "Replit-Code-v1 (3B)",
    "display_type": "code",
    "description": "replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.",
    "license": "",
    "link": "",
    "creator_organization": "Replit",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "limited",
    "num_parameters": 3000000000,
    "release_date": "2023-04-26T00:00:00.000Z",
    "show_in_playground": "true",
    "isFeaturedModel": false,
    "context_length": 2048,
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-30T00:07:40.594Z",
    "update_at": "2023-07-07T20:09:09.965Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecee",
    "name": "togethercomputer/Pythia-Chat-Base-7B-v0.16",
    "display_name": "Pythia-Chat-Base (7B)",
    "display_type": "chat",
    "description": "Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.",
    "license": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": [
        "<human>"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.251Z",
    "update_at": "2023-06-23T20:22:44.251Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceada227f790586239d11",
    "name": "mosaicml/mpt-7b",
    "display_name": "MPT (7B)",
    "display_type": "language",
    "description": "Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:38:34.852Z",
    "update_at": "2023-07-15T03:06:20.780Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb0e227f790586239d12",
    "name": "togethercomputer/mpt-30b-chat",
    "display_name": "MPT-Chat (30B)",
    "display_type": "chat",
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 30000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|im_end|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:39:26.078Z",
    "update_at": "2023-07-11T05:39:26.078Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace6df227f790586239cfc",
    "name": "google/flan-t5-xl",
    "display_name": "Flan T5 XL (3B)",
    "display_type": "language",
    "description": "T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ",
    "license": "",
    "link": "",
    "creator_organization": "Google",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.261Z",
    "update_at": "2023-06-23T20:22:42.261Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acebe0227f790586239d17",
    "name": "NumbersStation/nsql-6B",
    "display_name": "NSQL (6B)",
    "display_type": "language",
    "description": "Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.",
    "license": "",
    "creator_organization": "Numbers Station",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 6000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:42:56.540Z",
    "update_at": "2023-07-11T05:42:56.540Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace9ca227f790586239d09",
    "name": "togethercomputer/Koala-7B",
    "display_name": "Koala (7B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt} GPT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:34:02.521Z",
    "update_at": "2023-07-11T05:34:02.521Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc0",
    "name": "EleutherAI/pythia-6.9b",
    "display_name": "Pythia (6.9B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 6900000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.044Z",
    "update_at": "2023-06-23T20:22:42.044Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb6",
    "name": "databricks/dolly-v2-3b",
    "display_name": "Dolly v2 (3B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "### End"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.524Z",
    "update_at": "2023-06-23T20:22:41.524Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc2",
    "name": "EleutherAI/gpt-neox-20b",
    "display_name": "GPT-NeoX (20B)",
    "display_type": "language",
    "description": "Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 20000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.132Z",
    "update_at": "2023-06-23T20:22:42.132Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbf",
    "name": "EleutherAI/pythia-2.8b-v0",
    "display_name": "Pythia (2.8B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "num_parameters": 2800000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.975Z",
    "update_at": "2023-06-23T20:22:41.975Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acebb2227f790586239d16",
    "name": "NousResearch/Nous-Hermes-13b",
    "display_name": "Nous Hermes (13B)",
    "display_type": "language",
    "description": "LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.",
    "license": "",
    "link": "",
    "creator_organization": "Nous Research",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:42:10.444Z",
    "update_at": "2023-07-11T05:42:10.444Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8d1227f790586239d03",
    "name": "togethercomputer/guanaco-65b",
    "display_name": "Guanaco (65B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 65000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "###"
      ],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:53.740Z",
    "update_at": "2023-07-11T05:29:53.740Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e5",
    "name": "togethercomputer/llama-2-7b",
    "display_name": "LLaMA-2 (7B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "renamed": "meta-llama/Llama-2-7b-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acf031227f790586239d44",
    "name": "lmsys/fastchat-t5-3b-v1.0",
    "display_name": "Vicuna-FastChat-T5 (3B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "stop": [
        "###",
        "</s>"
      ],
      "prompt_format": "### Human: {prompt}\n### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\n' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:01:21.713Z",
    "update_at": "2023-07-11T06:01:21.713Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea6e227f790586239d0e",
    "name": "huggyllama/llama-7b",
    "display_name": "LLaMA (7B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:36:46.255Z",
    "update_at": "2023-07-11T05:36:46.255Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc9",
    "name": "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "display_name": "Open-Assistant StableLM SFT-7 (7B)",
    "display_type": "chat",
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "license": "",
    "link": "",
    "creator_organization": "LAION",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "prompt_format": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.425Z",
    "update_at": "2023-06-23T20:22:42.425Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc1",
    "name": "EleutherAI/pythia-12b-v0",
    "display_name": "Pythia (12B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.091Z",
    "update_at": "2023-06-23T20:22:42.091Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb28227f790586239d13",
    "name": "togethercomputer/mpt-7b-chat",
    "display_name": "MPT-Chat (7B)",
    "display_type": "chat",
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|im_end|>"
      ],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:39:52.024Z",
    "update_at": "2023-07-11T05:39:52.024Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbc",
    "name": "EleutherAI/gpt-j-6b",
    "display_name": "GPT-J (6B)",
    "display_type": "language",
    "description": "Transformer model trained using Ben Wang's Mesh Transformer JAX. ",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 6000000000,
    "release_date": "2021-06-04T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.831Z",
    "update_at": "2023-06-23T20:22:41.831Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc8",
    "name": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "display_name": "Open-Assistant Pythia SFT-4 (12B)",
    "display_type": "chat",
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "license": "",
    "link": "",
    "creator_organization": "LAION",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "prompt_format": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.383Z",
    "update_at": "2023-06-23T20:22:42.383Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acf013227f790586239d43",
    "name": "lmsys/vicuna-7b-v1.3",
    "display_name": "Vicuna v1.3 (7B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:00:51.553Z",
    "update_at": "2023-07-11T06:00:51.553Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cc",
    "name": "Phind/Phind-CodeLlama-34B-Python-v1",
    "display_name": "Phind Code LLaMA Python v1 (34B)",
    "display_type": "code",
    "description": "This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.",
    "license": "",
    "creator_organization": "Phind",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 33743970304,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": [
        "</s>",
        "###"
      ],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65ac4e5e75846d9d3ae5b836",
    "name": "NumbersStation/nsql-llama-2-7B",
    "display_name": "NSQL LLaMA-2 (7B)",
    "display_type": "code",
    "description": "NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks",
    "link": "",
    "creator_organization": "Numbers Station",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2024-01-20T22:51:10.492Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "pricing": {
      "hourly": 0,
      "input": 50,
      "output": 50,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2024-01-20T22:51:10.492Z",
    "update_at": "2024-01-20T22:59:48.333Z",
    "access": "",
    "license": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf8",
    "name": "NousResearch/Nous-Hermes-Llama2-70b",
    "display_name": "Nous Hermes LLaMA-2 (70B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "",
    "link": "",
    "creator_organization": "NousResearch",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": [
        "###",
        "</s>"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:\n",
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.404Z",
    "update_at": "2023-10-24T17:43:39.278Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f67555bc372ce719b97f03",
    "name": "WizardLM/WizardLM-70B-V1.0",
    "display_name": "WizardLM v1.0 (70B)",
    "display_type": "language",
    "description": "This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.",
    "license": "",
    "creator_organization": "WizardLM",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt} ASSISTANT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'ASSISTANT:' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:24:53.327Z",
    "update_at": "2023-09-05T00:24:53.327Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea57227f790586239d0d",
    "name": "huggyllama/llama-65b",
    "display_name": "LLaMA (65B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 65000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:36:23.656Z",
    "update_at": "2023-07-11T05:36:23.656Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5ce",
    "name": "lmsys/vicuna-13b-v1.5-16k",
    "display_name": "Vicuna v1.5 16K (13B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13015864320,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "stop": [
        "</s>"
      ],
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece4",
    "name": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "display_name": "GPT-NeoXT-Chat-Base (20B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.",
    "license": "",
    "link": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 20000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": [
        "<human>"
      ],
      "chat_template_name": "gpt"
    },
    "max_tokens": 995,
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.702Z",
    "update_at": "2023-06-23T20:22:43.702Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657bed666aca120ac2af2fb7",
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "display_name": "Zephyr-7B-",
    "display_type": "chat",
    "description": "A fine-tuned version of Mistral-7B to act as a helpful assistant.",
    "license": "",
    "link": "",
    "creator_organization": "HuggingFace",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241732096,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 32768,
    "config": {
      "stop": [
        "[INST]",
        "</s>"
      ],
      "prompt_format": "<s>[INST] {prompt} [INST]"
    },
    "created_at": "2023-12-15T06:08:38.925Z",
    "update_at": "2023-12-15T06:08:38.925Z",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78eba589782acafe1781f",
    "name": "togethercomputer/CodeLlama-13b-Python",
    "display_name": "Code Llama Python (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-20T22:52:59.177Z",
    "renamed": "codellama/CodeLlama-13b-Python-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e7",
    "name": "togethercomputer/llama-2-13b",
    "display_name": "LLaMA-2 (13B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:07:52.318Z",
    "renamed": "meta-llama/Llama-2-13b-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78e89589782acafe1781d",
    "name": "togethercomputer/CodeLlama-7b-Instruct",
    "display_name": "Code Llama Instruct (7B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "renamed": "codellama/CodeLlama-7b-Instruct-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f0de22caa9e2eb543b373b",
    "name": "togethercomputer/guanaco-13b",
    "display_name": "Guanaco (13B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A40 48GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "###"
      ],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:07.717Z",
    "update_at": "2023-07-11T05:29:07.717Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17822",
    "name": "togethercomputer/CodeLlama-34b-Python",
    "display_name": "Code Llama Python (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-Python-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb6f227f790586239d15",
    "name": "mosaicml/mpt-7b-instruct",
    "display_name": "MPT-Instruct (7B)",
    "display_type": "language",
    "description": "Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:41:03.757Z",
    "update_at": "2023-07-11T05:41:03.757Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07ea",
    "name": "togethercomputer/llama-2-70b-chat",
    "display_name": "LLaMA-2 Chat (70B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "renamed": "meta-llama/Llama-2-70b-chat-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17823",
    "name": "togethercomputer/CodeLlama-34b-Instruct",
    "display_name": "Code Llama Instruct (34B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-Instruct-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17821",
    "name": "togethercomputer/CodeLlama-34b",
    "display_name": "Code Llama (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecf1",
    "name": "Salesforce/codegen2-16B",
    "display_name": "CodeGen2 (16B)",
    "display_type": "code",
    "description": "An autoregressive language models for program synthesis.",
    "license": "",
    "link": "",
    "creator_organization": "Salesforce",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 16000000000,
    "release_date": "2022-03-25T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "\n\n"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.453Z",
    "update_at": "2023-06-23T20:22:44.453Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace476227f790586239cef",
    "name": "Salesforce/codegen2-7B",
    "display_name": "CodeGen2 (7B)",
    "display_type": "code",
    "description": "An autoregressive language models for program synthesis.",
    "license": "",
    "link": "",
    "creator_organization": "Salesforce",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "release_date": "2022-03-25T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "\n\n"
      ],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:11:18.328Z",
    "update_at": "2023-07-11T05:11:18.328Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc5",
    "name": "google/flan-t5-xxl",
    "display_name": "Flan T5 XXL (11B)",
    "display_type": "language",
    "description": "Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).",
    "creator_organization": "Google",
    "hardware_label": "A40 48GB",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.261Z",
    "update_at": "2023-09-01T14:35:00.161Z",
    "license": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e9",
    "name": "togethercomputer/llama-2-70b",
    "display_name": "LLaMA-2 (70B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "renamed": "meta-llama/Llama-2-70b-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425f",
    "name": "codellama/CodeLlama-7b-hf",
    "display_name": "Code Llama (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425c",
    "name": "codellama/CodeLlama-13b-hf",
    "display_name": "Code Llama (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-21T01:12:38.916Z",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78eba589782acafe17820",
    "name": "togethercomputer/CodeLlama-13b-Instruct",
    "display_name": "Code Llama Instruct (13B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "</s>",
        "[INST]"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-04T05:01:42.539Z",
    "renamed": "codellama/CodeLlama-13b-Instruct-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e8",
    "name": "togethercomputer/llama-2-13b-chat",
    "display_name": "LLaMA-2 Chat (13B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:00:54.436Z",
    "renamed": "meta-llama/Llama-2-13b-chat-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acefe5227f790586239d41",
    "name": "lmsys/vicuna-13b-v1.3",
    "display_name": "Vicuna v1.3 (13B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:00:05.166Z",
    "update_at": "2023-07-15T03:08:44.173Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea0b227f790586239d0b",
    "name": "huggyllama/llama-13b",
    "display_name": "LLaMA (13B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:35:07.955Z",
    "update_at": "2023-07-11T05:35:07.955Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acefbe227f790586239d40",
    "name": "HuggingFaceH4/starchat-alpha",
    "display_name": "StarCoderChat Alpha (16B)",
    "display_type": "chat",
    "description": "Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.",
    "license": "",
    "link": "",
    "creator_organization": "HuggingFaceH4",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 16000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|endoftext|>",
        "<|end|>"
      ],
      "prompt_format": "<|system|>\n<|end|>\n<|user|>\n{prompt}<|end|>\n<|assistant|>",
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:59:26.298Z",
    "update_at": "2023-07-11T05:59:26.298Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea35227f790586239d0c",
    "name": "huggyllama/llama-30b",
    "display_name": "LLaMA (30B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "access": "open",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:35:49.870Z",
    "update_at": "2023-07-11T05:35:49.870Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecf4",
    "name": "stabilityai/stablelm-base-alpha-3b",
    "display_name": "StableLM-Base-Alpha (3B)",
    "display_type": "language",
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "license": "",
    "link": "",
    "creator_organization": "Stability AI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.907Z",
    "update_at": "2023-06-23T20:22:44.907Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f67987bc372ce719b97f07",
    "name": "defog/sqlcoder",
    "display_name": "Sqlcoder (15B)",
    "display_type": "language",
    "description": "Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.",
    "license": "",
    "creator_organization": "Defog",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 15000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|endoftext|>"
      ],
      "prompt_format": "### Instructions:\n\n{prompt}\n\n### Response:\n"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:42:47.496Z",
    "update_at": "2023-09-05T00:42:47.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acef6e227f790586239d3f",
    "name": "bigcode/starcoder",
    "display_name": "StarCoder (16B)",
    "display_type": "code",
    "description": "Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.",
    "license": "",
    "link": "",
    "creator_organization": "BigCode",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 16000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": [
        "<|endoftext|>",
        "<|end|>"
      ]
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:58:06.486Z",
    "update_at": "2023-07-11T05:58:06.486Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb7",
    "name": "databricks/dolly-v2-7b",
    "display_name": "Dolly v2 (7B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "### End"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.565Z",
    "update_at": "2023-06-23T20:22:41.565Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8a3227f790586239d02",
    "name": "togethercomputer/guanaco-33b",
    "display_name": "Guanaco (33B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "###"
      ],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:07.717Z",
    "update_at": "2023-07-11T05:29:07.717Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace9b1227f790586239d07",
    "name": "togethercomputer/Koala-13B",
    "display_name": "Koala (13B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "</s>"
      ],
      "prompt_format": "USER: {prompt} GPT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:33:37.737Z",
    "update_at": "2023-07-11T05:33:37.737Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece2",
    "name": "togethercomputer/GPT-JT-6B-v1",
    "display_name": "GPT-JT (6B)",
    "display_type": "language",
    "description": "Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai",
    "license": "",
    "link": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 6700000000,
    "release_date": "2022-11-29T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.617Z",
    "update_at": "2023-06-23T20:22:43.617Z"
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e6",
    "name": "togethercomputer/llama-2-7b-chat",
    "display_name": "LLaMA-2 Chat (7B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": [
        "[/INST]",
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "renamed": "meta-llama/Llama-2-7b-chat-hf",
    "lago_tag": "LLAMA_2_MODEL",
    "hardware_label": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "662b250e246deee9aefbcc50",
    "name": "togethercomputer/SOLAR-10.7B-Instruct-v1.0-int4",
    "display_name": "Upstage SOLAR Instruct v1 (11B)-Int4",
    "display_type": "chat",
    "description": "Built on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage Depth Up-Scaling",
    "license": "",
    "creator_organization": "upstage",
    "hardware_label": "A100B",
    "pricing_tier": "Featured",
    "num_parameters": 10700000000,
    "release_date": "2023-12-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "add_generation_prompt": true,
      "stop": [
        "<|im_end|>",
        "<|im_start|>"
      ],
      "chat_template": "{% for message in messages %}{{'<|im_start|>'}}{% if message['role'] == 'user' %}{{'user\n' + message['content'] + '<|im_end|>\n'}}{% elif message['role'] == 'assistant' %}{{'assistant\n' + message['content'] + '<|im_end|>\n'}}{% elif message['role'] == 'system' %}{{'system\n' + message['content'] + '<|im_end|>\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"
    },
    "pricing": {
      "input": 75,
      "output": 75
    },
    "created_at": "2024-04-26T03:52:46.866Z",
    "update_at": "2024-04-26T03:52:46.866Z",
    "instances": [],
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8ed227f790586239d04",
    "name": "togethercomputer/guanaco-7b",
    "display_name": "Guanaco (7B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A40 48GB",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "###"
      ],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:30:21.531Z",
    "update_at": "2023-07-11T05:30:21.531Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf7",
    "name": "EleutherAI/llemma_7b",
    "display_name": "Llemma (7B)",
    "display_type": "language",
    "description": "Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738546688,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T17:42:38.630Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb8",
    "name": "databricks/dolly-v2-12b",
    "display_name": "Dolly v2 (12B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": [
        "### End"
      ],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.607Z",
    "update_at": "2023-06-23T20:22:41.607Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "66316415c3b4aab9202b12df",
    "name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "serviceName": "meta-llama/Llama-3-8b-chat-hf",
    "display_name": "Meta Llama 3 8B Instruct",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": null,
    "num_parameters": 8000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-04-18T06:07:59.041Z",
    "update_at": "2024-04-24T19:14:26.075Z",
    "instances": [],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de96e620478cfa144262",
    "name": "codellama/CodeLlama-34b-hf",
    "display_name": "Code Llama (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": [
        "</s>"
      ],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "lago_tag": "LLAMA_2_MODEL",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "66316309c3b4aab9202b12de",
    "name": "meta-llama/Meta-Llama-3-70B-Instruct",
    "serviceName": "meta-llama/Llama-3-70b-chat-hf",
    "display_name": "Meta Llama 3 70B Instruct",
    "display_type": "chat",
    "description": "Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "owner_userid": null,
    "config": {
      "stop": [
        "<|eot_id|>"
      ],
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "bos_token": "<|begin_of_text|>",
      "eos_token": "<|end_of_text|>",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-04-18T08:33:56.492Z",
    "update_at": "2024-04-24T19:06:49.423Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [],
    "isPrivate": false,
    "access_control": [],
    "isDedicatedInstance": false,
    "access": "",
    "hardware_label": "",
    "descriptionLink": ""
  }
]