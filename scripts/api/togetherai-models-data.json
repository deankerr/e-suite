[
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e831864b84b428b8d322d0",
    "name": "Austism/chronos-hermes-13b",
    "display_name": "Chronos Hermes (13B)",
    "display_type": "chat",
    "description": "This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.",
    "license": "other",
    "creator_organization": "Austism",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xbf44F2f23dF67f46EF127dAA4Ae58424b0748935": 1
      },
      "asks_updated": "2024-02-15T07:40:53.761128924Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 68.66666666666667,
      "throughput_out": 4.266666666666667,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.07453416149068323,
          "qps": 0.06666666666666667,
          "throughput_in": 68.66666666666667,
          "throughput_out": 4.266666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6560b993b56cf1e0970c9b1a",
    "name": "BAAI/bge-base-en-v1.5",
    "display_name": "BAAI-Bge-Base-1p5",
    "display_type": "embedding",
    "description": "bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding",
    "license": "MIT",
    "creator_organization": "BAAI",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 109482240,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-24T14:56:19.475Z",
    "update_at": "2023-12-22T03:26:23.802Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5a69632062DE9d9397079725f3e7125318ED5FaA": 1,
        "0x947C7D9118573Ef572bA1DbCC093513AA7768352": 1
      },
      "asks_updated": "2024-02-15T07:41:03.479818079Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6560b938b56cf1e0970c9b19",
    "name": "BAAI/bge-large-en-v1.5",
    "display_name": "BAAI-Bge-Large-1p5",
    "display_type": "embedding",
    "description": "bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding",
    "license": "MIT",
    "creator_organization": "BAAI",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 335141888,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 4,
      "output": 4,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-24T14:54:48.986Z",
    "update_at": "2023-12-22T03:27:18.465Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x42B0c62bBe54e4788174E40ebeD128e174D24C0d": 1,
        "0x85D53F9AF9Bb56E00FC16e91445eD7ce9C2D7924": 1
      },
      "asks_updated": "2024-02-15T07:41:02.434299129Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.3333333333333333,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0.06666666666666667,
          "throughput_in": 0.3333333333333333,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f78861d683768020b9f005",
    "name": "Gryphe/MythoMax-L2-13b",
    "display_name": "MythoMax-L2 (13B)",
    "display_type": "chat",
    "description": "MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model",
    "license": "other",
    "creator_organization": "Gryphe",
    "hardware_label": "1x A40 48GB",
    "num_parameters": 13000000000,
    "release_date": "2023-08-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T19:58:25.683Z",
    "update_at": "2023-09-05T19:58:25.683Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      },
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      },
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      },
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      },
      {
        "avzone": "us-central-5a",
        "cluster": "testytiger"
      },
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 37,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x13b9795C4EF7D54158346d7ee3DAF3a95931F2bC": 1,
        "0x17FC38fbC2C15F4CB7D74cF7Dd778Bb9375Bb70F": 1,
        "0x1a37E72cD74e1D6f0746D2A78D1C29Bfc40Cbc3F": 1,
        "0x1fFAe85665f086e74FE1CD15C2C86F72c949E9Cb": 1,
        "0x2b81Da1A5B4C6b4E087D7a6dC42D9980B24bf49D": 1,
        "0x334b45eB2F5dBC4A857CeF35f97035D00CF1898b": 1,
        "0x3BC8208879e9B044D15468353E55FdbCaA08e7b8": 1,
        "0x3C27a77598EDd183657eEFA68d572e6350910bbE": 1,
        "0x42c055D46bdd17db693f5Ce9B3a9eac36f077495": 1,
        "0x47777245F0F38cE62fB1C634A4e2F8387e73c575": 1,
        "0x49160a1e620c2B858aC7DE974FB31830a88c60dd": 1,
        "0x550647eA79812904f3B5093c30F39DaBA745D56a": 1,
        "0x561Ac3F53B8eD9b5D03FB0851d0bd217445b11AF": 1,
        "0x59D08c2a6af1c857323D5E243b4f91E7583a046e": 1,
        "0x5D2373C310F8836A09ee46A113EeB2Ba6CF3743f": 1,
        "0x65638d43E7CB06062Fa2E0f3A67afE8A2FD36137": 1,
        "0x6d2CcB65D6117D791ed7A386DDFF0c4D1d7dCb27": 1,
        "0x6e46c99cb3bC555a1CC84d5FF351784e314D737E": 1,
        "0x70cC61D4b6f58c0FbE58a84756E15C2225f7fbF6": 1,
        "0x7655Fbe146E2706db0b9dDc41264Df4b6dF7F87A": 1,
        "0x769B2383710604771C71852d6eC5168167dA4D59": 1,
        "0x798189418713e1a31a9b3A739F883BAf46FDdC37": 1,
        "0x8075D6A7A1D19AE1a8e5f4C053ae02Aa19b996E9": 1,
        "0x93D7E131E1617608864a3b76fbebB22607A38508": 1,
        "0x9B4ae27D4930f3867C2c47a2a67BD1eb865Ef506": 1,
        "0x9D1Df73c0714Fd1405A351a10129483C748e374b": 1,
        "0x9a90B0a4284A7c2eDB1C662E675d9B0Ed4Ff3C34": 1,
        "0x9fEaa116556b8A6Df0C248cadbB5b7920f6CDEcF": 1,
        "0xAB84F512aa6bE668e352Ca65CfD550D93Bbd0b20": 1,
        "0xAa40c92A9B6f35D4048617A6D310a50De569122A": 1,
        "0xB37DAD3377FF67BBBee58EB26471402a01dF2412": 1,
        "0xB5BAE5A3fe2eB4D02F3a18B1A81d039B36313abD": 1,
        "0xD61B551a995Ae41Ae48590BEbe2fc95f61e1889e": 1,
        "0xDC94D08012b63EF3F8AE10A0A0628B071de51d47": 1,
        "0xE775d5dD8A02960aDEfbd3D4b2585492892EAa6d": 1,
        "0xF24a9b609bb6eebA23794AbA1D9564F19b0b8Ddc": 1,
        "0xa286F528E47a24259d2DCa8cbAF14C6d9886e3E6": 1,
        "0xa782Cf9A2328F5400535Bc7352482c3F081F9bfa": 1,
        "0xbC9028b5802e0F9AFE2A283C2b3c7d5Fa19c2570": 1,
        "0xbEaA008D2F7B85bfe6C710C6c0f66BeA870Fb1b5": 1,
        "0xc65AaA0832DA601910EdE8F2477FD995Acee414d": 1,
        "0xfDfE570b364Ae3CC6Ff2f0170209a183fA644066": 1
      },
      "asks_updated": "2024-02-15T09:53:35.556813553Z",
      "gpus": {
        "": 0
      },
      "qps": 50.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 46213.066666666666,
      "throughput_out": 6982.466666666667,
      "retry_rate": 0.06666666666666667,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.9685185185185179,
          "qps": 6.2,
          "throughput_in": 5610.333333333333,
          "throughput_out": 847.4666666666667,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.48853503184713376,
          "qps": 8.266666666666667,
          "throughput_in": 7132.066666666667,
          "throughput_out": 1111.5333333333333,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.5182699478001499,
          "qps": 8.133333333333333,
          "throughput_in": 7212.8,
          "throughput_out": 1171.4,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.533481152993348,
          "qps": 8.933333333333334,
          "throughput_in": 8833,
          "throughput_out": 1271.6666666666667,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5a",
          "cluster": "testytiger",
          "capacity": 0.5725925925925948,
          "qps": 8.866666666666667,
          "throughput_in": 8671.133333333333,
          "throughput_out": 1196,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.36169312169312307,
          "qps": 9.8,
          "throughput_in": 8753.733333333334,
          "throughput_out": 1384.4,
          "error_rate": 0,
          "retry_rate": 0.06666666666666667
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6573540efe9a5c79871809ce",
    "name": "Meta-Llama/Llama-Guard-7b",
    "display_name": "Llama Guard (7B)",
    "display_type": "moderation",
    "description": "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/LlamaGuard-7b",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template": "{{ '[INST] Task: Check if there is unsafe content in \\'' }}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{ '\\' messages in conversations according our safety policy with the below categories.\n\n<BEGIN UNSAFE CONTENT CATEGORIES>\nO1: Violence and Hate. \nShould not\n - Help people plan or engage in violence.\n - Encourage people to engage in violence.\n - Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics like their race, color, religion, national origin, sexual orientation, gender, gender identity, or disability.\n - Encourage discrimination against people based on those characteristics and should not use slurs or create insults based on those characteristics.\nCan\n - Provide information on violence and discrimination.\n - Discuss the topics of hate and violence, and can discuss historical events involving violence.\nO2: Sexual Content. \nShould not\n - Engage in sexually explicit (i.e., erotic) conversations and should not encourage people to engage in sexual activities.\nCan\n - Discuss topics related to sexuality and sexual education.\n - Provide general information regarding sexual activities.\n - Provide guidance on topics related to sexual health.\nO3: Criminal Planning. \nShould not\n - Help people plan or engage in criminal activities like theft, kidnapping, or financial crimes, especially when the person indicates that they may act on the information provided to them.\n - Encourage people to engage in criminal activities or condone criminal behavior.\nCan\n - Help people understand how crimes are committed, provided that the response is not so detailed that it could be used to provide a roadmap for future crimes.\n - Help people understand how systems work that are used to prevent crimes, provided those descriptions do not provide detailed information on how to defeat those systems.\nO4: Guns and Illegal Weapons. \nShould not\n - Assist in the planning or execution of firearm or illegal weapons crimes, especially when the person indicates that they may act on the information provided to them.\n - Encourage people to engage in firearm or illegal weapons crimes or condone such behavior.\nCan\n - Discuss firearms and the arguments for and against firearm ownership.\nO5: Regulated or Controlled Substances. \nShould not\n - Encourage or assist people in the trafficking, consumption, or use of regulated or controlled substances, including but not limited to illegal drugs, tobacco, alcohol, and cannabis.\n - Assist or encourage people to create such substances when it is illegal to do so.\nCan\n - Discuss the use of regulated or controlled substances, and can provide general information on those substances (ex: what their chemical composition is and what their effects are).\n - Provide information on how those substances are manufactured, provided that the information is not so detailed as to provide step-by-step instructions for their creation.\nO6: Self-Harm. \nShould not\n - Encourage people to harm themselves.\n - Romanticize or condone self-harm or suicide.\n - Provide information regarding the methods of suicide or self-harm.\n - Provide any information or advice, other than information regarding appropriate health resources, to people who express or imply that they wish to harm themselves.\nCan\n - Provide general information regarding self-harm and suicide (ex: statistics, the mental health challenges faced by those who take these actions).\nShould\n - Provide information regarding appropriate health resources to people who imply or express the desire to harm themselves.\n<END UNSAFE CONTENT CATEGORIES>\n\n<BEGIN CONVERSATION>\n\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'User: ' + message['content'] + '\n\n' }}{% else %}{{ 'Agent: ' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '<END CONVERSATION>\n\nProvide your safety assessment for '}}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{' in the above conversation:\n - First line must read \\'safe\\' or \\'unsafe\\'.\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]' }}",
      "safety_label": "safe",
      "safe_response": true,
      "safety_config": {
        "max_tokens": 64
      },
      "safety_categories": {
        "O1": "Violence and Hate",
        "O2": "Sexual Content",
        "O3": "Criminal Planning",
        "O4": "Guns and Illegal Weapons",
        "O5": "Regulated or Controlled Substances",
        "O6": "Self-Harm"
      }
    },
    "pricing": {
      "input": 6,
      "output": 6,
      "hourly": 0
    },
    "update_at": "2024-01-18T17:03:16.859Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      },
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      },
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 39,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0712137E9EEc75e646DdbAaB72d6852b36FbBC30": 1,
        "0x0b585BBae462A151dD515653876B6756C751c932": 1,
        "0x16F090F7Ab52523D6eb6794Dce903d0431a88c8B": 1,
        "0x2148111969486eb34e4E22aD7d6774847FABc640": 1,
        "0x2316F1105a1600329aac6C5A0c5E1fD93e1B53A4": 1,
        "0x25d7E6B6B8421B2B021b8A17C260B52c52E1BB7a": 1,
        "0x4046c5FfA620c35add7e64F39670786ED790e2Bb": 1,
        "0x43F6739C2C5aD4c4F287677325184f6404b1E830": 1,
        "0x45E274B41Dbe1BC37383E97486DCd546AdB24f97": 1,
        "0x52403612dF985dc108FFc12653393bB854b38aF9": 1,
        "0x542cbF185542bc9f5d146d2Ed1F8373B3bf442aA": 1,
        "0x5C56EA8dB0912234cE199D6E538cD971c2185250": 1,
        "0x5Cf03F817Ef8b8950B137228FF3A6AB5d51A1166": 1,
        "0x65081F36cFA36afbd92d600DDC02Dc7EEa145FF8": 1,
        "0x65e1Bc022f3ADfec245d8bd7524A7E8852EcFa6C": 1,
        "0x6622EF1890aE6437f3E5ef5ceEC6b9929C2Db53F": 1,
        "0x6d04aF535C381B034D2b41b6C2BFd899b4bcC0ff": 1,
        "0x6fDff4eb1938076F824B0ad5e08805b0CdaA00F2": 1,
        "0x72625f3C3108837d7E7F980897A6c7B5f107DA91": 1,
        "0x73e7Dcb0E420222F36d6AcFBA39aDDDd31150F51": 1,
        "0x740Ca5c6A0b247020e05517Dd9897a8EDe7FeFfB": 1,
        "0x74839074E0C98557F180b09366B9965E9949eBba": 1,
        "0x76C12B412c195d1475530CF096FC08572e820c21": 1,
        "0x7951b835d92f578385f74aeacdc5ADb9005db862": 1,
        "0x7e38246AC07b5E921cB7DCb1B8Dab5adD434ca6D": 1,
        "0x88384007De5Bd2B292d8d8700c8ceFA5D1887be0": 1,
        "0x936F24126d3E80D2dE3946C830d37126424605D5": 1,
        "0x937Bb345006E6F40235E60fd11Dd00983Cb422e6": 1,
        "0x95063a0a099D9d2E4c0d0d1B25EAb067375990Ae": 1,
        "0xB457664B18079162b55232D03b5094d275bae806": 1,
        "0xBA6D278C7DFD4b6bE51a2f8FF77746E1003b0BAe": 1,
        "0xBD08e734928c5EA6388dcc173787550D584BEf71": 1,
        "0xBE408d11bfa405D7f1dAE813233f787Ac390B048": 1,
        "0xBd7DE2a5403B205130783E75aA0A181a0B4E7FA8": 1,
        "0xE69Afc7E074501d91bEC1b6Bb9b04B581bd1D311": 1,
        "0xFAA37046B962A4Ce217B57A7527b5201d7F312e2": 1,
        "0xFe6d51021Bd460D11F4346E3D1E25847f40527b5": 1,
        "0xa53Ecc4BcFf4fB99cb05B790424E5868E5169045": 1,
        "0xbdF5b5E20C8B643b27d83335b67412c6176D65bD": 1,
        "0xc2012FBCe6D5f1b8f1C7ABeccB1A98B2435cFaC6": 1,
        "0xf59b4Ac36b1e217f462AE0b8f1Eca27a9aCBc0ca": 1
      },
      "asks_updated": "2024-02-15T10:17:48.205184123Z",
      "gpus": {
        "": 0
      },
      "qps": 350.6666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 335909.5333333333,
      "throughput_out": 706.7333333333333,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.4949813258636788,
          "qps": 106.4,
          "throughput_in": 102334.46666666666,
          "throughput_out": 215,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.4888372093023256,
          "qps": 107,
          "throughput_in": 102229.53333333334,
          "throughput_out": 215.8,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.17444937507633299,
          "qps": 137.26666666666668,
          "throughput_in": 131345.53333333333,
          "throughput_out": 275.93333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656f5aac044c74c554a30c4f",
    "name": "Nexusflow/NexusRaven-V2-13B",
    "display_name": "NexusRaven (13B)",
    "display_type": "language",
    "description": "NexusRaven is an open-source and commercially viable function calling LLM that surpasses the state-of-the-art in function calling capabilities.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Nexusflow/NexusRaven-V2-13B",
    "creator_organization": "Nexusflow",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-12-05T17:15:24.561Z",
    "update_at": "2023-12-05T17:15:24.561Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe1296aa9c9579B1D0fee69d4688784aDEA3A956d": 1
      },
      "asks_updated": "2024-02-15T04:53:53.510520418Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 1,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65664e4d79fe5514beebd5d3",
    "name": "NousResearch/Nous-Capybara-7B-V1p9",
    "display_name": "Nous Capybara v1.9 (7B)",
    "display_type": "chat",
    "description": "first Nous collection of dataset and models made by fine-tuning mostly on data created by Nous in-house",
    "license": "MIT",
    "creator_organization": "NousResearch",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["USER:", "ASSISTANT:"],
      "prompt_format": "USER:\n{prompt}\nASSISTANT:",
      "pre_prompt": ""
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-28T20:32:13.026Z",
    "update_at": "2023-11-28T20:33:03.163Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6837Cd8A797B53B9f92ca92C37169D77C571BAA1": 1,
        "0xeb8B2072208d0555066Dbd668D32b723daa9bd62": 1
      },
      "asks_updated": "2024-02-15T07:41:04.005706259Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.3333333333333333,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a4b298fbc8405400423169",
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "display_name": "Nous Hermes 2 - Mixtral 8x7B-DPO ",
    "display_type": "chat",
    "description": "Nous Hermes 2 Mixtral 7bx8 DPO is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "creator_organization": "NousResearch",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": ["<|im_end|>", "<|im_start|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2024-01-15T04:20:40.079Z",
    "update_at": "2024-01-15T04:20:40.079Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x32b741eFa5c7dEF7f448A1002cF8DcEB1C1149De": 1,
        "0x70563b6C4Bb757519f75460EdA995bD10FA4Caa1": 1,
        "0xbba1A54574E347a8788CAE187dE170674895bB6d": 1
      },
      "asks_updated": "2024-02-15T05:53:23.843280957Z",
      "gpus": {
        "": 0
      },
      "qps": 5.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 9269.933333333332,
      "throughput_out": 576.3333333333334,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.29030054644808745,
          "qps": 5.4,
          "throughput_in": 9269.933333333332,
          "throughput_out": 576.3333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a4466efbc8405400423166",
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "display_name": "Nous Hermes 2 - Mixtral 8x7B-SFT",
    "display_type": "chat",
    "description": "Nous Hermes 2 Mixtral 7bx8 SFT is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "creator_organization": "NousResearch",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": ["<|im_end|>", "<|im_start|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2024-01-14T20:39:10.060Z",
    "update_at": "2024-01-14T20:39:10.060Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x97356ffEaB2f60b34759A9913777C6259d0bea74": 1,
        "0xa42Bf9A9d8E9789FC2C6F673dc5b39743f43FDC7": 1
      },
      "asks_updated": "2024-02-15T10:17:47.466509883Z",
      "gpus": {
        "": 0
      },
      "qps": 3.3333333333333335,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 4663.133333333333,
      "throughput_out": 137.33333333333334,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.21057513914656809,
          "qps": 3.3333333333333335,
          "throughput_in": 4663.133333333333,
          "throughput_out": 137.33333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "658c8dad27fb98d2edc447ff",
    "name": "NousResearch/Nous-Hermes-2-Yi-34B",
    "display_name": "Nous Hermes-2 Yi (34B)",
    "display_type": "chat",
    "description": "Nous Hermes 2 - Yi-34B is a state of the art Yi Fine-tune",
    "license": "apache-2",
    "creator_organization": "NousResearch",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-12-27T20:48:45.586Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["<|im_start|>", "<|im_end|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 200,
      "output": 200
    },
    "created_at": "2023-12-27T20:48:45.586Z",
    "update_at": "2023-12-27T20:50:38.632Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x90462E9dF5B4D30aF311cF945680b9bF811b8D7f": 1
      },
      "asks_updated": "2024-02-15T04:45:22.858969691Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 86.8,
      "throughput_out": 4,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.018518518518518517,
          "qps": 0.06666666666666667,
          "throughput_in": 86.8,
          "throughput_out": 4,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64cae18d3ede2fa7e2cbcc7d",
    "name": "NousResearch/Nous-Hermes-Llama2-13b",
    "display_name": "Nous Hermes Llama-2 (13B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "mit",
    "creator_organization": "NousResearch",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": ["###", "</s>"],
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-08-02T23:06:53.926Z",
    "update_at": "2023-10-07T00:19:33.779Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2F4546efd34983A2379bFd617DF745f06f517c22": 1,
        "0x339cEC586Ea8054A66a308f86B10C2B382773030": 1
      },
      "asks_updated": "2024-02-15T09:43:27.529214164Z",
      "gpus": {
        "": 0
      },
      "qps": 5.066666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1251.9333333333334,
      "throughput_out": 162.33333333333334,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.44342105263157894,
          "qps": 5.066666666666666,
          "throughput_in": 1251.9333333333334,
          "throughput_out": 162.33333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf6",
    "name": "NousResearch/Nous-Hermes-llama-2-7b",
    "display_name": "Nous Hermes LLaMA-2 (7B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b",
    "creator_organization": "NousResearch",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738415616,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": ["###", "</s>"],
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T17:41:52.365Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xccE34133F4dD9CaFbaBC3e2dFCFeA070e9a14eb1": 1
      },
      "asks_updated": "2024-02-15T05:00:47.700728407Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 53.2,
      "throughput_out": 9.666666666666666,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.06666666666666667,
          "qps": 0.06666666666666667,
          "throughput_in": 53.2,
          "throughput_out": 9.666666666666666,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf5",
    "name": "Open-Orca/Mistral-7B-OpenOrca",
    "display_name": "OpenOrca Mistral (7B) 8K",
    "display_type": "chat",
    "description": "An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
    "creator_organization": "OpenOrca",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241748480,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["<|im_end|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T00:01:52.541Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      },
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x51C0e7d30E0376a475d176de7F41B088E9b3f4B5": 1,
        "0xf45ae28fC1E545b51Cab0A4c6f95Bd5F7039125c": 1
      },
      "asks_updated": "2024-02-15T05:41:37.992920999Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.1111111111111111,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1111111111111111,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cb",
    "name": "Phind/Phind-CodeLlama-34B-v2",
    "display_name": "Phind Code LLaMA v2 (34B)",
    "display_type": "code",
    "description": "Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.",
    "license": "llama2",
    "creator_organization": "Phind",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 33743970304,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "### System Prompt\nYou are an intelligent programming assistant.\n\n### User Message\n{prompt}n\n### Assistant\n",
      "stop": ["</s>"],
      "chat_template": "{{ '### System Prompt\nYou are an intelligent programming assistant.\n\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User Message\n' + message['content'] + '\n' }}{% else %}{{ '### Assistant\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant\n' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "testytiger"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1B003d0b52B18C66800bEdDB9Bd222B656fCe429": 1
      },
      "asks_updated": "2024-02-15T05:29:44.119173681Z",
      "gpus": {
        "": 0
      },
      "qps": 0.8,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1651.2666666666667,
      "throughput_out": 163.33333333333334,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "testytiger",
          "capacity": 1.6114911080711358,
          "qps": 0.8,
          "throughput_in": 1651.2666666666667,
          "throughput_out": 163.33333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c81b4975e79f24d98b50",
    "name": "Qwen/Qwen1.5-0.5B-Chat",
    "display_name": "Qwen 1.5 Chat (0.5B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 500000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:35:55.571Z",
    "update_at": "2024-02-05T11:35:55.571Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x86C811cd7aC400ae354F37aFA7a399d3DF30F523": 1
      },
      "asks_updated": "2024-02-15T07:28:42.009835093Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.10714285714285714,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8164975e79f24d98b4f",
    "name": "Qwen/Qwen1.5-0.5B",
    "display_name": "Qwen 1.5 (0.5B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 500000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:35:50.032Z",
    "update_at": "2024-02-05T11:35:50.032Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xc285Cbb1eee5CC29CfFF40249dE6F0C77A63cc5E": 1
      },
      "asks_updated": "2024-02-15T04:43:51.768154961Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.07142857142857142,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8284975e79f24d98b52",
    "name": "Qwen/Qwen1.5-1.8B-Chat",
    "display_name": "Qwen 1.5 Chat (1.8B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 1800000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:08.609Z",
    "update_at": "2024-02-05T11:36:08.609Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5aa67C2Af1e7fa0a10661124BFbbd4D4BcABD354": 1
      },
      "asks_updated": "2024-02-15T07:28:41.104293699Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.25,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8214975e79f24d98b51",
    "name": "Qwen/Qwen1.5-1.8B",
    "display_name": "Qwen 1.5 (1.8B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-1.8B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 1800000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:01.895Z",
    "update_at": "2024-02-05T11:36:01.895Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xDaae17c5A3FC5A24C438e8eE61061Ad7cB4fbDdb": 1
      },
      "asks_updated": "2024-02-15T05:08:28.659636384Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.16666666666666666,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c85a4975e79f24d98b5a",
    "name": "Qwen/Qwen1.5-72B-Chat",
    "display_name": "Qwen 1.5 Chat (72B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 72000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:58.193Z",
    "update_at": "2024-02-05T11:36:58.193Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4eA17FF3B9B5a63c8857fA9851A89B68d961c221": 1
      },
      "asks_updated": "2024-02-15T04:23:36.144354538Z",
      "gpus": {
        "": 0
      },
      "qps": 0.13333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 193.53333333333333,
      "throughput_out": 39.733333333333334,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.057777777777777775,
          "qps": 0.13333333333333333,
          "throughput_in": 193.53333333333333,
          "throughput_out": 39.733333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8544975e79f24d98b59",
    "name": "Qwen/Qwen1.5-72B",
    "display_name": "Qwen 1.5 (72B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-72B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 72000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {},
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:52.008Z",
    "update_at": "2024-02-05T11:36:52.008Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x448965e59043D3ADBc8d6B7257f323EFf42Ed351": 1
      },
      "asks_updated": "2024-02-15T03:34:26.359895897Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.03225806451612903,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acee11227f790586239d36",
    "name": "SG161222/Realistic_Vision_V3.0_VAE",
    "display_name": "Realistic Vision 3.0",
    "display_type": "image",
    "description": "Fine-tune version of Stable Diffusion focused on photorealism.",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/SG161222/Realistic_Vision_V1.4",
    "creator_organization": "SG161222",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 1024,
      "width": 1024,
      "steps": 20,
      "number_of_images": 2,
      "seed": 42
    },
    "created_at": "2023-07-11T05:52:17.219Z",
    "update_at": "2023-07-11T05:52:17.219Z",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    },
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0": 1
      },
      "asks_updated": "2024-02-15T07:41:00.972386984Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.011949811,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.21509606
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655d15e7b56cf1e0970c9b17",
    "name": "Undi95/ReMM-SLERP-L2-13B",
    "display_name": "ReMM SLERP L2 (13B)",
    "display_type": "chat",
    "description": "Re:MythoMax (ReMM) is a recreation trial of the original MythoMax-L2-B13 with updated models. This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Undi95/ReMM-SLERP-L2-13B",
    "creator_organization": "Undi95",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-11-21T20:41:11.759Z",
    "update_at": "2023-11-21T20:41:11.759Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x98FC7Ae285bd96dA3A1fCD068F114BBb6C1698Cf": 1
      },
      "asks_updated": "2024-02-15T05:18:29.91162028Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.10000000000000002,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655d0fecb56cf1e0970c9b16",
    "name": "Undi95/Toppy-M-7B",
    "display_name": "Toppy M (7B)",
    "display_type": "chat",
    "description": "A merge of models built by Undi95 with the new task_arithmetic merge method from mergekit.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/Undi95/Toppy-M-7B",
    "creator_organization": "Undi95",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241748480,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-11-21T20:15:40.468Z",
    "update_at": "2023-11-21T20:15:40.468Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x00e78A1D796774c0D2D45FA8E921f0C946913b17": 1,
        "0x8509515079e2ec83DD92d4AeeE09C8aA4Ebd2495": 1
      },
      "asks_updated": "2024-02-15T09:49:45.42946734Z",
      "gpus": {
        "": 0
      },
      "qps": 0.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 870.7333333333333,
      "throughput_out": 89,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.012228260869565218,
          "qps": 0.4,
          "throughput_in": 870.7333333333333,
          "throughput_out": 89,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "658504fde7e2e898e81b5400",
    "name": "WhereIsAI/UAE-Large-V1",
    "display_name": "UAE-Large-V1",
    "display_type": "embedding",
    "description": "A universal English sentence embedding WhereIsAI/UAE-Large-V1 achieves SOTA on the MTEB Leaderboard with an average score of 64.64!",
    "license": "apache-2.0",
    "link": "https://huggingface.co/bert-base-uncased",
    "creator_organization": "WhereIsAI",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 330000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 4,
      "output": 4,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-12-22T03:39:41.105Z",
    "update_at": "2023-12-22T03:45:34.219Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3a3381c3eFaB0CD55C68196a73DadCD2a12F7EBF": 1,
        "0x9384C2d1c3f000Dc1DCD71f29e1f1ea0974d5D2e": 1,
        "0xFE76817fCF62355C5CD88f242CD40a4dD1c9401A": 1
      },
      "asks_updated": "2024-02-15T07:41:01.008173382Z",
      "gpus": {
        "": 0
      },
      "qps": 2.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 394.6,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.008638211382113821,
          "qps": 2.4,
          "throughput_in": 394.6,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cd",
    "name": "WizardLM/WizardCoder-15B-V1.0",
    "display_name": "WizardCoder v1.0 (15B)",
    "display_type": "code",
    "description": "This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 15517462528,
    "show_in_playground": true,
    "context_length": 8192,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:\n",
      "stop": ["###", "<|endoftext|>"],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xc5115Abedb26805F76FBc1934F0c6237EE1C9d20": 1
      },
      "asks_updated": "2024-02-15T04:55:27.15398087Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f672e8bc372ce719b97f02",
    "name": "WizardLM/WizardCoder-Python-34B-V1.0",
    "display_name": "WizardCoder Python v1.0 (34B)",
    "display_type": "code",
    "description": "This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["</s>", "###"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:14:32.365Z",
    "update_at": "2023-09-05T00:14:32.365Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x32a476804f1fd610AED74Aa44fa04D193Ec744F2": 1,
        "0xB3670Fd8199a0e3363f7C8505b464CbA7dA7D4fC": 1
      },
      "asks_updated": "2024-02-15T08:49:31.804724773Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.05263157894736842,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6567d4e5d1c5e59967640530",
    "name": "WizardLM/WizardLM-13B-V1.2",
    "display_name": "WizardLM v1.2 (13B)",
    "display_type": "chat",
    "description": "This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities",
    "license": "llama2",
    "creator_organization": "WizardLM",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 13000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>", "USER:", "ASSISTANT:"],
      "prompt_format": "USER: {prompt} ASSISTANT:",
      "pre_prompt": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. "
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-30T00:18:45.791Z",
    "update_at": "2023-11-30T01:20:01.779Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe4B5D5B362Fbf66d3047040a0A0339353D72138E": 1
      },
      "asks_updated": "2024-02-15T09:49:50.230889004Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 111.2,
      "throughput_out": 1.7333333333333334,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1,
          "qps": 0.06666666666666667,
          "throughput_in": 111.2,
          "throughput_out": 1.7333333333333334,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6598bc0201bf780326e7eac8",
    "name": "bert-base-uncased",
    "display_name": "Bert Base Uncased",
    "display_type": "embedding",
    "description": "original BERT model",
    "license": "Apache-2",
    "creator_organization": "Google",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 46550608,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2024-01-06T02:33:38.323Z",
    "update_at": "2024-01-06T02:33:38.323Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 3,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x21558AA2fCc15eF003135a4108a0884d4A3054f2": 1,
        "0x4e0CB8412319d0A4cdEf4C6e14E577c841Ff5c13": 1,
        "0x6b2B37f18919E411D9DcD68A89275e9C820f35D9": 1
      },
      "asks_updated": "2024-02-15T07:41:03.653077392Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425b",
    "name": "codellama/CodeLlama-13b-Instruct-hf",
    "display_name": "Code Llama Instruct (13B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-04T05:01:42.539Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xC5d6bb7Be84dbb680bB3A42E0567772c49FF0E07": 1
      },
      "asks_updated": "2024-02-15T09:37:52.121191812Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.16666666666666666,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425a",
    "name": "codellama/CodeLlama-13b-Python-hf",
    "display_name": "Code Llama Python (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-20T22:52:59.177Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2e269e8A85450b9B38E887dff704F7bE52633B08": 1
      },
      "asks_updated": "2024-02-15T08:01:07.577355937Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.16666666666666666,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa144261",
    "name": "codellama/CodeLlama-34b-Instruct-hf",
    "display_name": "Code Llama Instruct (34B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1dd77b9aA9c214e636e20e08c5D1cf6a79a30f4f": 1
      },
      "asks_updated": "2024-02-15T06:03:18.159634161Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.05263157894736842,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa144260",
    "name": "codellama/CodeLlama-34b-Python-hf",
    "display_name": "Code Llama Python (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xB065035bFF0Fa9644379D0Fc658789a96749f916": 1
      },
      "asks_updated": "2024-02-15T03:39:18.437798475Z",
      "gpus": {
        "": 0
      },
      "qps": 1.2666666666666666,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 462.1333333333333,
      "throughput_out": 100.8,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.18181818181818177,
          "qps": 1.2666666666666666,
          "throughput_in": 462.1333333333333,
          "throughput_out": 100.8,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f505752a299002ee4dc9",
    "name": "codellama/CodeLlama-70b-Instruct-hf",
    "display_name": "Code Llama Instruct (70B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template": "{{ bos_token + ' ' }}{% for message in messages %}{{'Source: ' + message['role'].trim() }}{% if not message['destination'] is 'undefined' %}{{ '\n' + 'Destination: ' + message['destination'].trim()  }}{% elif message['role'] == 'system' %}{{ '\n' + 'Destination: assistant' }}{% elif message['role'] == 'user' %}{{ '\n' + 'Destination: assistant' }}{% elif message['role'] == 'assistant' %}{{ '\n' + 'Destination: user'  }}{% endif %}{{ '\n\n ' + message['content'].trim() + '<step>'  + ' '}}{% endfor %}{% if add_generation_prompt %}{{ 'Source: assistant' + '\n' }}{{ 'Destination: user' + '\n\n' + ' '  }}{% endif %}",
      "bos_token": "<s>",
      "step_id": "<step>",
      "stop": ["<step>"],
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:44:53.513Z",
    "update_at": "2024-01-29T00:44:53.513Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x050EF09acf1b439DCdd37E10d20bce12632eA5C6": 1
      },
      "asks_updated": "2024-02-15T05:34:26.945833175Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.010752688172043012,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f4ba752a299002ee4dc7",
    "name": "codellama/CodeLlama-70b-Python-hf",
    "display_name": "Code Llama Python (70B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-Python-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>"]
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:43:38.396Z",
    "update_at": "2024-01-29T00:43:38.396Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xCCFccc44f7422dD7CB8D6E127859471CF72e20C8": 1
      },
      "asks_updated": "2024-02-15T04:35:12.434086125Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.010752688172043012,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b6f4d4752a299002ee4dc8",
    "name": "codellama/CodeLlama-70b-hf",
    "display_name": "Code Llama (70B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/codellama/CodeLlama-70b-hf",
    "creator_organization": "Meta",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "70000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"]
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2024-01-29T00:44:04.149Z",
    "update_at": "2024-01-29T00:44:04.149Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x7Be40A415ddC632FD04aB624E22E9da36DeC3139": 1
      },
      "asks_updated": "2024-02-15T05:56:15.525275338Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.043478260869565216,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425e",
    "name": "codellama/CodeLlama-7b-Instruct-hf",
    "display_name": "Code Llama Instruct (7B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1108201BBBf248e2e14c2218aD141cBf3303AF40": 1
      },
      "asks_updated": "2024-02-15T10:19:51.746061885Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.25,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425d",
    "name": "codellama/CodeLlama-7b-Python-hf",
    "display_name": "Code Llama Python (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1004f5A60b273151460DAe0996911Bd44FbeDbCB": 1
      },
      "asks_updated": "2024-02-15T06:20:24.13267471Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.25,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c3137e4975e79f24d98b5c",
    "name": "deepseek-ai/deepseek-coder-33b-instruct",
    "display_name": "Deepseek Coder Instruct (33B)",
    "display_type": "chat",
    "description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
    "license": "deepseek",
    "link": "https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct",
    "creator_organization": "DeepSeek",
    "pricing_tier": "Featured",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 16384,
    "config": {
      "prompt_format": "",
      "stop": ["<|EOT|>", "<｜begin▁of▁sentence｜>", "<｜end▁of▁sentence｜>"],
      "bos_token": "<｜begin▁of▁sentence｜>",
      "add_generation_prompt": true,
      "chat_template": "{{'<｜begin▁of▁sentence｜>'}}{%- for message in messages %}{%- if message['role'] == 'system' %}{{ message['content'] }}{%- else %}{%- if message['role'] == 'user' %}{{'### Instruction:\\n' + message['content'] + '\\n'}}{%- else %}{{'### Response:\\n' + message['content'] + '\\n<|EOT|>\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt %}{{'### Response:'}}{% endif %}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2024-02-07T05:22:06.809Z",
    "update_at": "2024-02-07T05:22:06.809Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x24f375C2d3d04344EB5e84fd5C70102C15eD5d01": 1,
        "0xA22c74101B50b220323162b8B60c1Ce88Dfd9BDc": 1
      },
      "asks_updated": "2024-02-15T05:15:18.104578939Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.07142857142857142,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f676f7bc372ce719b97f04",
    "name": "garage-bAInd/Platypus2-70B-instruct",
    "display_name": "Platypus2 Instruct (70B)",
    "display_type": "chat",
    "description": "An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.",
    "license": "CC BY-NC-4.0",
    "creator_organization": "garage-bAInd",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "featured",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>", "###"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:31:51.264Z",
    "update_at": "2023-09-07T01:46:29.338Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6ab1B944C7166f2def77708632346c1b4b49bEF3": 1
      },
      "asks_updated": "2024-02-15T05:57:03.57394234Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 49.93333333333333,
      "throughput_out": 2.8666666666666667,
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.25,
          "qps": 0.06666666666666667,
          "throughput_in": 49.93333333333333,
          "throughput_out": 2.8666666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f678e7bc372ce719b97f06",
    "name": "lmsys/vicuna-13b-v1.5",
    "display_name": "Vicuna v1.5 (13B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "llama2",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:40:07.763Z",
    "update_at": "2023-09-05T00:40:07.763Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xe768dA5554653182D862E3b439Da46164C19385C": 1
      },
      "asks_updated": "2024-02-15T08:01:07.583195401Z",
      "gpus": {
        "": 0
      },
      "qps": 0.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 195.66666666666666,
      "throughput_out": 33.6,
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.09090909090909093,
          "qps": 0.2,
          "throughput_in": 195.66666666666666,
          "throughput_out": 33.6,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "652da26579174a6bc507647f",
    "name": "lmsys/vicuna-7b-v1.5",
    "display_name": "Vicuna v1.5 (7B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738415616,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["</s>", "USER:"],
      "prompt_format": "USER: {prompt}\nASSISTANT: Hello!",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-16T20:51:49.194Z",
    "update_at": "2023-10-16T20:51:49.194Z",
    "instances": [
      {
        "avzone": "us-west-1a",
        "cluster": "curiouscrow"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x76AA761551eB1101f47bB68DF795391401719581": 1
      },
      "asks_updated": "2024-02-15T07:36:27.690527579Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-west-1a",
          "cluster": "curiouscrow",
          "capacity": 0.047619047619047616,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd95e620478cfa144257",
    "name": "meta-llama/Llama-2-70b-chat-hf",
    "display_name": "LLaMA-2 Chat (70B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x198A6dcE6D27d7bcB2238C1cf2e02DB70690e358": 1,
        "0x4f60B27369644fb21f8787aa416832015760103C": 1,
        "0xf9686559D2236c5ae1F0CA96AA9FDFD0F9c50973": 1
      },
      "asks_updated": "2024-02-15T10:17:23.983289208Z",
      "gpus": {
        "": 0
      },
      "qps": 3,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1088.4,
      "throughput_out": 392.3333333333333,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.039727393617021274,
          "qps": 1.5333333333333334,
          "throughput_in": 558.9333333333333,
          "throughput_out": 190.73333333333332,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.011463994565217392,
          "qps": 1.4666666666666666,
          "throughput_in": 529.4666666666667,
          "throughput_out": 201.6,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6dd0ee620478cfa144256",
    "name": "meta-llama/Llama-2-70b-hf",
    "display_name": "LLaMA-2 (70B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-hf",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      },
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 5,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x14f768dAce2e209Fb1D23D7ed76ffcf2F6F36420": 1,
        "0x7249005ac4e3A43770320d9e66aee26055ec495e": 1,
        "0x7C7Bc88Fdd48205981c3e8eacDD8F037f2b24389": 1,
        "0x91EaA742E8962108b749b9357892ca4F4681Ede8": 1,
        "0xb2b66b174BFDDE8E62039Bd1D590404F734d0582": 1,
        "0xdAC0E70D520b97862285525d74dcb752c05Ea384": 1
      },
      "asks_updated": "2024-02-15T10:07:48.547638751Z",
      "gpus": {
        "": 0
      },
      "qps": 174.53333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 9077.6,
      "throughput_out": 1007.4666666666667,
      "retry_rate": 0.7333333333333334,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.5012003757698079,
          "qps": 88.93333333333334,
          "throughput_in": 4623.066666666667,
          "throughput_out": 506.6,
          "error_rate": 0,
          "retry_rate": 0.4
        },
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.5371696299855832,
          "qps": 85.6,
          "throughput_in": 4454.533333333334,
          "throughput_out": 500.8666666666667,
          "error_rate": 0,
          "retry_rate": 0.3333333333333333
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b40661251b2ff9f146d8ba",
    "name": "microsoft/phi-2",
    "display_name": "Microsoft Phi-2",
    "display_type": "language",
    "description": "Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (for safety and educational value)",
    "license": "mit",
    "link": "https://huggingface.co/microsoft/phi-2",
    "creator_organization": "Microsoft",
    "pricing_tier": "Featured",
    "num_parameters": 2700000000,
    "release_date": "2024-01-26T19:22:09.533Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-01-26T19:22:09.533Z",
    "update_at": "2024-01-26T19:23:46.072Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xD13D60186eC2F972F3290F6e9E4994d67923e5fe": 1
      },
      "asks_updated": "2024-02-15T03:58:48.699819707Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.027777777777777776,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6514c873829715ded9cd17b1",
    "name": "mistralai/Mistral-7B-Instruct-v0.1",
    "display_name": "Mistral (7B) Instruct",
    "display_type": "chat",
    "description": "instruct fine-tuned version of Mistral-7B-v0.1",
    "license": "Apache-2",
    "creator_organization": "mistralai",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 7241732096,
    "release_date": "2023-09-27T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["[/INST]", "</s>"],
      "prompt_format": "<s>[INST] {prompt} [/INST]",
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-09-28T00:27:31.815Z",
    "update_at": "2023-10-12T01:13:51.840Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      },
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xd67c558915095d7fe3D8762B09eb97A143202602": 1,
        "0xf77C7E9E44521eC5Da12982d9EB6840Ab35ab08b": 1
      },
      "asks_updated": "2024-02-15T06:54:03.303415522Z",
      "gpus": {
        "": 0
      },
      "qps": 4.4,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1186.3333333333333,
      "throughput_out": 648.5333333333333,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.13532110091743124,
          "qps": 2.3333333333333335,
          "throughput_in": 616.8,
          "throughput_out": 358.6666666666667,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.12655512655512638,
          "qps": 2.066666666666667,
          "throughput_in": 569.5333333333333,
          "throughput_out": 289.8666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65776c7d6923087ddd5a660a",
    "name": "mistralai/Mistral-7B-Instruct-v0.2",
    "display_name": "Mistral (7B) Instruct v0.2",
    "display_type": "chat",
    "description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1.",
    "license": "apache-2.0",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama",
      "tools_template": "{{ 'If you need to invoke any of the following functions:\n' + tools + '\nplease respond in the following JSON format:\n[\n\n  {\n    \"name\": \"the name of the function to be invoked\",\n    \"arguments\": {\"key1\": \"value1\", \"key2\": \"value2\", ...}\n  }\n]\nIf any required arguments are missing, please ask for them without JSON function calls.\nIf the instruction does not necessitate a function call, please provide your response in clear, concise natural language.\n\n' + message['content'] }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-12-11T20:09:33.627Z",
    "update_at": "2023-12-11T20:09:33.627Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 9,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x00c309c3Badef94Bde9a29981EeC9A1ADB3eA840": 1,
        "0x178Dc1F817dEe7005e9cf3e4dC8989e8334d67e8": 1,
        "0x405F5C81729E1Bad61F78324bE3B88D0e50F51DB": 1,
        "0x42d46C44645Cd7D7fE783F1D6017Ab718B2d7629": 1,
        "0x91c4d39FeD6617aE769f2197db9c9F0AB7F20ccb": 1,
        "0x9366AbCEcC34F575355DEc8097425092FeeaDB02": 1,
        "0xA10410EA0F80e23eBD09561abf1D1147FF94b953": 1,
        "0xB8F48aA00f0Af352C36f976Fc3cf1300D3771254": 1,
        "0xD78696D61c19755cbf3092F89dCa6f116d3822dF": 1
      },
      "asks_updated": "2024-02-15T07:41:03.711494287Z",
      "gpus": {
        "": 0
      },
      "qps": 0.9333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 724.3333333333334,
      "throughput_out": 66.2,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.11549707602339161,
          "qps": 0.9333333333333333,
          "throughput_in": 724.3333333333334,
          "throughput_out": 66.2,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6514c6ee829715ded9cd17b0",
    "name": "mistralai/Mistral-7B-v0.1",
    "display_name": "Mistral (7B)",
    "display_type": "language",
    "description": "7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost",
    "license": "Apache-2",
    "creator_organization": "mistralai",
    "hardware_label": "2x A100 80GB",
    "num_parameters": 7241732096,
    "release_date": "2023-09-27T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "{prompt}",
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-09-28T00:21:02.330Z",
    "update_at": "2023-09-28T00:21:02.330Z",
    "instances": [
      {
        "avzone": "us-central-2a",
        "cluster": "jollyllama"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xd3F86c85035E331BB9fC815765f3168aa663e57f": 1
      },
      "asks_updated": "2024-02-15T05:17:57.378634288Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-2a",
          "cluster": "jollyllama",
          "capacity": 0.045454545454545456,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6577af4434e6c1e2bb5283d8",
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "display_name": "Mixtral-8x7B Instruct v0.1",
    "display_type": "chat",
    "description": "The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2023-12-12T00:54:28.108Z",
    "update_at": "2024-02-08T07:58:24.624Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-central-6a",
        "cluster": "mirthfulmonkey"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 16,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1944C0439e83DB17b568638386d5B1153C5DC3A9": 1,
        "0x3e1C076F497F14723F1529D4E921A97dEff3f638": 1,
        "0x461d505feBE72731a5aBf3ceacb7213c58818bF4": 1,
        "0x4Fcf8EE62C8D67107267E644DC122b084BFF3f07": 1,
        "0x51323eBC4030d9430D04735Cac41e545D6C9282e": 1,
        "0x61Ee2675565050A5255963f1315A7CfCF86a70aD": 1,
        "0x6f25390A2eacFb96B4ceEB19C20E04400F21d38C": 1,
        "0x8c05566C6C843BDA0cc0C9981b439623E5105c42": 1,
        "0xAdD0a58e99F38B0D9dE3A9BB6E143Cd0785FF18c": 1,
        "0xC2Ec46E9a40bD885f85cafbf9e36f9F42A177314": 1,
        "0xC707257E0058b28A6FD4C1fA18Bd3a8D9513B4Ac": 1,
        "0xE26fd10b1Ec7aC2d1daFb5212b5D5876F0D076F7": 1,
        "0xb1439889F292f69F8b8796c5dDf4f397043667e1": 1,
        "0xc24B30847918aBA03f7E34158eEc47e409eA10e3": 1,
        "0xc6Aa579d2c2647Ae20382c822B9Ac0510415c79f": 1,
        "0xcAE8c408aB064014401E00AaE508F86CEC9f34B3": 1
      },
      "asks_updated": "2024-02-15T10:18:38.080486301Z",
      "gpus": {
        "": 0
      },
      "qps": 19.733333333333334,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 13962.066666666668,
      "throughput_out": 3489.0666666666666,
      "stats": [
        {
          "avzone": "us-central-6a",
          "cluster": "mirthfulmonkey",
          "capacity": 0.21643032559613487,
          "qps": 19.733333333333334,
          "throughput_in": 13962.066666666668,
          "throughput_out": 3489.0666666666666,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6577bf1034e6c1e2bb5283d9",
    "name": "mistralai/Mixtral-8x7B-v0.1",
    "display_name": "Mixtral-8x7B v0.1",
    "display_type": "language",
    "description": "The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "creator_organization": "mistralai",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "56000000000",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "input": 150,
      "output": 150,
      "hourly": 0
    },
    "created_at": "2023-12-12T02:01:52.674Z",
    "update_at": "2024-02-08T07:58:39.848Z",
    "autopilot_pool": "cr-a100-80-2x",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4250B2Bee33537ce172E5eB4B0222f750A7Dc7d2": 1
      },
      "asks_updated": "2024-02-15T08:33:04.449086975Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0.15384615384615385,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657b7a2a84ef58c3562de91e",
    "name": "openchat/openchat-3.5-1210",
    "display_name": "OpenChat 3.5",
    "display_type": "chat",
    "description": "A merge of OpenChat 3.5 was trained with C-RLFT on a collection of publicly available high-quality instruction data, with a custom processing pipeline.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/openchat/openchat-3.5-1210",
    "creator_organization": "OpenChat",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "7000000000",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'] + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
      "stop": ["<|end_of_turn|>", "</s>"],
      "add_generation_prompt": true,
      "bos_token": "<s>",
      "prompt_format": "GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-12-14T21:56:58.576Z",
    "update_at": "2023-12-14T21:56:58.576Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xABDf5E3162B18e8ddA01478386c88dC1021A7383": 1
      },
      "asks_updated": "2024-02-15T04:37:56.738666421Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.04054054054054054,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aced5c227f790586239d2b",
    "name": "prompthero/openjourney",
    "display_name": "Openjourney v4",
    "display_type": "image",
    "description": "An open source Stable Diffusion model fine tuned model on Midjourney images. ",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/prompthero/openjourney",
    "creator_organization": "Prompt Hero",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 512,
      "width": 512,
      "steps": 20,
      "number_of_images": 2,
      "seed": 42
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:49:16.586Z",
    "update_at": "2023-07-11T05:49:16.586Z",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85": 1,
        "0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556": 1
      },
      "asks_updated": "2024-02-15T07:40:59.32019033Z",
      "gpus": {
        "NVIDIA A40": 2
      },
      "options": {
        "input=text,image": 2
      },
      "qps": 0.011949728,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.2150951
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece1",
    "name": "runwayml/stable-diffusion-v1-5",
    "display_name": "Stable Diffusion 1.5",
    "display_type": "image",
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/runwayml/stable-diffusion-v1-5",
    "creator_organization": "Runway ML",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "height": 512,
      "width": 512,
      "steps": 20,
      "number_of_images": 2,
      "seed": 42
    },
    "created_at": "2023-06-23T20:22:43.572Z",
    "update_at": "2023-06-23T20:22:43.572Z",
    "access": "",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    },
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8": 1
      },
      "asks_updated": "2024-02-15T07:40:59.450575431Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.011949728,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.2150951
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65460075c5ce2e5fa70d6721",
    "name": "sentence-transformers/msmarco-bert-base-dot-v5",
    "display_name": "Sentence-BERT",
    "display_type": "embedding",
    "description": "A sentence-transformers model: it maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/sentence-transformers/msmarco-bert-base-dot-v5",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 110000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 512,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T08:27:33.867Z",
    "update_at": "2023-12-22T03:15:44.832Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x12A5aA174921D1A107E2c4f8a1b7fbf262B548e3": 1,
        "0x662c7EE2ca9D3D4fAbcEE2286C1bbc5f24CA02fD": 1
      },
      "asks_updated": "2024-02-15T07:41:03.928175793Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65b454f3d9877b0bd1376470",
    "name": "snorkelai/Snorkel-Mistral-PairRM-DPO",
    "display_name": "Snorkel Mistral PairRM DPO (7B)",
    "display_type": "chat",
    "description": "A state-of-the-art model by Snorkel AI, DPO fine-tuned on Mistral-7B",
    "license": "apache-2.0",
    "creator_organization": "Snorkel AI",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2024-01-27T00:57:23.638Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-01-27T00:57:23.638Z",
    "update_at": "2024-01-27T14:24:41.745Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "hardware_label": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x905d9333Bf36FC9fD26b130adaaEe6f5Bd4E800f": 1
      },
      "asks_updated": "2024-02-15T10:15:27.995120394Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.1111111111111111,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acef00227f790586239d3b",
    "name": "stabilityai/stable-diffusion-2-1",
    "display_name": "Stable Diffusion 2.1",
    "display_type": "image",
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "license": "openrail++",
    "link": "https://huggingface.co/stabilityai/stable-diffusion-2-1",
    "creator_organization": "Stability AI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "created_at": "2023-06-23T20:22:43.572Z",
    "update_at": "2023-06-23T20:22:43.572Z",
    "access": "",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    },
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xC9494f3A014EAC6DD43De5b03E03364F1AcC9ea7": 1
      },
      "asks_updated": "2024-02-15T07:41:00.004463183Z",
      "gpus": {
        "NVIDIA A100 80GB PCIe": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.011949728,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.2150951
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64c9890c689aa3b286cfcff9",
    "name": "stabilityai/stable-diffusion-xl-base-1.0",
    "display_name": "Stable Diffusion XL 1.0",
    "display_type": "image",
    "description": "A text-to-image generative AI model that excels at creating 1024x1024 images.",
    "license": "openrail++",
    "link": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",
    "creator_organization": "Stability AI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "config": {
      "seed": 1000,
      "height": 1024,
      "width": 1024,
      "steps": 40,
      "number_of_images": 4
    },
    "created_at": "2023-08-01T22:37:00.851Z",
    "update_at": "2023-08-01T22:37:00.851Z",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    },
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2E595c6ee5e62FeFF9f426b239a2fB0970476593": 1
      },
      "asks_updated": "2024-02-15T07:40:50.043506986Z",
      "gpus": {
        "NVIDIA A100 80GB PCIe": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.025269663,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.21509568
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "653c053fd9679a84df55c4e7",
    "name": "teknium/OpenHermes-2-Mistral-7B",
    "display_name": "OpenHermes-2-Mistral (7B)",
    "display_type": "chat",
    "description": "State of the art Mistral Fine-tuned on extensive public datasets",
    "license": "Apache-2",
    "creator_organization": "teknium",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-10-27T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["<|im_end|>", "<|im_start|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "pre_prompt": "<|im_start|>system\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-27T18:45:19.307Z",
    "update_at": "2023-10-27T23:53:05.438Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      },
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0916A27F8b14De53BE968F395dFb041b1564d828": 1,
        "0x4CB31b3AA66Deb84917CD1f252ca09AfBb11284C": 1
      },
      "asks_updated": "2024-02-15T06:13:24.310845275Z",
      "gpus": {
        "": 0
      },
      "qps": 0.2,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 134.73333333333332,
      "throughput_out": 12.266666666666667,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.07024793388429752,
          "qps": 0.06666666666666667,
          "throughput_in": 25.466666666666665,
          "throughput_out": 0.4,
          "error_rate": 0,
          "retry_rate": 0
        },
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.18253968253968253,
          "qps": 0.13333333333333333,
          "throughput_in": 109.26666666666667,
          "throughput_out": 11.866666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "655667fe6664bf7229b2dc6c",
    "name": "teknium/OpenHermes-2p5-Mistral-7B",
    "display_name": "OpenHermes-2.5-Mistral (7B)",
    "display_type": "chat",
    "description": "Continuation of OpenHermes 2 Mistral model trained on additional code datasets",
    "license": "Apache-2",
    "creator_organization": "teknium",
    "hardware_label": "A40",
    "pricing_tier": "Featured",
    "num_parameters": 7241732096,
    "release_date": "2023-11-15T00:00:00.000Z",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["<|im_end|>", "<|im_start|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-11-16T19:05:34.976Z",
    "update_at": "2023-11-16T19:12:24.883Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x5d7AD325990943DdE38302C299A0F92896247644": 1
      },
      "asks_updated": "2024-02-15T09:54:40.258490138Z",
      "gpus": {
        "": 0
      },
      "qps": 1.8666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 2057.2,
      "throughput_out": 404.73333333333335,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.2667440960123883,
          "qps": 1.8666666666666667,
          "throughput_in": 2057.2,
          "throughput_out": 404.73333333333335,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece3",
    "name": "togethercomputer/GPT-JT-Moderation-6B",
    "display_name": "GPT-JT-Moderation (6B)",
    "display_type": "language",
    "description": "This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 6700000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template": "Possible labels:\n1. casual\n2. needs caution\n3. needs intervention\n4. possibly needs caution\n5. probably needs caution\nInput: Hi!\nOutput: casual\nInput: I want to kill my cat.\nOutput: needs intervention\nInput: How to poison my dog?\nOutput: needs intervention\nInput: I don't want to talk to my brother\nOutput: probably needs caution\nInput: Today we had a disagreement and  \nwe got into a screaming fight. I don't want to talk.\nOutput: probably needs caution\nInput: My brother is being an asshole... Fuck him.\nOutput: needs caution\nInput: Hello.\nOutput: casual\nInput: {% for message in messages %}{{ message.content }}{{ eos_token }}{% endfor %}\nOutput:",
      "safety_label": "casual",
      "safety_config": {
        "temperature": 0.2,
        "top_p": 1,
        "max_tokens": 10,
        "stop": ["\n"]
      }
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.657Z",
    "update_at": "2023-06-23T20:22:43.657Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "testytiger"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xA6088D16A0d5b65430087E9ba98375f71469582E": 1
      },
      "asks_updated": "2024-02-15T04:35:40.149360507Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "testytiger",
          "capacity": 0.07500000000000001,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64c28e8742fa06a9511509d1",
    "name": "togethercomputer/LLaMA-2-7B-32K",
    "display_name": "LLaMA-2-32K (7B)",
    "display_type": "language",
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.",
    "license": "Meta license",
    "link": "https://huggingface.co/togethercomputer/LLaMA-2-7B-32K",
    "creator_organization": "Together",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": ["\n\n\n\n", "<|endoftext|>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-27T15:34:31.581Z",
    "update_at": "2023-08-17T17:07:36.346Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 6,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x080F7061c1135A4E90227980EB24Ad9fE0E8948e": 1,
        "0xA54EccfE808D8Fd4318792bDf78A75141a7EC5d3": 1,
        "0xa813BB4F6AD14c5589C423860979983487EE5389": 1,
        "0xd96e7256980b11c0D3c223cd320147E85228dFfb": 1,
        "0xe2Ff656f822d09b898bF37877fAf5f0F8117d497": 1,
        "0xe97ca5cb55Bfe7F90938A7865F650F5d65fAc3A3": 1
      },
      "asks_updated": "2024-02-15T10:18:15.922377717Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 1,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64de96090d052d10425df3c9",
    "name": "togethercomputer/Llama-2-7B-32K-Instruct",
    "display_name": "LLaMA-2-7B-32K-Instruct (7B)",
    "display_type": "chat",
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together",
    "license": "Meta license",
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "creator_organization": "Together",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "[INST]\n {prompt} \n[/INST]\n\n",
      "stop": ["[INST]", "\n\n"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-27T15:34:31.581Z",
    "update_at": "2023-08-17T17:07:36.346Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 6,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x1436160Ef715a81cBB1a3eB716945C4C56F737Ff": 1,
        "0x512FBf0B2574D8ba348C57CA212a40Dec624c798": 1,
        "0x82815f4BD5A58C8748fEcd9A12FB5f2E5a0622Ba": 1,
        "0x9cfcC352D5F64d021755e5D028655927a577d5eC": 1,
        "0xC037AAAdc952dE3573d9f13b03d6A662369dAa47": 1,
        "0xd00094Ea9465190c22CB832C01Eb2ee807cE1f9F": 1
      },
      "asks_updated": "2024-02-15T09:49:44.304384433Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 1,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64efd5511b76196fc5a54872",
    "name": "togethercomputer/Qwen-7B-Chat",
    "display_name": "Qwen-Chat (7B)",
    "display_type": "chat",
    "description": "7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques.   ",
    "license": "Tongyi Qianwen LICENSE AGREEMENT",
    "creator_organization": "Qwen",
    "hardware_label": "1x A100 80GB",
    "num_parameters": 7000000000,
    "release_date": "2023-08-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["<|im_end|>", "<|im_start|>"],
      "prompt_format": "\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-30T23:48:33.852Z",
    "update_at": "2023-09-07T01:49:42.840Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xb1e57eD0d782829125ADa4613be842a523aFD2C9": 1
      },
      "asks_updated": "2024-02-15T07:42:34.568355933Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64efcc2a1b76196fc5a54870",
    "name": "togethercomputer/Qwen-7B",
    "display_name": "Qwen (7B)",
    "display_type": "language",
    "description": "7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc. ",
    "license": "Tongyi Qianwen LICENSE AGREEMENT",
    "creator_organization": "Qwen",
    "hardware_label": "1x A100 80GB",
    "num_parameters": 7000000000,
    "release_date": "2023-08-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "config": {
      "stop": ["<|im_end|>", "<|endoftext|>"],
      "add_generation_prompt": true,
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-30T23:09:30.570Z",
    "update_at": "2023-09-07T01:49:24.716Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xABa7da50E0546db174c1b4c5B60258838DA909B0": 1
      },
      "asks_updated": "2024-02-15T08:45:24.987985677Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aeceb",
    "name": "togethercomputer/RedPajama-INCITE-7B-Base",
    "display_name": "RedPajama-INCITE (7B)",
    "display_type": "language",
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/redpajama-models-v1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.033Z",
    "update_at": "2023-06-23T20:22:44.033Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x9F9dc194aA98148c1C9A52Dc197EDFBdf32Db9a9": 1
      },
      "asks_updated": "2024-02-15T07:41:03.370130732Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.01171875,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aeced",
    "name": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "display_name": "RedPajama-INCITE Chat (7B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat",
    "creator_organization": "Together",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": ["<human>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.190Z",
    "update_at": "2023-06-23T20:22:44.190Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x25C9f9263DCbB16597cfe1b6bf8293971A277BAC": 1
      },
      "asks_updated": "2024-02-15T07:41:03.668736615Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.01171875,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecec",
    "name": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "display_name": "RedPajama-INCITE Instruct (7B)",
    "display_type": "language",
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct",
    "creator_organization": "Together",
    "hardware_label": "A100 80GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "6857302016",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.083Z",
    "update_at": "2023-06-23T20:22:44.083Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x007FdA772e56cF406Dc6a907E96728864B3F6663": 1
      },
      "asks_updated": "2024-02-15T07:40:51.955840823Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece5",
    "name": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "display_name": "RedPajama-INCITE (3B)",
    "display_type": "language",
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/redpajama-models-v1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.751Z",
    "update_at": "2023-06-23T20:22:43.751Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xEEe584b521fe7CC593aeDc2E5d2A510292D3698A": 1
      },
      "asks_updated": "2024-02-15T07:40:57.277964218Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece7",
    "name": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "display_name": "RedPajama-INCITE Chat (3B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": ["<human>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.839Z",
    "update_at": "2023-06-23T20:22:43.839Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x39a47C489b801ceBD66423D50F8c92D7b09eddcC": 1
      },
      "asks_updated": "2024-02-15T07:40:51.134190754Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece6",
    "name": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "display_name": "RedPajama-INCITE Instruct (3B)",
    "display_type": "language",
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": "2775864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.796Z",
    "update_at": "2023-06-23T20:22:43.796Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x0eFB61661ae0a1eBCDd4129D6BE1938225cB35a9": 1
      },
      "asks_updated": "2024-02-15T07:41:03.654798685Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.01171875,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65735df36923087ddd5a6607",
    "name": "togethercomputer/StripedHyena-Hessian-7B",
    "display_name": "StripedHyena Hessian (7B)",
    "display_type": "language",
    "description": "A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers",
    "license": "Apache-2",
    "creator_organization": "Together",
    "hardware_label": "H100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-12-08T18:18:27.005Z",
    "update_at": "2023-12-08T19:03:32.567Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x65a60a88BD4ae232c33346330956fC1819aC56ed": 1
      },
      "asks_updated": "2024-02-15T06:19:39.932285013Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.03571428571428571,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65735d536923087ddd5a6606",
    "name": "togethercomputer/StripedHyena-Nous-7B",
    "display_name": "StripedHyena Nous (7B)",
    "display_type": "chat",
    "description": "A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers",
    "license": "Apache-2",
    "creator_organization": "Together",
    "hardware_label": "H100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "stop": ["###", "</s>"],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ bos_token + '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n'  + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ '### Response:\\n' }}{% endif %}{% endfor %}"
    },
    "pricing": {
      "input": 50,
      "output": 50
    },
    "created_at": "2023-12-08T18:15:47.433Z",
    "update_at": "2023-12-08T19:03:11.497Z",
    "instances": [
      {
        "avzone": "ap-northeast-1a",
        "cluster": "optimisticotter"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6406701BcD6ED79271da200b05e645965C6597C6": 1
      },
      "asks_updated": "2024-02-15T04:38:28.177938172Z",
      "gpus": {
        "": 0
      },
      "qps": 1.3333333333333333,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 1899.1333333333334,
      "throughput_out": 38,
      "stats": [
        {
          "avzone": "ap-northeast-1a",
          "cluster": "optimisticotter",
          "capacity": 0.03839285714285713,
          "qps": 1.3333333333333333,
          "throughput_in": 1899.1333333333334,
          "throughput_out": 38,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace317227f790586239ce2",
    "name": "togethercomputer/alpaca-7b",
    "display_name": "Alpaca (7B)",
    "display_type": "chat",
    "description": "Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ",
    "license": "cc-by-nc-4.0",
    "link": "https://huggingface.co/tatsu-lab/alpaca-7b-wdiff",
    "creator_organization": "Stanford",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": ["</s>", "###"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:05:27.713Z",
    "update_at": "2023-07-11T05:05:27.713Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x93AAe4543cbb2881e1e97572382869F83f6Ca878": 1
      },
      "asks_updated": "2024-02-15T07:41:00.473815042Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.020833333333333332,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace614227f790586239cf7",
    "name": "togethercomputer/falcon-40b-instruct",
    "display_name": "Falcon Instruct (40B)",
    "display_type": "chat",
    "description": "Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ",
    "license": "apache-2.0",
    "link": "https://huggingface.co/tiiuae/falcon-40b-instruct",
    "creator_organization": "TII UAE",
    "hardware_label": "2X A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 40000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "prompt_format": "User: {prompt}\nAssistant:",
      "stop": ["User:", "</s>"],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:18:12.323Z",
    "update_at": "2023-07-11T05:18:12.323Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xc3dCAEFb2fB24EcAf7C84eFeB4c59D6Ae1308290": 1
      },
      "asks_updated": "2024-02-15T03:58:48.956307062Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.01171875,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace59f227f790586239cf5",
    "name": "togethercomputer/falcon-40b",
    "display_name": "Falcon (40B)",
    "display_type": "language",
    "description": "Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/tiiuae/falcon-40b",
    "creator_organization": "TII UAE",
    "hardware_label": "2X A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 40000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:16:15.898Z",
    "update_at": "2023-07-11T05:16:15.898Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x36965DA0006E1B014eF3eA631C2B745AfB31452c": 1
      },
      "asks_updated": "2024-02-15T06:29:42.711961639Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace63d227f790586239cf8",
    "name": "togethercomputer/falcon-7b-instruct",
    "display_name": "Falcon Instruct (7B)",
    "display_type": "chat",
    "description": "Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ",
    "license": "apache-2.0",
    "link": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "creator_organization": "TII UAE",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "prompt_format": "User: {prompt}\nAssistant:",
      "stop": ["User:", "</s>"],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:18:53.623Z",
    "update_at": "2023-07-11T05:18:53.623Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xa7Fa07E7B1dFCaDC6846172ab1C5BCd9AFb754D7": 1
      },
      "asks_updated": "2024-02-15T06:06:05.327969781Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.01171875,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace5dd227f790586239cf6",
    "name": "togethercomputer/falcon-7b",
    "display_name": "Falcon (7B)",
    "display_type": "language",
    "description": "Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/tiiuae/falcon-7b",
    "creator_organization": "TII UAE",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:17:17.883Z",
    "update_at": "2023-07-11T05:17:17.883Z",
    "instances": [
      {
        "avzone": "us-central-5a",
        "cluster": "wrigleycub"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x925BBAC0441f02F46Af7A284D6FFFA7F885760C2": 1
      },
      "asks_updated": "2024-02-15T03:28:11.164753835Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-5a",
          "cluster": "wrigleycub",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e8",
    "name": "togethercomputer/llama-2-13b-chat",
    "display_name": "LLaMA-2 Chat (13B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/togethercomputer/llama-2-13b-chat",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:00:54.436Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x453FD020c749D9eeE5e08446B95E54bE1d874E32": 1
      },
      "asks_updated": "2024-02-15T10:12:45.910262652Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 155.33333333333334,
      "throughput_out": 8.466666666666667,
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.1,
          "qps": 0.06666666666666667,
          "throughput_in": 155.33333333333334,
          "throughput_out": 8.466666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e7",
    "name": "togethercomputer/llama-2-13b",
    "display_name": "LLaMA-2 (13B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/togethercomputer/llama-2-13b",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "13015864320",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-12-04T05:07:52.318Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x69577d61260247B9c96Dfd611EA6372e0cdcC508": 1
      },
      "asks_updated": "2024-02-15T07:40:53.703135101Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.1,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e6",
    "name": "togethercomputer/llama-2-7b-chat",
    "display_name": "LLaMA-2 Chat (7B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/togethercomputer/llama-2-7b-chat",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x3e9A4Dd89FD31E9072f6141d81B5F2fC3079C580": 1
      },
      "asks_updated": "2024-02-15T07:40:58.635409697Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.05000000000000001,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e5",
    "name": "togethercomputer/llama-2-7b",
    "display_name": "LLaMA-2 (7B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "LLaMA license Agreement (Meta)",
    "link": "https://huggingface.co/togethercomputer/llama-2-7b",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "6738415616",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x370dfBC1cc49e89f208150381Eb121E4C7271BF9": 1
      },
      "asks_updated": "2024-02-15T07:40:58.457789975Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.05,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6553b8da6664bf7229b2dbfb",
    "name": "togethercomputer/m2-bert-80M-2k-retrieval",
    "display_name": "M2-BERT-Retrieval-2K",
    "display_type": "embedding",
    "description": "M2-BERT from the Monarch Mixer paper fine-tuned for retrieval",
    "license": "Apache-2",
    "creator_organization": "Together Computer",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "num_parameters": 80000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-14T18:13:46.901Z",
    "update_at": "2023-12-22T03:13:15.108Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x4e74AAf1C6f7491fc1a983F656dF0711DC85D510": 1
      },
      "asks_updated": "2024-02-15T08:26:34.513426991Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6585058be7e2e898e81b5401",
    "name": "togethercomputer/m2-bert-80M-32k-retrieval",
    "display_name": "M2-BERT-Retrieval-32k",
    "display_type": "embedding",
    "description": "The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 80000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T17:57:24.532Z",
    "update_at": "2023-11-04T17:57:24.532Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x6Ce6AECb696A379a802fb2D1DA6e37DAA4cf538a": 1
      },
      "asks_updated": "2024-02-15T07:40:54.02877892Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65468604c5ce2e5fa70d6722",
    "name": "togethercomputer/m2-bert-80M-8k-retrieval",
    "display_name": "M2-BERT-Retrieval-8k",
    "display_type": "embedding",
    "description": "The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/m2-bert-80M-8k-retrieval",
    "creator_organization": "Together",
    "hardware_label": "L40",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 80000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 8192,
    "pricing": {
      "hourly": 0,
      "input": 2,
      "output": 2,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2023-11-04T17:57:24.532Z",
    "update_at": "2023-11-04T17:57:24.532Z",
    "instances": [
      {
        "avzone": "us-central-1a",
        "cluster": "sassyseal"
      }
    ],
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xd65b5c4D27804D99A0C1E7884EcE0466de3dA570": 1
      },
      "asks_updated": "2024-02-15T07:40:50.087283729Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-central-1a",
          "cluster": "sassyseal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657f7552a9c4049b6a42e4c6",
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "display_name": "Upstage SOLAR Instruct v1 (11B)",
    "display_type": "chat",
    "description": "Built on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage Depth Up-Scaling",
    "license": "cc-by-nc-4.0",
    "creator_organization": "upstage",
    "hardware_label": "A100B",
    "pricing_tier": "Featured",
    "num_parameters": 10700000000,
    "release_date": "2023-12-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["###", "</s>"],
      "prompt_format": "<s> ### User:\n{prompt}\n### Assistant:\n"
    },
    "pricing": {
      "input": 75,
      "output": 75
    },
    "created_at": "2023-12-17T22:25:22.252Z",
    "update_at": "2023-12-17T22:32:58.075Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xdDEE94E47556463eF0a8B26841474Fe00c47e2fC": 1
      },
      "asks_updated": "2024-02-15T04:58:41.373282144Z",
      "gpus": {
        "": 0
      },
      "qps": 0.06666666666666667,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.6,
      "throughput_out": 2.066666666666667,
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.031007751937984496,
          "qps": 0.06666666666666667,
          "throughput_in": 0.6,
          "throughput_out": 2.066666666666667,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace3af227f790586239ce6",
    "name": "wavymulder/Analog-Diffusion",
    "display_name": "Analog Diffusion",
    "display_type": "image",
    "description": "Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ",
    "license": "creativeml-openrail-m",
    "link": "https://huggingface.co/wavymulder/Analog-Diffusion",
    "creator_organization": "Wavymulder",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 0,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "external_pricing_url": "https://www.together.xyz/apis#pricing",
    "created_at": "2023-07-11T05:07:59.364Z",
    "update_at": "2023-07-11T05:07:59.364Z",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    },
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xC830b3583bcA51887185318c0184fbdB622A55f5": 1
      },
      "asks_updated": "2024-02-15T07:40:59.134754582Z",
      "gpus": {
        "NVIDIA A40": 1
      },
      "options": {
        "input=text,image": 1
      },
      "qps": 0.011949728,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "throughput_in": 0.2150951
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656a79054d805f78df5fd530",
    "name": "zero-one-ai/Yi-34B-Chat",
    "display_name": "01-ai Yi Chat (34B)",
    "display_type": "chat",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "config": {
      "stop": ["<|im_start|>", "<|im_end|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "pre_prompt": ""
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "base": 0
    },
    "created_at": "2023-12-02T00:23:33.685Z",
    "update_at": "2023-12-02T00:26:55.827Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 2,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x40F27D8Da9b87066e1826BAAb110f41339C9Ab52": 1,
        "0xD721282B2e3b9Ed12Cc56a749C96cC43E5AB9B28": 1
      },
      "asks_updated": "2024-02-15T09:59:45.79429597Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.016129032258064516,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "656fa3548d9fd20968de9ba7",
    "name": "zero-one-ai/Yi-34B",
    "display_name": "01-ai Yi Base (34B)",
    "display_type": "language",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 34000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "pricing": {
      "input": 200,
      "output": 200
    },
    "created_at": "2023-12-05T22:25:24.982Z",
    "update_at": "2023-12-05T22:51:15.306Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0xab23aD1137c7f2A7FbFd3e84c90615308c8414FA": 1
      },
      "asks_updated": "2024-02-15T07:06:20.545632703Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.016129032258064516,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6570718281b9e1cf0455ec53",
    "name": "zero-one-ai/Yi-6B",
    "display_name": "01-ai Yi Base (6B)",
    "display_type": "language",
    "description": "The Yi series models are large language models trained from scratch by developers at 01.AI",
    "license": "yi-license",
    "creator_organization": "01.AI",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 6000000000,
    "release_date": "2023-11-01T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 4096,
    "pricing": {
      "input": 20,
      "output": 50
    },
    "created_at": "2023-12-06T13:05:06.567Z",
    "update_at": "2023-12-06T13:07:50.190Z",
    "instances": [
      {
        "avzone": "us-east-2a",
        "cluster": "jumpyjackal"
      }
    ],
    "access": "",
    "link": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "asks": {
        "0x2e30c657D4371207549a06E3f749E8542E93ff6C": 1
      },
      "asks_updated": "2024-02-15T09:03:20.697065714Z",
      "gpus": {
        "": 0
      },
      "qps": 0,
      "permit_required": false,
      "price": {
        "base": 0,
        "finetune": 0,
        "hourly": 0,
        "input": 0,
        "output": 0
      },
      "stats": [
        {
          "avzone": "us-east-2a",
          "cluster": "jumpyjackal",
          "capacity": 0.0078125,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c82e4975e79f24d98b53",
    "name": "Qwen/Qwen1.5-4B",
    "display_name": "Qwen 1.5 (4B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-4B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 4000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:14.800Z",
    "update_at": "2024-02-05T11:36:14.800Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 23.266666666666666,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 23.266666666666666
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8344975e79f24d98b54",
    "name": "Qwen/Qwen1.5-4B-Chat",
    "display_name": "Qwen 1.5 Chat (4B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-4B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 4000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:20.314Z",
    "update_at": "2024-02-05T11:36:20.314Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 13.333333333333334,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 13.333333333333334
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c83a4975e79f24d98b55",
    "name": "Qwen/Qwen1.5-7B",
    "display_name": "Qwen 1.5 (7B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-7B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:26.420Z",
    "update_at": "2024-02-05T11:36:26.420Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 13.333333333333334,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 13.333333333333334
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8404975e79f24d98b56",
    "name": "Qwen/Qwen1.5-7B-Chat",
    "display_name": "Qwen 1.5 Chat (7B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-7B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:32.804Z",
    "update_at": "2024-02-05T11:36:32.804Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 23.333333333333332,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 23.333333333333332
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c8474975e79f24d98b57",
    "name": "Qwen/Qwen1.5-14B",
    "display_name": "Qwen 1.5 (14B)",
    "display_type": "language",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-14B",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 14000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {},
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:39.431Z",
    "update_at": "2024-02-05T11:36:39.431Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 0,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 0
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65c0c84d4975e79f24d98b58",
    "name": "Qwen/Qwen1.5-14B-Chat",
    "display_name": "Qwen 1.5 Chat (14B)",
    "display_type": "chat",
    "description": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.",
    "license": "tongyi-qianwen-research",
    "link": "https://huggingface.co/Qwen/Qwen1.5-14B-Chat",
    "creator_organization": "Qwen",
    "pricing_tier": "Featured",
    "num_parameters": 14000000000,
    "show_in_playground": true,
    "isFeaturedModel": true,
    "context_length": 32768,
    "config": {
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
      "stop": ["<|im_end|>", "<|im_start|>"],
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2024-02-05T11:36:45.529Z",
    "update_at": "2024-02-05T11:36:45.529Z",
    "instances": [
      {
        "avzone": "us-east-1a",
        "cluster": "happypiglet"
      }
    ],
    "access": "",
    "hardware_label": "",
    "descriptionLink": "",
    "depth": {
      "num_asks": 1,
      "num_bids": 0,
      "num_running": 0,
      "qps": 0,
      "throughput_in": 0,
      "throughput_out": 0,
      "error_rate": 0,
      "retry_rate": 13.4,
      "stats": [
        {
          "avzone": "us-east-1a",
          "cluster": "happypiglet",
          "capacity": 0,
          "qps": 0,
          "throughput_in": 0,
          "throughput_out": 0,
          "error_rate": 0,
          "retry_rate": 13.4
        }
      ]
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbe",
    "name": "EleutherAI/pythia-1b-v0",
    "display_name": "Pythia (1B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 1000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.925Z",
    "update_at": "2023-06-23T20:22:41.925Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "649e1ccca073332e47742415",
    "name": "replit/replit-code-v1-3b",
    "display_name": "Replit-Code-v1 (3B)",
    "display_type": "code",
    "description": "replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.",
    "license": "",
    "link": "",
    "creator_organization": "Replit",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "limited",
    "num_parameters": 3000000000,
    "release_date": "2023-04-26T00:00:00.000Z",
    "show_in_playground": "true",
    "isFeaturedModel": false,
    "context_length": 2048,
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-30T00:07:40.594Z",
    "update_at": "2023-07-07T20:09:09.965Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecee",
    "name": "togethercomputer/Pythia-Chat-Base-7B-v0.16",
    "display_name": "Pythia-Chat-Base (7B)",
    "display_type": "chat",
    "description": "Chat model based on EleutherAI’s Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.",
    "license": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": ["<human>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.251Z",
    "update_at": "2023-06-23T20:22:44.251Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceada227f790586239d11",
    "name": "mosaicml/mpt-7b",
    "display_name": "MPT (7B)",
    "display_type": "language",
    "description": "Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:38:34.852Z",
    "update_at": "2023-07-15T03:06:20.780Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb0e227f790586239d12",
    "name": "togethercomputer/mpt-30b-chat",
    "display_name": "MPT-Chat (30B)",
    "display_type": "chat",
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 30000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|im_end|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:39:26.078Z",
    "update_at": "2023-07-11T05:39:26.078Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace6df227f790586239cfc",
    "name": "google/flan-t5-xl",
    "display_name": "Flan T5 XL (3B)",
    "display_type": "language",
    "description": "T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ",
    "license": "",
    "link": "",
    "creator_organization": "Google",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.261Z",
    "update_at": "2023-06-23T20:22:42.261Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acebe0227f790586239d17",
    "name": "NumbersStation/nsql-6B",
    "display_name": "NSQL (6B)",
    "display_type": "language",
    "description": "Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.",
    "license": "",
    "creator_organization": "Numbers Station",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 6000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:42:56.540Z",
    "update_at": "2023-07-11T05:42:56.540Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace9ca227f790586239d09",
    "name": "togethercomputer/Koala-7B",
    "display_name": "Koala (7B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt} GPT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:34:02.521Z",
    "update_at": "2023-07-11T05:34:02.521Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc0",
    "name": "EleutherAI/pythia-6.9b",
    "display_name": "Pythia (6.9B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 6900000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.044Z",
    "update_at": "2023-06-23T20:22:42.044Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb8",
    "name": "databricks/dolly-v2-12b",
    "display_name": "Dolly v2 (12B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["### End"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.607Z",
    "update_at": "2023-06-23T20:22:41.607Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb6",
    "name": "databricks/dolly-v2-3b",
    "display_name": "Dolly v2 (3B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["### End"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.524Z",
    "update_at": "2023-06-23T20:22:41.524Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc2",
    "name": "EleutherAI/gpt-neox-20b",
    "display_name": "GPT-NeoX (20B)",
    "display_type": "language",
    "description": "Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 20000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.132Z",
    "update_at": "2023-06-23T20:22:42.132Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbf",
    "name": "EleutherAI/pythia-2.8b-v0",
    "display_name": "Pythia (2.8B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "num_parameters": 2800000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.975Z",
    "update_at": "2023-06-23T20:22:41.975Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acebb2227f790586239d16",
    "name": "NousResearch/Nous-Hermes-13b",
    "display_name": "Nous Hermes (13B)",
    "display_type": "language",
    "description": "LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.",
    "license": "",
    "link": "",
    "creator_organization": "Nous Research",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:42:10.444Z",
    "update_at": "2023-07-11T05:42:10.444Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8d1227f790586239d03",
    "name": "togethercomputer/guanaco-65b",
    "display_name": "Guanaco (65B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 65000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:53.740Z",
    "update_at": "2023-07-11T05:29:53.740Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acf031227f790586239d44",
    "name": "lmsys/fastchat-t5-3b-v1.0",
    "display_name": "Vicuna-FastChat-T5 (3B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "stop": ["###", "</s>"],
      "prompt_format": "### Human: {prompt}\n### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\n' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:01:21.713Z",
    "update_at": "2023-07-11T06:01:21.713Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea6e227f790586239d0e",
    "name": "huggyllama/llama-7b",
    "display_name": "LLaMA (7B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:36:46.255Z",
    "update_at": "2023-07-11T05:36:46.255Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc9",
    "name": "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "display_name": "Open-Assistant StableLM SFT-7 (7B)",
    "display_type": "chat",
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "license": "",
    "link": "",
    "creator_organization": "LAION",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["<|endoftext|>"],
      "prompt_format": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.425Z",
    "update_at": "2023-06-23T20:22:42.425Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc1",
    "name": "EleutherAI/pythia-12b-v0",
    "display_name": "Pythia (12B)",
    "display_type": "language",
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.091Z",
    "update_at": "2023-06-23T20:22:42.091Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb28227f790586239d13",
    "name": "togethercomputer/mpt-7b-chat",
    "display_name": "MPT-Chat (7B)",
    "display_type": "chat",
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|im_end|>"],
      "prompt_format": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:39:52.024Z",
    "update_at": "2023-07-11T05:39:52.024Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecbc",
    "name": "EleutherAI/gpt-j-6b",
    "display_name": "GPT-J (6B)",
    "display_type": "language",
    "description": "Transformer model trained using Ben Wang's Mesh Transformer JAX. ",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 6000000000,
    "release_date": "2021-06-04T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.831Z",
    "update_at": "2023-06-23T20:22:41.831Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc8",
    "name": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "display_name": "Open-Assistant Pythia SFT-4 (12B)",
    "display_type": "chat",
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "license": "",
    "link": "",
    "creator_organization": "LAION",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 12000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "prompt_format": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.383Z",
    "update_at": "2023-06-23T20:22:42.383Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acf013227f790586239d43",
    "name": "lmsys/vicuna-7b-v1.3",
    "display_name": "Vicuna v1.3 (7B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:00:51.553Z",
    "update_at": "2023-07-11T06:00:51.553Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5cc",
    "name": "Phind/Phind-CodeLlama-34B-Python-v1",
    "display_name": "Phind Code LLaMA Python v1 (34B)",
    "display_type": "code",
    "description": "This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.",
    "license": "",
    "creator_organization": "Phind",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 33743970304,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "### Instruction:\n{prompt}\n### Response:\n",
      "stop": ["</s>", "###"],
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65ac4e5e75846d9d3ae5b836",
    "name": "NumbersStation/nsql-llama-2-7B",
    "display_name": "NSQL LLaMA-2 (7B)",
    "display_type": "code",
    "description": "NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks",
    "link": "",
    "creator_organization": "Numbers Station",
    "hardware_label": "A100",
    "pricing_tier": "Featured",
    "num_parameters": 7000000000,
    "release_date": "2024-01-20T22:51:10.492Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "pricing": {
      "hourly": 0,
      "input": 50,
      "output": 50,
      "finetune": 0,
      "base": 0
    },
    "created_at": "2024-01-20T22:51:10.492Z",
    "update_at": "2024-01-20T22:59:48.333Z",
    "access": "",
    "license": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf8",
    "name": "NousResearch/Nous-Hermes-Llama2-70b",
    "display_name": "Nous Hermes LLaMA-2 (70B)",
    "display_type": "chat",
    "description": "Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "license": "",
    "link": "",
    "creator_organization": "NousResearch",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["###", "</s>"],
      "prompt_format": "### Instruction:\n{prompt}\n\n### Response:\n",
      "chat_template_name": "llama",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:\n' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.404Z",
    "update_at": "2023-10-24T17:43:39.278Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f67555bc372ce719b97f03",
    "name": "WizardLM/WizardLM-70B-V1.0",
    "display_name": "WizardLM v1.0 (70B)",
    "display_type": "language",
    "description": "This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.",
    "license": "",
    "creator_organization": "WizardLM",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 70000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt} ASSISTANT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'ASSISTANT:' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:24:53.327Z",
    "update_at": "2023-09-05T00:24:53.327Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea57227f790586239d0d",
    "name": "huggyllama/llama-65b",
    "display_name": "LLaMA (65B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 65000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:36:23.656Z",
    "update_at": "2023-07-11T05:36:23.656Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64fbbc5adfdb1e4b06b5d5ce",
    "name": "lmsys/vicuna-13b-v1.5-16k",
    "display_name": "Vicuna v1.5 16K (13B)",
    "display_type": "chat",
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "license": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13015864320,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "stop": ["</s>"],
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-09T00:29:14.496Z",
    "update_at": "2023-09-09T00:29:14.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece4",
    "name": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "display_name": "GPT-NeoXT-Chat-Base (20B)",
    "display_type": "chat",
    "description": "Chat model fine-tuned from EleutherAI’s GPT-NeoX with over 40 million instructions on carbon reduced compute.",
    "license": "",
    "link": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 20000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "prompt_format": "<human>: {prompt}\n<bot>:",
      "stop": ["<human>"],
      "chat_template_name": "gpt"
    },
    "max_tokens": 995,
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.702Z",
    "update_at": "2023-06-23T20:22:43.702Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "657bed666aca120ac2af2fb7",
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "display_name": "Zephyr-7B-ß",
    "display_type": "chat",
    "description": "A fine-tuned version of Mistral-7B to act as a helpful assistant.",
    "license": "",
    "link": "",
    "creator_organization": "HuggingFace",
    "hardware_label": "2x A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 7241732096,
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 32768,
    "config": {
      "stop": ["[INST]", "</s>"],
      "prompt_format": "<s>[INST] {prompt} [INST]"
    },
    "created_at": "2023-12-15T06:08:38.925Z",
    "update_at": "2023-12-15T06:08:38.925Z",
    "descriptionLink": "",
    "pricing": {
      "hourly": 0,
      "input": 0,
      "output": 0,
      "base": 0,
      "finetune": 0
    }
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de96e620478cfa144262",
    "name": "codellama/CodeLlama-34b-hf",
    "display_name": "Code Llama (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78e89589782acafe1781d",
    "name": "togethercomputer/CodeLlama-7b-Instruct",
    "display_name": "Code Llama Instruct (7B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "renamed": "codellama/CodeLlama-7b-Instruct-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f0de22caa9e2eb543b373b",
    "name": "togethercomputer/guanaco-13b",
    "display_name": "Guanaco (13B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A40 48GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:07.717Z",
    "update_at": "2023-07-11T05:29:07.717Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17822",
    "name": "togethercomputer/CodeLlama-34b-Python",
    "display_name": "Code Llama Python (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-Python-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64aceb6f227f790586239d15",
    "name": "mosaicml/mpt-7b-instruct",
    "display_name": "MPT-Instruct (7B)",
    "display_type": "language",
    "description": "Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets",
    "license": "",
    "link": "",
    "creator_organization": "Mosaic ML",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["<|endoftext|>"],
      "chat_template_name": "default",
      "add_generation_prompt": true
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:41:03.757Z",
    "update_at": "2023-07-11T05:41:03.757Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07ea",
    "name": "togethercomputer/llama-2-70b-chat",
    "display_name": "LLaMA-2 Chat (70B)",
    "display_type": "chat",
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["[/INST]", "</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "renamed": "meta-llama/Llama-2-70b-chat-hf",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17823",
    "name": "togethercomputer/CodeLlama-34b-Instruct",
    "display_name": "Code Llama Instruct (34B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama",
      "tools_template": "{{ '<<SYS>>\\n' + systemMessage['content'] + '\\n\\nYou can access the following functions. Use them if required -\\n' + tools + '\\n<</SYS>>\\n\\n' + message['content'] }}"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-Instruct-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e7934a589782acafe17821",
    "name": "togethercomputer/CodeLlama-34b",
    "display_name": "Code Llama (34B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": 34000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 194,
      "output": 194,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:28:42.172Z",
    "update_at": "2023-08-24T17:28:42.172Z",
    "renamed": "codellama/CodeLlama-34b-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78eba589782acafe1781f",
    "name": "togethercomputer/CodeLlama-13b-Python",
    "display_name": "Code Llama Python (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-20T22:52:59.177Z",
    "renamed": "codellama/CodeLlama-13b-Python-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecf1",
    "name": "Salesforce/codegen2-16B",
    "display_name": "CodeGen2 (16B)",
    "display_type": "code",
    "description": "An autoregressive language models for program synthesis.",
    "license": "",
    "link": "",
    "creator_organization": "Salesforce",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 16000000000,
    "release_date": "2022-03-25T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["\n\n"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.453Z",
    "update_at": "2023-06-23T20:22:44.453Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace476227f790586239cef",
    "name": "Salesforce/codegen2-7B",
    "display_name": "CodeGen2 (7B)",
    "display_type": "code",
    "description": "An autoregressive language models for program synthesis.",
    "license": "",
    "link": "",
    "creator_organization": "Salesforce",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 7000000000,
    "release_date": "2022-03-25T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["\n\n"],
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:11:18.328Z",
    "update_at": "2023-07-11T05:11:18.328Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1212907e072b8aecc5",
    "name": "google/flan-t5-xxl",
    "display_name": "Flan T5 XXL (11B)",
    "display_type": "language",
    "description": "Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).",
    "creator_organization": "Google",
    "hardware_label": "A40 48GB",
    "access": "open",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 512,
    "config": {
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:42.261Z",
    "update_at": "2023-09-01T14:35:00.161Z",
    "license": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64b7165fcccc52103e2f07e9",
    "name": "togethercomputer/llama-2-70b",
    "display_name": "LLaMA-2 (70B)",
    "display_type": "language",
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "2X A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": "68976648192",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 225,
      "output": 225,
      "hourly": 0
    },
    "created_at": "2023-07-18T22:46:55.042Z",
    "update_at": "2023-07-18T22:46:55.042Z",
    "autopilot_pool": "cr-a100-80-2x",
    "renamed": "meta-llama/Llama-2-70b-hf",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425f",
    "name": "codellama/CodeLlama-7b-hf",
    "display_name": "Code Llama (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "65a6de95e620478cfa14425c",
    "name": "codellama/CodeLlama-13b-hf",
    "display_name": "Code Llama (13B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-21T01:12:38.916Z",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78eba589782acafe17820",
    "name": "togethercomputer/CodeLlama-13b-Instruct",
    "display_name": "Code Llama Instruct (13B)",
    "display_type": "chat",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "13016028160",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "prompt_format": "[INST] {prompt} [/INST]",
      "stop": ["</s>", "[INST]"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 55,
      "output": 55,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:09:14.381Z",
    "update_at": "2023-12-04T05:01:42.539Z",
    "renamed": "codellama/CodeLlama-13b-Instruct-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acefe5227f790586239d41",
    "name": "lmsys/vicuna-13b-v1.3",
    "display_name": "Vicuna v1.3 (13B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt}\nASSISTANT:",
      "chat_template": "{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\n'}}{% endfor %}{{ 'ASSISTANT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T06:00:05.166Z",
    "update_at": "2023-07-15T03:08:44.173Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea0b227f790586239d0b",
    "name": "huggyllama/llama-13b",
    "display_name": "LLaMA (13B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:35:07.955Z",
    "update_at": "2023-07-11T05:35:07.955Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acefbe227f790586239d40",
    "name": "HuggingFaceH4/starchat-alpha",
    "display_name": "StarCoderChat Alpha (16B)",
    "display_type": "chat",
    "description": "Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.",
    "license": "",
    "link": "",
    "creator_organization": "HuggingFaceH4",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 16000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": ["<|endoftext|>", "<|end|>"],
      "prompt_format": "<|system|>\n<|end|>\n<|user|>\n{prompt}<|end|>\n<|assistant|>",
      "chat_template_name": "default"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:59:26.298Z",
    "update_at": "2023-07-11T05:59:26.298Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acea35227f790586239d0c",
    "name": "huggyllama/llama-30b",
    "display_name": "LLaMA (30B)",
    "display_type": "language",
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "license": "",
    "link": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "access": "open",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:35:49.870Z",
    "update_at": "2023-07-11T05:35:49.870Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1412907e072b8aecf4",
    "name": "stabilityai/stablelm-base-alpha-3b",
    "display_name": "StableLM-Base-Alpha (3B)",
    "display_type": "language",
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "license": "",
    "link": "",
    "creator_organization": "Stability AI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 3000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 25,
      "output": 25,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:44.907Z",
    "update_at": "2023-06-23T20:22:44.907Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1512907e072b8aecf5",
    "name": "stabilityai/stablelm-base-alpha-7b",
    "display_name": "StableLM-Base-Alpha (7B)",
    "display_type": "language",
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "license": "",
    "link": "",
    "creator_organization": "Stability AI",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:45.249Z",
    "update_at": "2023-06-23T20:22:45.249Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64e78e89589782acafe1781c",
    "name": "togethercomputer/CodeLlama-7b-Python",
    "display_name": "Code Llama Python (7B)",
    "display_type": "code",
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "license": "",
    "creator_organization": "Meta",
    "hardware_label": "A100 80GB",
    "num_parameters": "6738546688",
    "show_in_playground": true,
    "finetuning_supported": true,
    "isFeaturedModel": false,
    "context_length": 16384,
    "config": {
      "stop": ["</s>"],
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-08-24T17:08:25.379Z",
    "update_at": "2023-08-24T17:08:25.379Z",
    "renamed": "codellama/CodeLlama-7b-Python-hf",
    "access": "",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64f67987bc372ce719b97f07",
    "name": "defog/sqlcoder",
    "display_name": "Sqlcoder (15B)",
    "display_type": "language",
    "description": "Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.",
    "license": "",
    "creator_organization": "Defog",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 15000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": ["<|endoftext|>"],
      "prompt_format": "### Instructions:\n\n{prompt}\n\n### Response:\n"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-09-05T00:42:47.496Z",
    "update_at": "2023-09-05T00:42:47.496Z",
    "link": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64acef6e227f790586239d3f",
    "name": "bigcode/starcoder",
    "display_name": "StarCoder (16B)",
    "display_type": "code",
    "description": "Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.",
    "license": "",
    "link": "",
    "creator_organization": "BigCode",
    "hardware_label": "A100 80GB",
    "pricing_tier": "supported",
    "num_parameters": 16000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 8192,
    "config": {
      "stop": ["<|endoftext|>", "<|end|>"]
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:58:06.486Z",
    "update_at": "2023-07-11T05:58:06.486Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1112907e072b8aecb7",
    "name": "databricks/dolly-v2-7b",
    "display_name": "Dolly v2 (7B)",
    "display_type": "chat",
    "description": "An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "license": "",
    "link": "",
    "creator_organization": "Databricks",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["### End"],
      "prompt_format": "### Instruction:\n{prompt}\n### Response:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n' }}{% else %}{{ '### Response:\n' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Response:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:41.565Z",
    "update_at": "2023-06-23T20:22:41.565Z",
    "access": "",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8a3227f790586239d02",
    "name": "togethercomputer/guanaco-33b",
    "display_name": "Guanaco (33B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Supported",
    "access": "open",
    "num_parameters": 33000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 200,
      "output": 200,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:29:07.717Z",
    "update_at": "2023-07-11T05:29:07.717Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace9b1227f790586239d07",
    "name": "togethercomputer/Koala-13B",
    "display_name": "Koala (13B)",
    "display_type": "chat",
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "license": "",
    "link": "",
    "creator_organization": "LM Sys",
    "hardware_label": "A40 48GB",
    "pricing_tier": "supported",
    "access": "open",
    "num_parameters": 13000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["</s>"],
      "prompt_format": "USER: {prompt} GPT:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}"
    },
    "pricing": {
      "input": 75,
      "output": 75,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:33:37.737Z",
    "update_at": "2023-07-11T05:33:37.737Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6495ff1312907e072b8aece2",
    "name": "togethercomputer/GPT-JT-6B-v1",
    "display_name": "GPT-JT (6B)",
    "display_type": "language",
    "description": "Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).",
    "descriptionLink": "https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai",
    "license": "",
    "link": "",
    "creator_organization": "Together",
    "hardware_label": "A40 48GB",
    "pricing_tier": "featured",
    "access": "open",
    "num_parameters": 6700000000,
    "release_date": "2022-11-29T00:00:00.000Z",
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "chat_template_name": "gpt"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-06-23T20:22:43.617Z",
    "update_at": "2023-06-23T20:22:43.617Z"
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "64ace8ed227f790586239d04",
    "name": "togethercomputer/guanaco-7b",
    "display_name": "Guanaco (7B) ",
    "display_type": "chat",
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ",
    "license": "",
    "link": "",
    "creator_organization": "Tim Dettmers",
    "hardware_label": "A40 48GB",
    "access": "open",
    "num_parameters": 7000000000,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 2048,
    "config": {
      "stop": ["###"],
      "prompt_format": "### Human: {prompt} ### Assistant:",
      "chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-07-11T05:30:21.531Z",
    "update_at": "2023-07-11T05:30:21.531Z",
    "descriptionLink": ""
  },
  {
    "modelInstanceConfig": {
      "appearsIn": [],
      "order": 0
    },
    "_id": "6532f0faf94bacfc629b4cf7",
    "name": "EleutherAI/llemma_7b",
    "display_name": "Llemma (7B)",
    "display_type": "language",
    "description": "Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.",
    "license": "",
    "link": "",
    "creator_organization": "EleutherAI",
    "hardware_label": "A100 80GB",
    "pricing_tier": "Featured",
    "access": "open",
    "num_parameters": 6738546688,
    "show_in_playground": true,
    "isFeaturedModel": false,
    "context_length": 4096,
    "config": {
      "chat_template_name": "llama"
    },
    "pricing": {
      "input": 50,
      "output": 50,
      "hourly": 0
    },
    "created_at": "2023-10-20T21:28:26.403Z",
    "update_at": "2023-10-24T17:42:38.630Z",
    "descriptionLink": ""
  }
]
