[
  {
    "id": "openai@gpt-3.5-turbo",
    "model": "openai/gpt-3.5-turbo",
    "category": "chat",

    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo",

    "displayName": "OpenAI: GPT-3.5 Turbo",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 4096,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-instruct",
    "model": "openai/gpt-3.5-turbo-instruct",
    "category": "instruct",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-instruct",
    "displayName": "OpenAI: GPT-3.5 Turbo Instruct",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 4096,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-instruct-0914",
    "model": "openai/gpt-3.5-turbo-instruct-0914",
    "category": "instruct",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-instruct-0914",
    "displayName": "OpenAI: GPT-3.5 Turbo Instruct (v0914)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 4096,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-0301",
    "model": "openai/gpt-3.5-turbo-0301",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-0301",
    "displayName": "OpenAI: GPT-3.5 Turbo (v0301)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 4096,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-0613",
    "model": "openai/gpt-3.5-turbo-0613",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-0613",
    "displayName": "OpenAI: GPT-3.5 Turbo (v0613)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 4096,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-1106",
    "model": "openai/gpt-3.5-turbo-1106",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-1106",
    "displayName": "OpenAI: GPT-3.5 Turbo (v0613)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens.",
    "url": "https://openai.com",
    "contextLength": 16385,
    "tokenizer": "GPT",
    "isAvailable": true,
    "outputTokenLimit": 4096
  },

  {
    "id": "openai@gpt-3.5-turbo-16k",
    "model": "openai/gpt-3.5-turbo-16k",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-16k",
    "displayName": "OpenAI: GPT-3.5 Turbo 16K",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 16385,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-3.5-turbo-16k-0613",
    "model": "openai/gpt-3.5-turbo-16k-0613\"",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-3.5-turbo-16k-0613",
    "displayName": "OpenAI: GPT-3.5 Turbo 16K (v0613)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "description": "GPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.",
    "url": "https://openai.com",
    "contextLength": 16385,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-4",
    "model": "openai/gpt-4",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-4",
    "displayName": "OpenAI: GPT-4",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "description": "GPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to paying customers. Like gpt-3.5-turbo, GPT-4 is optimized for chat but works well for traditional completions tasks using the Chat Completions API.",
    "url": "https://openai.com",
    "contextLength": 8192,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-4-0314",
    "model": "openai/gpt-4-0314",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-4-0314",
    "displayName": "OpenAI: GPT-4 (v0314)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "description": "GPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to paying customers. Like gpt-3.5-turbo, GPT-4 is optimized for chat but works well for traditional completions tasks using the Chat Completions API.",
    "url": "https://openai.com",
    "contextLength": 8192,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-4-0613",
    "model": "openai/gpt-4-0613",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-4-0613",
    "displayName": "OpenAI: GPT-4 (v0613)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "description": "GPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to paying customers. Like gpt-3.5-turbo, GPT-4 is optimized for chat but works well for traditional completions tasks using the Chat Completions API.",
    "url": "https://openai.com",
    "contextLength": 8192,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-4-1106-preview",
    "model": "openai/gpt-4-1106-preview",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-4-1106-preview",
    "displayName": "OpenAI: GPT-4 Turbo (preview)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "description": "The latest GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic.",
    "url": "https://openai.com",
    "contextLength": 128000,
    "tokenizer": "GPT",
    "isAvailable": true
  },

  {
    "id": "openai@gpt-4-vision-preview",
    "model": "openai/gpt-4-vision-preview",
    "category": "chat",
    "vendorId": "openai",
    "vendorModelId": "gpt-4-vision-preview",
    "displayName": "OpenAI: GPT-4 Turbo with vision",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "description": "Ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens. This is a preview model version and not suited yet for production traffic.",
    "url": "https://openai.com",
    "contextLength": 128000,
    "tokenizer": "GPT",
    "isAvailable": true,
    "comment": "Additional cost incurred per image size"
  },
  {
    "id": "openrouter@mistral-7b-instruct",
    "model": "mistral-7b-instruct",
    "category": "instruct",
    "vendorId": "openrouter",
    "vendorModelId": "mistralai/mistral-7b-instruct",
    "displayName": "Mistral 7B Instruct (beta)",
    "creatorName": "Mistral 7B Instruct (beta)",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "parameterSize": 7000,
    "contextLength": 8192,
    "tokenizer": "Mistral",
    "instructType": "llama2"
  },
  {
    "id": "openrouter@zephyr-7b-beta",
    "model": "zephyr-7b-beta",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "huggingfaceh4/zephyr-7b-beta",
    "displayName": "Hugging Face: Zephyr 7B (beta)",
    "creatorName": "Hugging Face",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "parameterSize": 7000,
    "contextLength": 4096,
    "tokenizer": "Mistral",
    "instructType": "zephyr"
  },
  {
    "id": "openrouter@toppy-m-7b",
    "model": "toppy-m-7b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "undi95/toppy-m-7b",
    "displayName": "Toppy M 7B (beta)",
    "creatorName": "Toppy M 7B (beta)",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "parameterSize": 7000,
    "contextLength": 32768,
    "tokenizer": "Mistral",
    "instructType": "alpaca",
    "outputTokenLimit": 2048
  },
  {
    "id": "openrouter@gpt-3.5-turbo",
    "model": "gpt-3.5-turbo",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-3.5-turbo",
    "displayName": "OpenAI: GPT-3.5 Turbo",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "contextLength": 4095,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-3.5-turbo-1106",
    "model": "gpt-3.5-turbo-1106",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-3.5-turbo-1106",
    "displayName": "OpenAI: GPT-3.5 Turbo 16k (preview)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "contextLength": 16385,
    "tokenizer": "GPT",
    "instructType": null,
    "outputTokenLimit": 4096
  },
  {
    "id": "openrouter@gpt-3.5-turbo-0301",
    "model": "gpt-3.5-turbo-0301",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-3.5-turbo-0301",
    "displayName": "OpenAI: GPT-3.5 Turbo (older v0301)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 250,
    "costOutputNanoUsd": 500,
    "contextLength": 4095,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-3.5-turbo-16k",
    "model": "gpt-3.5-turbo-16k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-3.5-turbo-16k",
    "displayName": "OpenAI: GPT-3.5 Turbo 16k",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 750,
    "costOutputNanoUsd": 1000,
    "contextLength": 16385,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-4-1106-preview",
    "model": "gpt-4-1106-preview",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4-1106-preview",
    "displayName": "OpenAI: GPT-4 Turbo (preview)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "contextLength": 128000,
    "tokenizer": "GPT",
    "instructType": null,
    "outputTokenLimit": 4096
  },
  {
    "id": "openrouter@gpt-4",
    "model": "gpt-4",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4",
    "displayName": "OpenAI: GPT-4",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 7500,
    "costOutputNanoUsd": 15000,
    "contextLength": 8191,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-4-0314",
    "model": "gpt-4-0314",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4-0314",
    "displayName": "OpenAI: GPT-4 (older v0314)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 7500,
    "costOutputNanoUsd": 15000,
    "contextLength": 8191,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-4-32k",
    "model": "gpt-4-32k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4-32k",
    "displayName": "OpenAI: GPT-4 32k",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 15000,
    "costOutputNanoUsd": 30000,
    "contextLength": 32767,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-4-32k-0314",
    "model": "gpt-4-32k-0314",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4-32k-0314",
    "displayName": "OpenAI: GPT-4 32k (older v0314)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 15000,
    "costOutputNanoUsd": 30000,
    "contextLength": 32767,
    "tokenizer": "GPT",
    "instructType": null
  },
  {
    "id": "openrouter@gpt-4-vision-preview",
    "model": "gpt-4-vision-preview",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-4-vision-preview",
    "displayName": "OpenAI: GPT-4 Vision (preview)",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 2500,
    "costOutputNanoUsd": 7500,
    "contextLength": 128000,
    "tokenizer": "GPT",
    "instructType": null,
    "outputTokenLimit": 4096
  },
  {
    "id": "openrouter@text-davinci-002",
    "model": "text-davinci-002",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "openai/text-davinci-002",
    "displayName": "OpenAI: Davinci 2",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 5000,
    "costOutputNanoUsd": 5000,
    "contextLength": 4095,
    "tokenizer": "GPT",
    "instructType": "gpt"
  },
  {
    "id": "openrouter@gpt-3.5-turbo-instruct",
    "model": "gpt-3.5-turbo-instruct",
    "category": "instruct",
    "vendorId": "openrouter",
    "vendorModelId": "openai/gpt-3.5-turbo-instruct",
    "displayName": "OpenAI: GPT-3.5 Turbo Instruct",
    "creatorName": "OpenAI",
    "costInputNanoUsd": 375,
    "costOutputNanoUsd": 500,
    "contextLength": 4095,
    "tokenizer": "GPT",
    "instructType": "gpt"
  },
  {
    "id": "openrouter@palm-2-chat-bison",
    "model": "palm-2-chat-bison",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "google/palm-2-chat-bison",
    "displayName": "Google: PaLM 2 Chat",
    "creatorName": "Google",
    "costInputNanoUsd": 125,
    "costOutputNanoUsd": 125,
    "contextLength": 9216,
    "tokenizer": "PaLM",
    "instructType": null,
    "outputTokenLimit": 1024
  },
  {
    "id": "openrouter@palm-2-codechat-bison",
    "model": "palm-2-codechat-bison",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "google/palm-2-codechat-bison",
    "displayName": "Google: PaLM 2 Code Chat",
    "creatorName": "Google",
    "costInputNanoUsd": 125,
    "costOutputNanoUsd": 125,
    "contextLength": 7168,
    "tokenizer": "PaLM",
    "instructType": null,
    "outputTokenLimit": 1024
  },
  {
    "id": "openrouter@palm-2-chat-bison-32k",
    "model": "palm-2-chat-bison-32k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "google/palm-2-chat-bison-32k",
    "displayName": "Google: PaLM 2 Chat 32k",
    "creatorName": "Google",
    "costInputNanoUsd": 125,
    "costOutputNanoUsd": 125,
    "contextLength": 32000,
    "tokenizer": "PaLM",
    "instructType": null,
    "outputTokenLimit": 8192
  },
  {
    "id": "openrouter@palm-2-codechat-bison-32k",
    "model": "palm-2-codechat-bison-32k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "google/palm-2-codechat-bison-32k",
    "displayName": "Google: PaLM 2 Code Chat 32k",
    "creatorName": "Google",
    "costInputNanoUsd": 125,
    "costOutputNanoUsd": 125,
    "contextLength": 32000,
    "tokenizer": "PaLM",
    "instructType": null,
    "outputTokenLimit": 8192
  },
  {
    "id": "openrouter@llama-2-13b-chat",
    "model": "llama-2-13b-chat",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "meta-llama/llama-2-13b-chat",
    "displayName": "Meta: Llama v2 13B Chat (beta)",
    "creatorName": "Meta",
    "costInputNanoUsd": 58.625,
    "costOutputNanoUsd": 58.625,
    "parameterSize": 13000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "llama2"
  },
  {
    "id": "openrouter@llama-2-70b-chat",
    "model": "llama-2-70b-chat",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "meta-llama/llama-2-70b-chat",
    "displayName": "Meta: Llama v2 70B Chat (beta)",
    "creatorName": "Meta",
    "costInputNanoUsd": 175,
    "costOutputNanoUsd": 237.5,
    "parameterSize": 70000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "llama2"
  },
  {
    "id": "openrouter@nous-hermes-llama2-13b",
    "model": "nous-hermes-llama2-13b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "nousresearch/nous-hermes-llama2-13b",
    "displayName": "Nous: Hermes 13B (beta)",
    "creatorName": "Nous",
    "costInputNanoUsd": 37.5,
    "costOutputNanoUsd": 37.5,
    "parameterSize": 13000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "alpaca"
  },
  {
    "id": "openrouter@nous-hermes-llama2-70b",
    "model": "nous-hermes-llama2-70b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "nousresearch/nous-hermes-llama2-70b",
    "displayName": "Nous: Hermes 70B (beta)",
    "creatorName": "Nous",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "parameterSize": 70000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "alpaca"
  },
  {
    "id": "openrouter@codellama-34b-instruct",
    "model": "codellama-34b-instruct",
    "category": "instruct",
    "vendorId": "openrouter",
    "vendorModelId": "meta-llama/codellama-34b-instruct",
    "displayName": "Meta: CodeLlama 34B Instruct (beta)",
    "creatorName": "Meta",
    "costInputNanoUsd": 100,
    "costOutputNanoUsd": 100,
    "parameterSize": 34000,
    "contextLength": 8192,
    "tokenizer": "Llama2",
    "instructType": "llama2"
  },
  {
    "id": "openrouter@phind-codellama-34b",
    "model": "phind-codellama-34b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "phind/phind-codellama-34b",
    "displayName": "Phind: CodeLlama 34B v2 (beta)",
    "creatorName": "Phind",
    "costInputNanoUsd": 100,
    "costOutputNanoUsd": 100,
    "parameterSize": 34000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "alpaca"
  },
  {
    "id": "openrouter@airoboros-l2-70b",
    "model": "airoboros-l2-70b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "jondurbin/airoboros-l2-70b",
    "displayName": "Airoboros 70B (beta)",
    "creatorName": "Airoboros 70B (beta)",
    "costInputNanoUsd": 175,
    "costOutputNanoUsd": 237,
    "parameterSize": 70000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "airoboros"
  },
  {
    "id": "openrouter@synthia-70b",
    "model": "synthia-70b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "migtissera/synthia-70b",
    "displayName": "Synthia 70B (beta)",
    "creatorName": "Synthia 70B (beta)",
    "costInputNanoUsd": 2343,
    "costOutputNanoUsd": 2343,
    "parameterSize": 70000,
    "contextLength": 8192,
    "tokenizer": "Llama2",
    "instructType": "airoboros",
    "outputTokenLimit": 300
  },
  {
    "id": "openrouter@mistral-7b-openorca",
    "model": "mistral-7b-openorca",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "open-orca/mistral-7b-openorca",
    "displayName": "Mistral OpenOrca 7B (beta)",
    "creatorName": "Mistral OpenOrca 7B (beta)",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "parameterSize": 7000,
    "contextLength": 8192,
    "tokenizer": "Mistral",
    "instructType": "gpt"
  },
  {
    "id": "openrouter@openhermes-2-mistral-7b",
    "model": "openhermes-2-mistral-7b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "teknium/openhermes-2-mistral-7b",
    "displayName": "Mistral OpenHermes 7B (beta)",
    "creatorName": "Mistral OpenHermes 7B (beta)",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "parameterSize": 7000,
    "contextLength": 4096,
    "tokenizer": "Mistral",
    "instructType": "gpt"
  },
  {
    "id": "openrouter@mythalion-13b",
    "model": "mythalion-13b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "pygmalionai/mythalion-13b",
    "displayName": "Pygmalion: Mythalion 13B (beta)",
    "creatorName": "Pygmalion",
    "costInputNanoUsd": 281,
    "costOutputNanoUsd": 281,
    "parameterSize": 13000,
    "contextLength": 8192,
    "tokenizer": "Llama2",
    "instructType": "alpaca",
    "outputTokenLimit": 250
  },
  {
    "id": "openrouter@remm-slerp-l2-13b",
    "model": "remm-slerp-l2-13b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "undi95/remm-slerp-l2-13b",
    "displayName": "ReMM SLERP 13B (beta)",
    "creatorName": "ReMM SLERP 13B (beta)",
    "costInputNanoUsd": 281,
    "costOutputNanoUsd": 281,
    "parameterSize": 13000,
    "contextLength": 6144,
    "tokenizer": "Llama2",
    "instructType": "alpaca",
    "outputTokenLimit": 250
  },
  {
    "id": "openrouter@mythomax-l2-13b",
    "model": "mythomax-l2-13b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "gryphe/mythomax-l2-13b",
    "displayName": "MythoMax 13B",
    "creatorName": "MythoMax 13B",
    "costInputNanoUsd": 150,
    "costOutputNanoUsd": 150,
    "parameterSize": 13000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "alpaca"
  },
  {
    "id": "openrouter@xwin-lm-70b",
    "model": "xwin-lm-70b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "xwin-lm/xwin-lm-70b",
    "displayName": "Xwin 70B (beta)",
    "creatorName": "Xwin 70B (beta)",
    "costInputNanoUsd": 2343,
    "costOutputNanoUsd": 2343,
    "parameterSize": 70000,
    "contextLength": 8192,
    "tokenizer": "Llama2",
    "instructType": "airoboros",
    "outputTokenLimit": 300
  },
  {
    "id": "openrouter@mythomax-l2-13b-8k",
    "model": "mythomax-l2-13b-8k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "gryphe/mythomax-l2-13b-8k",
    "displayName": "MythoMax 13B 8k (beta)",
    "creatorName": "MythoMax 13B 8k (beta)",
    "costInputNanoUsd": 281,
    "costOutputNanoUsd": 281,
    "parameterSize": 13000,
    "contextLength": 8192,
    "tokenizer": "Llama2",
    "instructType": "alpaca",
    "outputTokenLimit": 300
  },
  {
    "id": "openrouter@goliath-120b",
    "model": "goliath-120b",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "alpindale/goliath-120b",
    "displayName": "Goliath 120B (beta)",
    "creatorName": "Goliath 120B (beta)",
    "costInputNanoUsd": 1406,
    "costOutputNanoUsd": 1406,
    "parameterSize": 120000,
    "contextLength": 6144,
    "tokenizer": "Llama2",
    "instructType": "airoboros",
    "outputTokenLimit": 300
  },
  {
    "id": "openrouter@lzlv-70b-fp16-hf",
    "model": "lzlv-70b-fp16-hf",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "lizpreciatior/lzlv-70b-fp16-hf",
    "displayName": "lzlv 70B (beta)",
    "creatorName": "lzlv 70B (beta)",
    "costInputNanoUsd": 175,
    "costOutputNanoUsd": 237,
    "parameterSize": 70000,
    "contextLength": 4096,
    "tokenizer": "Llama2",
    "instructType": "airoboros"
  },
  {
    "id": "openrouter@claude-2",
    "model": "claude-2",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-2",
    "displayName": "Anthropic: Claude v2",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 2755,
    "costOutputNanoUsd": 8170,
    "contextLength": 100000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-instant-v1",
    "model": "claude-instant-v1",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-instant-v1",
    "displayName": "Anthropic: Claude Instant v1",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 407,
    "costOutputNanoUsd": 1377,
    "contextLength": 100000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-v1",
    "model": "claude-v1",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-v1",
    "displayName": "Anthropic: Claude v1",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 2755,
    "costOutputNanoUsd": 8170,
    "contextLength": 9000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-1.2",
    "model": "claude-1.2",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-1.2",
    "displayName": "Anthropic: Claude (older v1)",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 2755,
    "costOutputNanoUsd": 8170,
    "contextLength": 9000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-instant-v1-100k",
    "model": "claude-instant-v1-100k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-instant-v1-100k",
    "displayName": "Anthropic: Claude Instant 100k v1",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 407,
    "costOutputNanoUsd": 1377,
    "contextLength": 100000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-v1-100k",
    "model": "claude-v1-100k",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-v1-100k",
    "displayName": "Anthropic: Claude 100k v1",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 2755,
    "costOutputNanoUsd": 8170,
    "contextLength": 100000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@claude-instant-1.0",
    "model": "claude-instant-1.0",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "anthropic/claude-instant-1.0",
    "displayName": "Anthropic: Claude Instant (older v1)",
    "creatorName": "Anthropic",
    "costInputNanoUsd": 407,
    "costOutputNanoUsd": 1377,
    "contextLength": 9000,
    "tokenizer": "Claude",
    "instructType": "claude"
  },
  {
    "id": "openrouter@weaver",
    "model": "weaver",
    "category": "chat",
    "vendorId": "openrouter",
    "vendorModelId": "mancer/weaver",
    "displayName": "Mancer: Weaver (alpha)",
    "creatorName": "Mancer",
    "costInputNanoUsd": 1125,
    "costOutputNanoUsd": 1125,
    "contextLength": 8000,
    "tokenizer": "Llama2",
    "instructType": "alpaca",
    "outputTokenLimit": 400
  },
  {
    "id": "togetherai@chronos-hermes-13b",
    "model": "chronos-hermes-13b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "Austism/chronos-hermes-13b",
    "displayName": "Chronos Hermes (13B)",
    "creatorName": "Austism",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.",
    "url": "",
    "license": "other",
    "parameterSize": 13000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@llemma_7b",
    "model": "llemma_7b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/llemma_7b",
    "displayName": "Llemma (7B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.",
    "url": "https://huggingface.co/EleutherAI/llemma_7b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 6738.546688,
    "contextLength": 4096
  },
  {
    "id": "togetherai@pythia-12b-v0",
    "model": "pythia-12b-v0",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/pythia-12b-v0",
    "displayName": "Pythia (12B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "url": "https://huggingface.co/EleutherAI/pythia-12b-v0",
    "license": "apache-2.0",
    "parameterSize": 12000,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@pythia-1b-v0",
    "model": "pythia-1b-v0",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/pythia-1b-v0",
    "displayName": "Pythia (1B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "url": "https://huggingface.co/EleutherAI/pythia-1b-v0",
    "license": "apache-2.0",
    "parameterSize": 1000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@pythia-2.8b-v0",
    "model": "pythia-2.8b-v0",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/pythia-2.8b-v0",
    "displayName": "Pythia (2.8B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "url": "",
    "license": "apache-2.0",
    "parameterSize": 2800,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@pythia-6.9b",
    "model": "pythia-6.9b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/pythia-6.9b",
    "displayName": "Pythia (6.9B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.",
    "url": "",
    "license": "apache-2.0",
    "parameterSize": 6900,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@mythomax-l2-13b",
    "model": "mythomax-l2-13b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "Gryphe/MythoMax-L2-13b",
    "displayName": "MythoMax-L2 (13B)",
    "creatorName": "Gryphe",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model",
    "url": "",
    "license": "other",
    "parameterSize": 13000,
    "contextLength": 4096,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@starchat-alpha",
    "model": "starchat-alpha",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "HuggingFaceH4/starchat-alpha",
    "displayName": "StarCoderChat Alpha (16B)",
    "creatorName": "HuggingFaceH4",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.",
    "url": "https://huggingface.co/HuggingFaceH4/starchat-alpha",
    "license": "bigcode-openrail-m",
    "parameterSize": 16000,
    "contextLength": 8192,
    "promptFormat": "<|system|>\n<|end|>\n<|user|>\n{prompt}<|end|>\n<|assistant|>",
    "stopTokens": ["<|endoftext|>", "<|end|>"]
  },
  {
    "id": "togetherai@nous-hermes-13b",
    "model": "nous-hermes-13b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "NousResearch/Nous-Hermes-13b",
    "displayName": "Nous Hermes (13B)",
    "creatorName": "Nous Research",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.",
    "url": "https://huggingface.co/NousResearch/Nous-Hermes-13b",
    "license": "gpl, LLaMA License Agreement (Meta)",
    "parameterSize": 13000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@nous-hermes-llama2-13b",
    "model": "nous-hermes-llama2-13b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "NousResearch/Nous-Hermes-Llama2-13b",
    "displayName": "Nous Hermes Llama-2 (13B)",
    "creatorName": "Nous Research",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "url": "",
    "license": "mit",
    "parameterSize": 13000,
    "contextLength": 4096,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["###", "</s>"]
  },
  {
    "id": "togetherai@nous-hermes-llama2-70b",
    "model": "nous-hermes-llama2-70b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "NousResearch/Nous-Hermes-Llama2-70b",
    "displayName": "Nous Hermes LLaMA-2 (70B)",
    "creatorName": "NousResearch",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "url": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-70b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 70000,
    "contextLength": 4096,
    "promptFormat": "### Instruction:\n{prompt}\n\n### Response:\n",
    "stopTokens": ["###", "</s>"]
  },
  {
    "id": "togetherai@nous-hermes-llama-2-7b",
    "model": "nous-hermes-llama-2-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "NousResearch/Nous-Hermes-llama-2-7b",
    "displayName": "Nous Hermes LLaMA-2 (7B)",
    "creatorName": "NousResearch",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.",
    "url": "https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 6738.415616,
    "contextLength": 4096,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["###", "</s>"]
  },
  {
    "id": "togetherai@nsql-llama-2-7b",
    "model": "nsql-llama-2-7b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "NumbersStation/nsql-llama-2-7B",
    "displayName": "NSQL LLaMA-2 (7B)",
    "creatorName": "Numbers Station",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks.",
    "url": "",
    "license": "llama2",
    "parameterSize": 7000,
    "contextLength": 4096
  },
  {
    "id": "togetherai@mistral-7b-openorca",
    "model": "mistral-7b-openorca",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "Open-Orca/Mistral-7B-OpenOrca",
    "displayName": "OpenOrca Mistral (7B) 8K",
    "creatorName": "OpenOrca",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.",
    "url": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
    "license": "apache-2.0",
    "parameterSize": 7241.74848,
    "contextLength": 8192,
    "promptFormat": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
    "stopTokens": ["<|im_end|>"]
  },
  {
    "id": "togetherai@oasst-sft-4-pythia-12b-epoch-3.5",
    "model": "oasst-sft-4-pythia-12b-epoch-3.5",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "displayName": "Open-Assistant Pythia SFT-4 (12B)",
    "creatorName": "LAION",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "url": "https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "license": "apache-2.0",
    "parameterSize": 12000,
    "contextLength": 2048,
    "promptFormat": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@stablelm-7b-sft-v7-epoch-3",
    "model": "stablelm-7b-sft-v7-epoch-3",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "displayName": "Open-Assistant StableLM SFT-7 (7B)",
    "creatorName": "LAION",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "url": "https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "license": "cc-by-sa-4.0",
    "parameterSize": 7000,
    "contextLength": 4096,
    "promptFormat": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@phind-codellama-34b-python-v1",
    "model": "phind-codellama-34b-python-v1",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "Phind/Phind-CodeLlama-34B-Python-v1",
    "displayName": "Phind Code LLaMA Python v1 (34B)",
    "creatorName": "Phind",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.",
    "url": "",
    "license": "llama2",
    "parameterSize": 33743.970304,
    "contextLength": 16384,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["</s>", "###"]
  },
  {
    "id": "togetherai@phind-codellama-34b-v2",
    "model": "phind-codellama-34b-v2",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "Phind/Phind-CodeLlama-34B-v2",
    "displayName": "Phind Code LLaMA v2 (34B)",
    "creatorName": "Phind",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.",
    "url": "",
    "license": "llama2",
    "parameterSize": 33743.970304,
    "contextLength": 16384,
    "promptFormat": "### System Prompt\nYou are an intelligent programming assistant.\n\n### User Message\n{prompt}n\n### Assistant\n",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@realistic_vision_v3.0_vae",
    "model": "realistic_vision_v3.0_vae",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "SG161222/Realistic_Vision_V3.0_VAE",
    "displayName": "Realistic Vision 3.0",
    "creatorName": "SG161222",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "description": "Fine-tune version of Stable Diffusion focused on photorealism.",
    "url": "https://huggingface.co/SG161222/Realistic_Vision_V1.4",
    "license": "creativeml-openrail-m"
  },
  {
    "id": "togetherai@wizardcoder-15b-v1.0",
    "model": "wizardcoder-15b-v1.0",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "WizardLM/WizardCoder-15B-V1.0",
    "displayName": "WizardCoder v1.0 (15B)",
    "creatorName": "WizardLM",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",
    "url": "",
    "license": "llama2",
    "parameterSize": 15517.462528,
    "contextLength": 8192,
    "promptFormat": "### Instruction:\n{prompt}\n\n### Response:\n",
    "stopTokens": ["###", "<|endoftext|>"]
  },
  {
    "id": "togetherai@wizardlm-70b-v1.0",
    "model": "wizardlm-70b-v1.0",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "WizardLM/WizardLM-70B-V1.0",
    "displayName": "WizardLM v1.0 (70B)",
    "creatorName": "WizardLM",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.",
    "url": "",
    "license": "llama2",
    "parameterSize": 70000,
    "contextLength": 4096,
    "promptFormat": "USER: {prompt} ASSISTANT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@starcoder",
    "model": "starcoder",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "bigcode/starcoder",
    "displayName": "StarCoder (16B)",
    "creatorName": "BigCode",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.",
    "url": "https://huggingface.co/bigcode/starcoder",
    "license": "bigcode-openrail-m",
    "parameterSize": 16000,
    "contextLength": 8192,
    "stopTokens": ["<|endoftext|>", "<|end|>"]
  },
  {
    "id": "togetherai@dolly-v2-3b",
    "model": "dolly-v2-3b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "databricks/dolly-v2-3b",
    "displayName": "Dolly v2 (3B)",
    "creatorName": "Databricks",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "url": "https://huggingface.co/databricks/dolly-v2-3b",
    "license": "mit",
    "parameterSize": 3000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:",
    "stopTokens": ["### End"]
  },
  {
    "id": "togetherai@dolly-v2-7b",
    "model": "dolly-v2-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "databricks/dolly-v2-7b",
    "displayName": "Dolly v2 (7B)",
    "creatorName": "Databricks",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "url": "https://huggingface.co/databricks/dolly-v2-7b",
    "license": "mit",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:",
    "stopTokens": ["### End"]
  },
  {
    "id": "togetherai@sqlcoder",
    "model": "sqlcoder",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "defog/sqlcoder",
    "displayName": "Sqlcoder (15B)",
    "creatorName": "Defog",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.",
    "url": "",
    "license": "other",
    "parameterSize": 15000,
    "contextLength": 8192,
    "promptFormat": "### Instructions:\n\n{prompt}\n\n### Response:\n",
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@platypus2-70b-instruct",
    "model": "platypus2-70b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "garage-bAInd/Platypus2-70B-instruct",
    "displayName": "Platypus2 Instruct (70B)",
    "creatorName": "garage-bAInd",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.",
    "url": "",
    "license": "CC BY-NC-4.0",
    "parameterSize": 70000,
    "contextLength": 4096,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["</s>", "###"]
  },
  {
    "id": "togetherai@llama-13b",
    "model": "llama-13b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "huggyllama/llama-13b",
    "displayName": "LLaMA (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "url": "https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 13000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@llama-30b",
    "model": "llama-30b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "huggyllama/llama-30b",
    "displayName": "LLaMA (30B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "url": "https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 33000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@llama-65b",
    "model": "llama-65b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "huggyllama/llama-65b",
    "displayName": "LLaMA (65B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "url": "https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 65000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@llama-7b",
    "model": "llama-7b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "huggyllama/llama-7b",
    "displayName": "LLaMA (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.",
    "url": "https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 7000,
    "contextLength": 2048
  },
  {
    "id": "togetherai@fastchat-t5-3b-v1.0",
    "model": "fastchat-t5-3b-v1.0",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/fastchat-t5-3b-v1.0",
    "displayName": "Vicuna-FastChat-T5 (3B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.",
    "url": "https://huggingface.co/lmsys/fastchat-t5-3b-v1.0",
    "license": "apache-2.0",
    "parameterSize": 3000,
    "contextLength": 512,
    "promptFormat": "### Human: {prompt}\n### Assistant:",
    "stopTokens": ["###", "</s>"]
  },
  {
    "id": "togetherai@vicuna-13b-v1.5-16k",
    "model": "vicuna-13b-v1.5-16k",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/vicuna-13b-v1.5-16k",
    "displayName": "Vicuna v1.5 16K (13B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "url": "",
    "license": "llama2",
    "parameterSize": 13015.86432,
    "contextLength": 16384,
    "promptFormat": "USER: {prompt}\nASSISTANT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@vicuna-13b-v1.5",
    "model": "vicuna-13b-v1.5",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/vicuna-13b-v1.5",
    "displayName": "Vicuna v1.5 (13B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "url": "",
    "license": "llama2",
    "parameterSize": 13000,
    "contextLength": 4096,
    "promptFormat": "USER: {prompt}\nASSISTANT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@vicuna-7b-v1.5",
    "model": "vicuna-7b-v1.5",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/vicuna-7b-v1.5",
    "displayName": "Vicuna v1.5 (7B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.",
    "url": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 6738.415616,
    "contextLength": 4096,
    "promptFormat": "USER: {prompt}\nASSISTANT: Hello!",
    "stopTokens": ["</s>", "USER:"]
  },
  {
    "id": "togetherai@mistral-7b-instruct-v0.1",
    "model": "mistral-7b-instruct-v0.1",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "mistralai/Mistral-7B-Instruct-v0.1",
    "displayName": "Mistral (7B) Instruct",
    "creatorName": "mistralai",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "instruct fine-tuned version of Mistral-7B-v0.1",
    "url": "",
    "license": "Apache-2",
    "parameterSize": 7241.732096,
    "contextLength": 4096,
    "promptFormat": "<s>[INST] {prompt} [/INST]",
    "stopTokens": ["[/INST]", "</s>"]
  },
  {
    "id": "togetherai@mistral-7b-v0.1",
    "model": "mistral-7b-v0.1",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "mistralai/Mistral-7B-v0.1",
    "displayName": "Mistral (7B)",
    "creatorName": "mistralai",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost",
    "url": "",
    "license": "Apache-2",
    "parameterSize": 7241.732096,
    "contextLength": 4096,
    "promptFormat": "{prompt}",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@openjourney",
    "model": "openjourney",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "prompthero/openjourney",
    "displayName": "Openjourney v4",
    "creatorName": "Prompt Hero",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "An open source Stable Diffusion model fine tuned model on Midjourney images. ",
    "url": "https://huggingface.co/prompthero/openjourney",
    "license": "creativeml-openrail-m",
    "parameterSize": 13000
  },
  {
    "id": "togetherai@stable-diffusion-v1-5",
    "model": "stable-diffusion-v1-5",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "runwayml/stable-diffusion-v1-5",
    "displayName": "Stable Diffusion 1.5",
    "creatorName": "Runway ML",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "url": "https://huggingface.co/runwayml/stable-diffusion-v1-5",
    "license": "creativeml-openrail-m"
  },
  {
    "id": "togetherai@stable-diffusion-2-1",
    "model": "stable-diffusion-2-1",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "stabilityai/stable-diffusion-2-1",
    "displayName": "Stable Diffusion 2.1",
    "creatorName": "Stability AI",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "description": "Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.",
    "url": "https://huggingface.co/stabilityai/stable-diffusion-2-1",
    "license": "openrail++"
  },
  {
    "id": "togetherai@stable-diffusion-xl-base-1.0",
    "model": "stable-diffusion-xl-base-1.0",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "stabilityai/stable-diffusion-xl-base-1.0",
    "displayName": "Stable Diffusion XL 1.0",
    "creatorName": "Stability AI",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "description": "A text-to-image generative AI model that excels at creating 1024x1024 images.",
    "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",
    "license": "openrail++"
  },
  {
    "id": "togetherai@openhermes-2-mistral-7b",
    "model": "openhermes-2-mistral-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "teknium/OpenHermes-2-Mistral-7B",
    "displayName": "OpenHermes-2-Mistral (7B)",
    "creatorName": "teknium",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "State of the art Mistral Fine-tuned on extensive public datasets",
    "url": "",
    "license": "Apache-2",
    "parameterSize": 7241.732096,
    "promptFormat": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
    "stopTokens": ["<|im_end|>", "<|im_start|>"]
  },
  {
    "id": "togetherai@codellama-13b-instruct",
    "model": "codellama-13b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-13b-Instruct",
    "displayName": "Code Llama Instruct (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 56.25,
    "costOutputNanoUsd": 56.25,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 13016.02816,
    "contextLength": 8192,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["</s>", "[INST]"]
  },
  {
    "id": "togetherai@codellama-13b-python",
    "model": "codellama-13b-python",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-13b-Python",
    "displayName": "Code Llama Python (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 56.25,
    "costOutputNanoUsd": 56.25,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 13016.02816,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@codellama-13b",
    "model": "codellama-13b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-13b",
    "displayName": "Code Llama (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 56.25,
    "costOutputNanoUsd": 56.25,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 13016.02816,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@codellama-34b-instruct",
    "model": "codellama-34b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-34b-Instruct",
    "displayName": "Code Llama Instruct (34B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 34000,
    "contextLength": 8192,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["</s>", "[INST]"]
  },
  {
    "id": "togetherai@codellama-34b-python",
    "model": "codellama-34b-python",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-34b-Python",
    "displayName": "Code Llama Python (34B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 34000,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@codellama-34b",
    "model": "codellama-34b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-34b",
    "displayName": "Code Llama (34B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 34000,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@codellama-7b-instruct",
    "model": "codellama-7b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-7b-Instruct",
    "displayName": "Code Llama Instruct (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 6738.546688,
    "contextLength": 8192,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["</s>", "[INST]"]
  },
  {
    "id": "togetherai@codellama-7b-python",
    "model": "codellama-7b-python",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-7b-Python",
    "displayName": "Code Llama Python (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 6738.546688,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@codellama-7b",
    "model": "codellama-7b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/CodeLlama-7b",
    "displayName": "Code Llama (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.",
    "url": "",
    "license": "LLAMA 2 Community license Agreement (Meta)",
    "parameterSize": 6738.546688,
    "contextLength": 8192,
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@gpt-jt-6b-v1",
    "model": "gpt-jt-6b-v1",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/GPT-JT-6B-v1",
    "displayName": "GPT-JT (6B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).",
    "url": "https://huggingface.co/togethercomputer/GPT-JT-6B-v1",
    "license": "apache-2.0",
    "parameterSize": 6700,
    "contextLength": 2048
  },
  {
    "id": "togetherai@gpt-jt-moderation-6b",
    "model": "gpt-jt-moderation-6b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/GPT-JT-Moderation-6B",
    "displayName": "GPT-JT-Moderation (6B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.",
    "url": "https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B",
    "license": "apache-2.0",
    "parameterSize": 6700,
    "contextLength": 2048
  },
  {
    "id": "togetherai@gpt-neoxt-chat-base-20b",
    "model": "gpt-neoxt-chat-base-20b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "displayName": "GPT-NeoXT-Chat-Base (20B)",
    "creatorName": "Together",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.",
    "url": "https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "license": "apache-2.0",
    "parameterSize": 20000,
    "contextLength": 2048,
    "promptFormat": "<human>: {prompt}\n<bot>:",
    "stopTokens": ["<human>"]
  },
  {
    "id": "togetherai@koala-13b",
    "model": "koala-13b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Koala-13B",
    "displayName": "Koala (13B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "url": "https://huggingface.co/TheBloke/koala-13B-HF",
    "license": "other",
    "parameterSize": 13000,
    "contextLength": 2048,
    "promptFormat": "USER: {prompt} GPT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@llama-2-7b-32k",
    "model": "llama-2-7b-32k",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/LLaMA-2-7B-32K",
    "displayName": "LLaMA-2-32K (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.",
    "url": "https://huggingface.co/togethercomputer/LLaMA-2-7B-32K",
    "license": "Meta license",
    "parameterSize": 6738.415616,
    "contextLength": 32768,
    "stopTokens": ["\n\n\n\n", "<|endoftext|>"]
  },
  {
    "id": "togetherai@llama-2-7b-32k-instruct",
    "model": "llama-2-7b-32k-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Llama-2-7B-32K-Instruct",
    "displayName": "LLaMA-2-7B-32K-Instruct (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together",
    "url": "",
    "license": "Meta license",
    "parameterSize": 7000,
    "contextLength": 32768,
    "promptFormat": "[INST]\n {prompt} \n[/INST]\n\n",
    "stopTokens": ["[INST]", "\n\n"]
  },
  {
    "id": "togetherai@pythia-chat-base-7b-v0.16",
    "model": "pythia-chat-base-7b-v0.16",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Pythia-Chat-Base-7B-v0.16",
    "displayName": "Pythia-Chat-Base (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.",
    "url": "",
    "license": "apache-2.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "<human>: {prompt}\n<bot>:",
    "stopTokens": ["<human>"]
  },
  {
    "id": "togetherai@qwen-7b-chat",
    "model": "qwen-7b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Qwen-7B-Chat",
    "displayName": "Qwen-Chat (7B)",
    "creatorName": "Qwen",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques. ",
    "url": "",
    "license": "Tongyi Qianwen LICENSE AGREEMENT",
    "parameterSize": 7000,
    "contextLength": 8192,
    "promptFormat": "\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
    "stopTokens": ["<|im_end|>", "<|im_start|>"]
  },
  {
    "id": "togetherai@qwen-7b",
    "model": "qwen-7b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Qwen-7B",
    "displayName": "Qwen (7B)",
    "creatorName": "Qwen",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc.",
    "url": "",
    "license": "Tongyi Qianwen LICENSE AGREEMENT",
    "parameterSize": 7000,
    "contextLength": 8192,
    "stopTokens": ["<|im_end|>", "<|endoftext|>"]
  },
  {
    "id": "togetherai@redpajama-incite-7b-base",
    "model": "redpajama-incite-7b-base",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-7B-Base",
    "displayName": "RedPajama-INCITE (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base",
    "license": "apache-2.0",
    "parameterSize": 6857.302016,
    "contextLength": 2048
  },
  {
    "id": "togetherai@redpajama-incite-7b-chat",
    "model": "redpajama-incite-7b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "displayName": "RedPajama-INCITE Chat (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat",
    "license": "apache-2.0",
    "parameterSize": 6857.302016,
    "contextLength": 2048,
    "promptFormat": "<human>: {prompt}\n<bot>:",
    "stopTokens": ["<human>"]
  },
  {
    "id": "togetherai@redpajama-incite-7b-instruct",
    "model": "redpajama-incite-7b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "displayName": "RedPajama-INCITE Instruct (7B)",
    "creatorName": "Together",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct",
    "license": "apache-2.0",
    "parameterSize": 6857.302016,
    "contextLength": 2048
  },
  {
    "id": "togetherai@redpajama-incite-base-3b-v1",
    "model": "redpajama-incite-base-3b-v1",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "displayName": "RedPajama-INCITE (3B)",
    "creatorName": "Together",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "license": "apache-2.0",
    "parameterSize": 2775.86432,
    "contextLength": 2048
  },
  {
    "id": "togetherai@redpajama-incite-chat-3b-v1",
    "model": "redpajama-incite-chat-3b-v1",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "displayName": "RedPajama-INCITE Chat (3B)",
    "creatorName": "Together",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "license": "apache-2.0",
    "parameterSize": 2775.86432,
    "contextLength": 2048,
    "promptFormat": "<human>: {prompt}\n<bot>:",
    "stopTokens": ["<human>"]
  },
  {
    "id": "togetherai@redpajama-incite-instruct-3b-v1",
    "model": "redpajama-incite-instruct-3b-v1",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "displayName": "RedPajama-INCITE Instruct (3B)",
    "creatorName": "Together",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.",
    "url": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "license": "apache-2.0",
    "parameterSize": 2775.86432,
    "contextLength": 2048
  },
  {
    "id": "togetherai@alpaca-7b",
    "model": "alpaca-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/alpaca-7b",
    "displayName": "Alpaca (7B)",
    "creatorName": "Stanford",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ",
    "url": "https://huggingface.co/tatsu-lab/alpaca-7b-wdiff",
    "license": "cc-by-nc-4.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["</s>", "###"]
  },
  {
    "id": "togetherai@codegen2-16b",
    "model": "codegen2-16b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/codegen2-16B",
    "displayName": "CodeGen2 (16B)",
    "creatorName": "Salesforce",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "An autoregressive language models for program synthesis.",
    "url": "https://huggingface.co/Salesforce/codegen2-3_7B",
    "license": "apache-2.0",
    "parameterSize": 16000,
    "contextLength": 2048,
    "stopTokens": ["\n\n"]
  },
  {
    "id": "togetherai@codegen2-7b",
    "model": "codegen2-7b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/codegen2-7B",
    "displayName": "CodeGen2 (7B)",
    "creatorName": "Salesforce",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "An autoregressive language models for program synthesis.",
    "url": "https://huggingface.co/Salesforce/codegen2-3_7B",
    "license": "apache-2.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "stopTokens": ["\n\n"]
  },
  {
    "id": "togetherai@falcon-40b-instruct",
    "model": "falcon-40b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/falcon-40b-instruct",
    "displayName": "Falcon Instruct (40B)",
    "creatorName": "TII UAE",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ",
    "url": "https://huggingface.co/tiiuae/falcon-40b-instruct",
    "license": "apache-2.0",
    "parameterSize": 40000,
    "contextLength": 2048,
    "promptFormat": "User: {prompt}\nAssistant:",
    "stopTokens": ["User:", "</s>"]
  },
  {
    "id": "togetherai@falcon-40b",
    "model": "falcon-40b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/falcon-40b",
    "displayName": "Falcon (40B)",
    "creatorName": "TII UAE",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.",
    "url": "https://huggingface.co/tiiuae/falcon-40b",
    "license": "apache-2.0",
    "parameterSize": 40000,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@falcon-7b-instruct",
    "model": "falcon-7b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/falcon-7b-instruct",
    "displayName": "Falcon Instruct (7B)",
    "creatorName": "TII UAE",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ",
    "url": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "license": "apache-2.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "User: {prompt}\nAssistant:",
    "stopTokens": ["User:", "</s>"]
  },
  {
    "id": "togetherai@falcon-7b",
    "model": "falcon-7b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/falcon-7b",
    "displayName": "Falcon (7B)",
    "creatorName": "TII UAE",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.",
    "url": "https://huggingface.co/tiiuae/falcon-7b",
    "license": "apache-2.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@guanaco-13b",
    "model": "guanaco-13b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/guanaco-13b",
    "displayName": "Guanaco (13B) ",
    "creatorName": "Tim Dettmers",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "url": "https://huggingface.co/timdettmers/guanaco-33b-merged",
    "license": "apache-2.0, LLaMA License Agreement (Meta)",
    "parameterSize": 13000,
    "contextLength": 2048,
    "promptFormat": "### Human: {prompt} ### Assistant:",
    "stopTokens": ["###"]
  },
  {
    "id": "togetherai@guanaco-65b",
    "model": "guanaco-65b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/guanaco-65b",
    "displayName": "Guanaco (65B) ",
    "creatorName": "Tim Dettmers",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "url": "https://huggingface.co/timdettmers/guanaco-65b-merged",
    "license": "apache-2.0, LLaMA License Agreement (Meta)",
    "parameterSize": 65000,
    "contextLength": 2048,
    "promptFormat": "### Human: {prompt} ### Assistant:",
    "stopTokens": ["###"]
  },
  {
    "id": "togetherai@guanaco-7b",
    "model": "guanaco-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/guanaco-7b",
    "displayName": "Guanaco (7B) ",
    "creatorName": "Tim Dettmers",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ",
    "url": "https://huggingface.co/timdettmers/guanaco-7b",
    "license": "apache-2.0, LLaMA License Agreement (Meta)",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "### Human: {prompt} ### Assistant:",
    "stopTokens": ["###"]
  },
  {
    "id": "togetherai@llama-2-13b-chat",
    "model": "llama-2-13b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-13b-chat",
    "displayName": "LLaMA-2 Chat (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 56.25,
    "costOutputNanoUsd": 56.25,
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-13b-chat",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 13015.86432,
    "contextLength": 4096,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["[/INST]", "</s>"]
  },
  {
    "id": "togetherai@llama-2-13b",
    "model": "llama-2-13b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-13b",
    "displayName": "LLaMA-2 (13B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 56.25,
    "costOutputNanoUsd": 56.25,
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-13b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 13015.86432,
    "contextLength": 4096
  },
  {
    "id": "togetherai@llama-2-70b-chat",
    "model": "llama-2-70b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-70b-chat",
    "displayName": "LLaMA-2 Chat (70B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-70b-chat",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 68976.648192,
    "contextLength": 4096,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["[/INST]", "</s>"]
  },
  {
    "id": "togetherai@llama-2-70b",
    "model": "llama-2-70b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-70b",
    "displayName": "LLaMA-2 (70B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-70b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 68976.648192,
    "contextLength": 4096
  },
  {
    "id": "togetherai@llama-2-7b-chat",
    "model": "llama-2-7b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-7b-chat",
    "displayName": "LLaMA-2 Chat (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-7b-chat",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 6738.415616,
    "contextLength": 4096,
    "promptFormat": "[INST] {prompt} [/INST]",
    "stopTokens": ["[/INST]", "</s>"]
  },
  {
    "id": "togetherai@llama-2-7b",
    "model": "llama-2-7b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/llama-2-7b",
    "displayName": "LLaMA-2 (7B)",
    "creatorName": "Meta",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters",
    "url": "https://huggingface.co/togethercomputer/llama-2-7b",
    "license": "LLaMA license Agreement (Meta)",
    "parameterSize": 6738.415616,
    "contextLength": 4096
  },
  {
    "id": "togetherai@mpt-30b-instruct",
    "model": "mpt-30b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-30b-instruct",
    "displayName": "MPT-Instruct (30B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets",
    "url": "https://huggingface.co/mosaicml/mpt-30b-instruct",
    "license": "CC-By-SA-3.0",
    "parameterSize": 30000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:\n",
    "stopTokens": ["<|endoftext|>", "###"]
  },
  {
    "id": "togetherai@mpt-30b",
    "model": "mpt-30b",
    "category": "language",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-30b",
    "displayName": "MPT (30B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.",
    "url": "https://huggingface.co/mosaicml/mpt-30b",
    "license": "apache-2.0",
    "parameterSize": 30000,
    "contextLength": 2048,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@mpt-7b-chat",
    "model": "mpt-7b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-7b-chat",
    "displayName": "MPT-Chat (7B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "url": "https://huggingface.co/mosaicml/mpt-7b-chat",
    "license": "cc-by-nc-sa-4.0",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
    "stopTokens": ["<|im_end|>"]
  },
  {
    "id": "togetherai@solar-0-70b-16bit",
    "model": "solar-0-70b-16bit",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "upstage/SOLAR-0-70b-16bit",
    "displayName": "SOLAR v0 (70B)",
    "creatorName": "Upstage",
    "costInputNanoUsd": 225,
    "costOutputNanoUsd": 225,
    "description": "Language model instruction fine-tuned by upstage.ai on Orca and Alpaca style datasets that reached the top spot in openLLM rankings",
    "url": "",
    "license": "CC BY-NC-4.0",
    "parameterSize": 70000,
    "contextLength": 4096,
    "promptFormat": "### System:\nYou are a respectful and helpful assistant.\n### User:\n{prompt}\n### Assistant:",
    "stopTokens": ["###"]
  },
  {
    "id": "togetherai@analog-diffusion",
    "model": "analog-diffusion",
    "category": "image",
    "vendorId": "togetherai",
    "vendorModelId": "wavymulder/Analog-Diffusion",
    "displayName": "Analog Diffusion",
    "creatorName": "Wavymulder",
    "costInputNanoUsd": 0,
    "costOutputNanoUsd": 0,
    "description": "Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ",
    "url": "https://huggingface.co/wavymulder/Analog-Diffusion",
    "license": "creativeml-openrail-m"
  },
  {
    "id": "togetherai@vicuna-13b-v1.3",
    "model": "vicuna-13b-v1.3",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/vicuna-13b-v1.3",
    "displayName": "Vicuna v1.3 (13B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "url": "",
    "license": "",
    "parameterSize": 13000,
    "contextLength": 2048,
    "promptFormat": "USER: {prompt}\nASSISTANT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@replit-code-v1-3b",
    "model": "replit-code-v1-3b",
    "category": "code",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/replit-code-v1-3b",
    "displayName": "Replit-Code-v1 (3B)",
    "creatorName": "Replit",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.",
    "url": "",
    "license": "",
    "parameterSize": 3000
  },
  {
    "id": "togetherai@mpt-7b",
    "model": "mpt-7b",
    "category": "",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-7b",
    "displayName": "MPT (7B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.",
    "url": "",
    "license": "",
    "parameterSize": 7000,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@mpt-30b-chat",
    "model": "mpt-30b-chat",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-30b-chat",
    "displayName": "MPT-Chat (30B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.",
    "url": "",
    "license": "",
    "parameterSize": 30000,
    "contextLength": 2048,
    "promptFormat": "<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant",
    "stopTokens": ["<|im_end|>"]
  },
  {
    "id": "togetherai@flan-t5-xxl",
    "model": "flan-t5-xxl",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "google/flan-t5-xxl",
    "displayName": "Flan T5 XXL (11B)",
    "creatorName": "Google",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).",
    "url": "",
    "license": ""
  },
  {
    "id": "togetherai@flan-t5-xl",
    "model": "flan-t5-xl",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "google/flan-t5-xl",
    "displayName": "Flan T5 XL (3B)",
    "creatorName": "Google",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ",
    "url": "",
    "license": "",
    "parameterSize": 3000
  },
  {
    "id": "togetherai@mpt-7b-instruct",
    "model": "mpt-7b-instruct",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/mpt-7b-instruct",
    "displayName": "MPT-Instruct (7B)",
    "creatorName": "Mosaic ML",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets",
    "url": "",
    "license": "",
    "parameterSize": 7000,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@nsql-6b",
    "model": "nsql-6b",
    "category": "",
    "vendorId": "togetherai",
    "vendorModelId": "NumbersStation/nsql-6B",
    "displayName": "NSQL (6B)",
    "creatorName": "Numbers Station",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.",
    "url": "",
    "license": "",
    "parameterSize": 6000,
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@koala-7b",
    "model": "koala-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/Koala-7B",
    "displayName": "Koala (7B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.",
    "url": "",
    "license": "",
    "parameterSize": 7000,
    "promptFormat": "USER: {prompt} GPT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@dolly-v2-12b",
    "model": "dolly-v2-12b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "databricks/dolly-v2-12b",
    "displayName": "Dolly v2 (12B)",
    "creatorName": "Databricks",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.",
    "url": "",
    "license": "",
    "parameterSize": 12000,
    "contextLength": 2048,
    "promptFormat": "### Instruction:\n{prompt}\n### Response:",
    "stopTokens": ["### End"]
  },
  {
    "id": "togetherai@gpt-neox-20b",
    "model": "gpt-neox-20b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/gpt-neox-20b",
    "displayName": "GPT-NeoX (20B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 75,
    "costOutputNanoUsd": 75,
    "description": "Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.",
    "url": "",
    "license": "",
    "parameterSize": 20000
  },
  {
    "id": "togetherai@oasst-sft-6-llama-30b-xor",
    "model": "oasst-sft-6-llama-30b-xor",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "OpenAssistant/oasst-sft-6-llama-30b-xor",
    "displayName": "Open-Assistant LLaMA SFT-6 (30B)",
    "creatorName": "LAION",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ",
    "url": "",
    "license": "",
    "promptFormat": "<|prompter|>{prompt}<|endoftext|><|assistant|>",
    "stopTokens": ["<|endoftext|>"]
  },
  {
    "id": "togetherai@instructcodet5p-16b",
    "model": "instructcodet5p-16b",
    "category": "instruct",
    "vendorId": "togetherai",
    "vendorModelId": "Salesforce/instructcodet5p-16b",
    "displayName": "InstructCodeT5 (16B)",
    "creatorName": "Salesforce",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Code large language model that can flexibly operate in different modes to support a wide range of code understanding and generation tasks. ",
    "url": "",
    "license": "",
    "parameterSize": 33000
  },
  {
    "id": "togetherai@gpt-j-6b",
    "model": "gpt-j-6b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "EleutherAI/gpt-j-6b",
    "displayName": "GPT-J (6B)",
    "creatorName": "EleutherAI",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Transformer model trained using Ben Wang's Mesh Transformer JAX. ",
    "url": "",
    "license": "",
    "parameterSize": 6000
  },
  {
    "id": "togetherai@vicuna-7b-v1.3",
    "model": "vicuna-7b-v1.3",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "lmsys/vicuna-7b-v1.3",
    "displayName": "Vicuna v1.3 (7B)",
    "creatorName": "LM Sys",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.",
    "url": "",
    "license": "",
    "parameterSize": 7000,
    "contextLength": 2048,
    "promptFormat": "USER: {prompt}\nASSISTANT:",
    "stopTokens": ["</s>"]
  },
  {
    "id": "togetherai@stablelm-base-alpha-3b",
    "model": "stablelm-base-alpha-3b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "stabilityai/stablelm-base-alpha-3b",
    "displayName": "StableLM-Base-Alpha (3B)",
    "creatorName": "Stability AI",
    "costInputNanoUsd": 25,
    "costOutputNanoUsd": 25,
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "url": "",
    "license": "",
    "parameterSize": 3000
  },
  {
    "id": "togetherai@stablelm-base-alpha-7b",
    "model": "stablelm-base-alpha-7b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "stabilityai/stablelm-base-alpha-7b",
    "displayName": "StableLM-Base-Alpha (7B)",
    "creatorName": "Stability AI",
    "costInputNanoUsd": 50,
    "costOutputNanoUsd": 50,
    "description": "Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.",
    "url": "",
    "license": "",
    "parameterSize": 7000
  },
  {
    "id": "togetherai@guanaco-33b",
    "model": "guanaco-33b",
    "category": "chat",
    "vendorId": "togetherai",
    "vendorModelId": "togethercomputer/guanaco-33b",
    "displayName": "Guanaco (33B) ",
    "creatorName": "Tim Dettmers",
    "costInputNanoUsd": 200,
    "costOutputNanoUsd": 200,
    "description": "Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.",
    "url": "",
    "license": "",
    "parameterSize": 33000,
    "contextLength": 2048,
    "promptFormat": "### Human: {prompt} ### Assistant:",
    "stopTokens": ["###"]
  }
]
